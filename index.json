[{"authors":["rjbeecham"],"categories":null,"content":"Roger Beecham is a Lecturer in Geography at University of Leeds.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en-uk","lastmod":1606733643,"objectID":"c292ffbb3141300ebc61798f6fdba165","permalink":"/authors/rjbeecham/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/rjbeecham/","section":"authors","summary":"Roger Beecham is a Lecturer in Geography at University of Leeds.","tags":null,"title":"","type":"authors"},{"authors":null,"categories":null,"content":"  The homework for each session are posted here. Work your way through the links on the left to complete the homework associated with each session.\n","date":1580947200,"expirydate":-62135596800,"kind":"section","lang":"en-uk","lastmod":1580947200,"objectID":"996950346c3c0da2fd661f739a1abdfd","permalink":"/homework/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/homework/","section":"homework","summary":"The homework for each session are posted here. Work your way through the links on the left to complete the homework associated with each session.","tags":null,"title":"Homework for sessions","type":"docs"},{"authors":null,"categories":null,"content":"  The materials for each session are posted here. Work your way through the links on the left and complete the associated homeworks.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en-uk","lastmod":1606644925,"objectID":"108da05078d325a5a1f01a1ff2583053","permalink":"/class/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/class/","section":"class","summary":"The materials for each session are posted here. Work your way through the links on the left and complete the associated homeworks.","tags":null,"title":"Class sessions","type":"docs"},{"authors":null,"categories":null,"content":"  The reading for each session is posted here. Work your way through the links on the left to locate the reading associated with each session.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en-uk","lastmod":1606644925,"objectID":"40fcd2da3bf2dc718a2fe044c31cdc56","permalink":"/reading/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reading/","section":"reading","summary":"The reading for each session is posted here. Work your way through the links on the left to locate the reading associated with each session.","tags":null,"title":"Reading","type":"docs"},{"authors":null,"categories":null,"content":"  Road safety analysis : https://docs.ropensci.org/stats19/ Others? Knife crime data?\nOR\nSharing your work – reproducible research\nIntroducing this :\nThat in academic visualization there has been a movement towards studying storytelling in visualization Why? This feels uneasy as Science, Data, Evidence – not making up stories Avoid philosophical discussions about objectivity, but data is now embedded in most domains, and particularly in the public sphere. Lies Damn, Lies and Statistics – data Journalism, statistical literacy.  From Data Driven Storytelling\nWe think this movement towards data-driven stories, which is apparent in both the data visualization research community and the professional journalism community, has the potential to form a crucial part of keeping the public informed, a movement sometimes referred to as the democratization of data – the making of data understandable to the general public. This exciting new development in the use of data visualization in media has revealed an emerging professional community in the already complex group of disciplines involved in data visualization. Data visualization has roots in many research fields including perception, computer graphics, design, and human-computer interaction, though only recently has this expanded to include journalism.\nData journalism here has also been a growing consciousness that some of today’s most relevant stories are buried in data. This data can be quite hard to understand in its raw formats but can become much more generally accessible when visualized. Journalists have not only begun to use standard data visualizations such as charts and maps in their stories, but are also creating new ones that are tailored to the particular data type and to the message of the story they are writing. Since journalists are now able to easily share interactive data visualizations on the Web, the democratization of data visualization is accelerating with new compelling data visualizations emerging in the media daily…\nBy carefully structuring the information and integrating explanation to guide the consumer, journalists help lead readers towards a valid interpretation of the underlying data.\n","date":1624924800,"expirydate":-62135596800,"kind":"page","lang":"en-uk","lastmod":1624924800,"objectID":"a696c93d764e2bfb447300660fcf2be7","permalink":"/class/08-class/","publishdate":"2021-06-29T00:00:00Z","relpermalink":"/class/08-class/","section":"class","summary":"Road safety analysis : https://docs.ropensci.org/stats19/ Others? Knife crime data?\nOR\nSharing your work – reproducible research\nIntroducing this :\nThat in academic visualization there has been a movement towards studying storytelling in visualization Why? This feels uneasy as Science, Data, Evidence – not making up stories Avoid philosophical discussions about objectivity, but data is now embedded in most domains, and particularly in the public sphere. Lies Damn, Lies and Statistics – data Journalism, statistical literacy.","tags":null,"title":"Visualization for data storytelling","type":"docs"},{"authors":null,"categories":null,"content":"  Road safety analysis : https://docs.ropensci.org/stats19/ Others? Knife crime data?\nOR\nSharing your work – reproducible research\n","date":1624924800,"expirydate":-62135596800,"kind":"page","lang":"en-uk","lastmod":1624924800,"objectID":"6fce0ded8aa03d77081bcdf32570ef18","permalink":"/class/09-class/","publishdate":"2021-06-29T00:00:00Z","relpermalink":"/class/09-class/","section":"class","summary":"Road safety analysis : https://docs.ropensci.org/stats19/ Others? Knife crime data?\nOR\nSharing your work – reproducible research","tags":null,"title":"Visualization for data storytelling","type":"docs"},{"authors":null,"categories":null,"content":"  Road safety analysis : https://docs.ropensci.org/stats19/\n","date":1624320000,"expirydate":-62135596800,"kind":"page","lang":"en-uk","lastmod":1624320000,"objectID":"026700f4d4068083b37f98f89edf4682","permalink":"/class/07-class/","publishdate":"2021-06-22T00:00:00Z","relpermalink":"/class/07-class/","section":"class","summary":"Road safety analysis : https://docs.ropensci.org/stats19/","tags":null,"title":"Visualization for uncertainty analysis","type":"docs"},{"authors":null,"categories":null,"content":"  Trump analysis : https://walker-data.com/tidycensus/\nStory – previously very data-driven\n","date":1623715200,"expirydate":-62135596800,"kind":"page","lang":"en-uk","lastmod":1623715200,"objectID":"119022d4a0cb3ad45bc292e062e9e05a","permalink":"/class/06-class/","publishdate":"2021-06-15T00:00:00Z","relpermalink":"/class/06-class/","section":"class","summary":"Trump analysis : https://walker-data.com/tidycensus/\nStory – previously very data-driven","tags":null,"title":"Visualization for model building: Expose, estimate, evaluate","type":"docs"},{"authors":null,"categories":null,"content":"  OD Census Travel to work data …\nhttps://cran.r-project.org/web/packages/stplanr/vignettes/stplanr-od.html\nContainment – geographically arranged small multiples Connection – lines Connection – OD maps Connection – bikes\n","date":1623110400,"expirydate":-62135596800,"kind":"page","lang":"en-uk","lastmod":1606644925,"objectID":"0ddf3e2b3a9f5347c88f83033fb01ff2","permalink":"/class/05-class/","publishdate":"2021-06-08T00:00:00Z","relpermalink":"/class/05-class/","section":"class","summary":"OD Census Travel to work data …\nhttps://cran.r-project.org/web/packages/stplanr/vignettes/stplanr-od.html\nContainment – geographically arranged small multiples Connection – lines Connection – OD maps Connection – bikes","tags":null,"title":"Visualization for exploratory geospatial data analysis: Containment and connection","type":"docs"},{"authors":null,"categories":null,"content":"   The simple graph has brought more information to the data analyst’s mind than any other device.\" –\u0026gt; – John Tukey\n Theory – EDA?\nStats19 data – preference – that will return to this in week 07 bikes data – second preference – though not too sure. Could link to the whole, bit sure if will be discriminating structure from start\nStats19 – large, attribute-rich. Underanalysed. Not sure how discriminating structure will be.\n Faceting https://ids-s1-20.github.io/slides/week-02/w2-d03-ggplot2/w2-d03-ggplot2.html#38  https://ids-s1-20.github.io/slides/week-02/w2-d02-data-viz/w2-d02-data-viz.html#18\nCode out loud a good idea https://ids-s1-20.github.io/slides/week-02/w2-d03-ggplot2/w2-d03-ggplot2.html#6\nApproach to analysing data to summarise its main characetristics Often visual Also here would calculate summary stats, perform data wrangling/manipulation/transformation\n","date":1622505600,"expirydate":-62135596800,"kind":"page","lang":"en-uk","lastmod":1606644925,"objectID":"ac7533426a3114e90edf09c0635b197a","permalink":"/class/04-class/","publishdate":"2021-06-01T00:00:00Z","relpermalink":"/class/04-class/","section":"class","summary":"The simple graph has brought more information to the data analyst’s mind than any other device.\" –\u0026gt; – John Tukey\n Theory – EDA?\nStats19 data – preference – that will return to this in week 07 bikes data – second preference – though not too sure. Could link to the whole, bit sure if will be discriminating structure from start\nStats19 – large, attribute-rich. Underanalysed. Not sure how discriminating structure will be.","tags":null,"title":"Visualization for exploratory data analysis: Colour and layout","type":"docs"},{"authors":null,"categories":null,"content":"  Contents  Introduction Grammar of Graphics Data, marks and channels Evaluating designs (Washington Post map) Characteristics of effective data graphics    By the end of this session you should gain the following knowledge:\n  Recognise the key characteristics of effective data graphics. Understand principles underpinning visualization design – that visualization design is concerned with a mapping between data to visual channels. Appreciate how these principles can be deployed when describe graphics in a consistent and systematic way – that there is a grammar of graphics, and that understanding this grammar is necessary for using modern visualization toolkits (ggplot, vega-lite and Tableau).    By the end of this session you should gain the following practical skills:\n  Create effective data graphics using ggplot2 specifications, by mapping data to colour and position.    Dataset : Trump election 2016 – with 2012 data so can look at shift (tar we will revisit this in session 6). General Election 2019 | https://researchbriefings.files.parliament.uk/documents/CBP-8749/HoC-GE2019-results-by-constituency-csv.csv\nIntroduction  That we will consider the process and steps that take place in order to turn some data into something graphical. That there is a formalised/systematic way of describing this process, the grammar of graphics. That this can be used to easily describe and create graphics – and so modern visualization toolkits explicitly follow GoG. That we can use this, and empirical knowledge of specifications/encoding combinations that are effective, to evaluate graphics.   Grammar of Graphics  Grammar The whole system and structure of a language or of languages in general, usually taken as consisting of syntax and morphology (including inflections) and sometimes also phonology and semantics.\n codify data types, encodings/channels, marks map data -\u0026gt; channels -\u0026gt; marks\nencode data with visual channels display encodings with marks\nExample of scatterplot scatter vote_share : numeric y position degree_educated : numeric x position margin : colour | shape mark : point .\n Mapping aes() within geoms\n Setting (not mapping to data, so outside of aes()) https://ids-s1-20.github.io/slides/week-02/w2-d03-ggplot2/w2-d03-ggplot2.html#28\n   Data, marks and channels What channel is best for? quantitative, ordered, nominal? Some encodings induce bias – length versus area encodings Absolute encoding versus flannery exponent. overlapping circles getting larger. Vis configruations may be equally expressive, but no as effective – circles versus bars Colour - Brewer and conceptually unform colour\nFrom this, guidelines :\nRecommendations/Guidelines Use perception to choose most effective Channels Use symbolisation that makes sense given the dataset – sloping to the right Trump, left Clinton, RdBu Use popout and separable encodings – colour hue in use, orientation in use, thickness (shape\n Evaluating designs (Washington Post map) Why GoG? Helps specify many charts and combinations, helps evaluate charts systematically, helps design charts systematically …\nEvaluate – how well do these match, given the channel used? Schematics do this The GoG is useful because it identifies the steps we have to go through to fully and unambiguously specify what we want a visualization to do. It also helps us to ask ‘why’ questions at each stage to assist us in justifying our visualization designs )\nCode out loud a good idea https://ids-s1-20.github.io/slides/week-02/w2-d03-ggplot2/w2-d03-ggplot2.html#6\nAssessed task 1? show graphic and describe and evaluate it:\nWhat are the variables / types? Channels / encodings? Marks? Is this effective? Why?\nCharacteristics of effective data graphics From Jo :\nRepresents a complex dataset graphically that could not as effectively be represented via other means. Often emphasises connections and comparisons between items of data. Frequently involves interaction to allow someone to influence what they see. A “narrative providing a clear answer to a question without extraneous details” (Fry, 2008 p.4). Generates an aesthetic response in order to encourage people to engage with the data or question.    ","date":1621900800,"expirydate":-62135596800,"kind":"page","lang":"en-uk","lastmod":1606644925,"objectID":"a0c01f3889200201f6df018341b3db8f","permalink":"/class/03-class/","publishdate":"2021-05-25T00:00:00Z","relpermalink":"/class/03-class/","section":"class","summary":"Contents  Introduction Grammar of Graphics Data, marks and channels Evaluating designs (Washington Post map) Characteristics of effective data graphics    By the end of this session you should gain the following knowledge:\n  Recognise the key characteristics of effective data graphics. Understand principles underpinning visualization design – that visualization design is concerned with a mapping between data to visual channels. Appreciate how these principles can be deployed when describe graphics in a consistent and systematic way – that there is a grammar of graphics, and that understanding this grammar is necessary for using modern visualization toolkits (ggplot, vega-lite and Tableau).","tags":null,"title":"Visualization fundamentals: Codify, map, evaluate","type":"docs"},{"authors":null,"categories":null,"content":"  Contents  Session outcomes Describing tidy data Tidy data  Data transformations – dplyr Data wrangling for tidy data   Session outcomes By the end of this session you should gain the following knowledge:\n  Be able to describe data according to its main characteristics – dimensions and measurement levels. Appreciate the characteristics and importance of Tidy data for data processing and analysis.    By the end of this session you should gain the following practical skills:\n  Load flat file datasets into R via RStudio. Calculate descriptive summaries over datasets. Apply high-level functions in dplyr for working with Tidy data. Create statistical graphics that expose high-level strutucture in data for cleaning purposes.    bikes data (advantage is that can revisit this in week 5) Load in Covid-19 data – and apply to Covid-19 : https://coronavirus.data.gov.uk/details/download\n Describing tidy data Categorical/nominal operations = != ordinal = != \u0026lt;\u0026gt; Quantitative = != \u0026lt;\u0026gt; + - (x /) Measurement-type Description Example – See Jo Session01 table!\nBike stations Quantitative num journeys, Ordinal (first, second, third, fourth), Categorical (is central London, is not Central London)\nOrdinal -\u0026gt; sequential/diverging Diverging -\u0026gt; net in/out\nNumerical : continuous or discrete. Continuous can take an infinite number of values; discrete only non-negative whole numbers\nCategorical : ordinal, whether or nor a natural ordering\nEach row is an observation; Each column is a variable glimpse() nrow() ncol() dim()\nTidy data Each variable forms a column. Each observation forms a row. Each type of observational unit forms a table.\nWhy do we need tidy data? – demonstrate summarise\n  Data transformations – dplyr Table of key functions – https://cfss.uchicago.edu/slides/data-transformation/#14 Table of key functions – https://ids-s1-20.github.io/slides/week-03/w3-d03-grammar-wrangle/w3-d03-grammar-wrangle.html#3\nRules : 1. data frame 2. arguments to describe what to do on data frame. 3. returns the datframe\nfirst look: names() second look: glimpse() select() dplyr functions always expect a data frame and always yield a data frame. select() combined with arrange(desc()) select(-) select() select(starts_with(\u0026lt;\"\"\u0026gt;)) slice() filter() https://ids-s1-20.github.io/slides/week-03/w3-d04-single-df/w3-d04-single-df.html#17 count()|distinct() mutate() – add a new variable summarise() and group_by() – count() is short for group_by and fid freq. Multiple summary stats.\nAssignment [\u0026lt;-] – e.g. printing to Console versus saving to workspace\nConditionals/logical operators https://cfss.uchicago.edu/slides/pipes-and-functions-in-r/#15 https://ids-s1-20.github.io/slides/week-03/w3-d04-single-df/w3-d04-single-df.html#18\nPiping In programming, a pipe is a technique for passing information from one process to another. no pipes versus with pipes – https://cfss.uchicago.edu/slides/data-transformation/#26 https://cfss.uchicago.edu/slides/pipes-and-functions-in-r/#8 Break down what happens https://ids-s1-20.github.io/slides/week-03/w3-d03-grammar-wrangle/w3-d03-grammar-wrangle.html#29\nAside: pipe operator is implemented in the package magrittr, though we don’t need to load this package explicitly since tidyverse does this for us.\nNaming columns should be syntactically valid – https://style.tidyverse.org/syntax.html#object-names\nJoins: inner left right union https://ids-s1-20.github.io/slides/week-03/w3-d05-multi-df/w3-d05-multi-df.html#8\n Data wrangling for tidy data https://ids-s1-20.github.io/slides/week-03/w3-d06-tidying/w3-d06-tidying.html#5\nPivot: longer|wider https://ids-s1-20.github.io/slides/week-03/w3-d06-tidying/w3-d06-tidying.html#14 https://ids-s1-20.github.io/slides/week-03/w3-d06-tidying/w3-d06-tidying.html#18 separate – https://cfss.uchicago.edu/slides/data-wrangling-tidy-data/#21 unite –\nFactors forcats: Catgeorical variables Best used for sorting values non-alphabetically Example applied to months https://cfss.uchicago.edu/slides/data-wrangling-relational-data-and-factors/#13\nFunctions named as verbs (they do things), followed by parameters affecting what they do, and what they will be applied to, in brackets. https://cfss.uchicago.edu/slides/pipes-and-functions-in-r/#9 name, argument, body\n ","date":1621296000,"expirydate":-62135596800,"kind":"page","lang":"en-uk","lastmod":1606644925,"objectID":"9ae245330f59c57e6f62568d635c26e4","permalink":"/class/02-class/","publishdate":"2021-05-18T00:00:00Z","relpermalink":"/class/02-class/","section":"class","summary":"Contents  Session outcomes Describing tidy data Tidy data  Data transformations – dplyr Data wrangling for tidy data   Session outcomes By the end of this session you should gain the following knowledge:\n  Be able to describe data according to its main characteristics – dimensions and measurement levels. Appreciate the characteristics and importance of Tidy data for data processing and analysis.    By the end of this session you should gain the following practical skills:","tags":null,"title":"Data fundamentals: Describe, wrangle, tidy","type":"docs"},{"authors":null,"categories":null,"content":"  Contents  Session outcomes Welcome to Visualization for Geographic Data Science Why vis-for-gds? Geographic Data Science Geographic Data Science and Visualization  What vis-for-gds? How vis-for-gds? R tidyverse ggplot2?  Our expectations Navigating the materials Self-guided learning Slack  Getting started with R and RStudio References   Session outcomes By the end of this session you should gain the following knowledge:\n  Appreciate the motivation for this module – why visualization, why R and why ggplot2    By the end of this session you should gain the following practical skills:\n  Navigate the materials on this course website, having familiarised yourself with its structure Open R using the RStudio Integrated Developer Environment (IDE) Install and enable R packages and query package documentation Perform basic calculations via the R Console Read-in datasets from external resources as objects (specifically tibbles)     Welcome to Visualization for Geographic Data Science Welcome to Visualization for Geographic Data Science (vis-for-gds). In this first session we’ll cover the background to the module – the why, what and how of vis-for-gds, a little on how the module will be run and our expectations of you.\nThe main home for this module is this website. However, via Minerva you can access the Module Handbook. You will use submission boxes in Minerva to upload coursework in the usual way.\n Why vis-for-gds? Geographic Data Science It is now taken-for-granted that over the last decade or so new data, new technology and new ways of doing science have transformed how we approach the world’s problems. Evidence for this can be seen in the response to the Covid-19 pandemic. Enter Covid19 github into a search and you’ll be confronted with hundreds of repositories demonstrating how an ever-expanding array of data related to the pandemic can be collected, processed and analysed. Data Science is a term used widely to capture this shift and Geographic Data Science (GDS), probably first discussed coherently by Arribas-Bel and Reades (2018) and Singleton and Arribas-Bel (2019), when observing that many of data science’s applications are – or at least should be – of inherent interest to geographers.\nSince gaining traction in the corporate world, the definition of Data Science has been somewhat stretched, but it has its origins in the work of John Tukey’s The Future of Data Analysis (1962). Drawing on this, and a survey of more recent work, Donoho (2017) neatly identify six key facets that a data science discipline might encompass1 :\ndata gathering, preparation, and exploration; data representation and transformation; computing with data; data visualization and presentation; data modelling; and a more introspective “science about data science”   Geographic Data Science and Visualization Visualization is fundamental to meeting the unprecedented challenges and exploiting the wonderful opportunities of the ever-expanding deluge of data confronting virtually every field.\" \\  -- Prof. Jim Hollan of UC San Diego --  Visual approaches to data analysis are particularly suited to Geographic Data Science applications because where datasets are being repurposed for social and natural sciences research for the first time, contain complex structure and geo-spatial relations that cannot be easily captured by statistical summaries alone and so where the types of questions that can be asked and the techniques deployed to answer them cannot be easily specified in advance.   -- Glancing at this list, visualization could be interpreted as a single facet of Data Science process2 – something that happens after data gathering, preparation, exploration, but before modelling. In this module you’ll learn that visualization is intrinsic to, and should inform, each of these activities, especially so when working with data sets that are spatial – for Geographic Data Science.\nLet’s develop this idea by asking why data visualizations are used in the first place. In her book Visualization Analysis and Design, Tamara Munzer (2014) considers how humans and computers interface in the decision-making process. She makes the point that data visualization is ultimately about connecting people with data in order to make decisions – or to install humans in a ‘decision-making-loop’. There are occasionally decision-making loops that are entirely computational and where an automated solution exists and is trusted. However, most require some form of human intervention.\nThe canonical example demonstrating how relying on computation alone can be problematic, and so for the use of visualization, is Anscombe’s quartet. Here, Anscombe (1973) presents four datasets, each containing eleven observations and two variables for each observation. The data are synthetic, but let’s say that they are the weight and height of independent samples taken from a population of Postgraduate Students studying Data Science.\nPresented with a new dataset it makes sense to compute some summaries and doing so, we observe that the data appear identical – they contain the same means, variances and strong positive correlation coefficient. This seems appropriate since the data are measuring weight and height. Although there may be some variation, we’d expect taller students to be heavier. Given these statical summaries we can be confident that we are drawing samples from the same population of (Data Science) students.\n Figure 1: Data from Anscombe’s quartet  Laying out the data in a meaningful way, horizontally according to weight (x) and vertically according to the height (y) to form a scatterplot, we quickly see that whilst these data contain the same statistical properties they are very different. Only dataset #1 now looks plausible if it were truly a measure of weights and heights drawn from a population of students.\nAnscombe’s is a deliberately contrived example3, but there are real cases of important structure being missed, leading to poorly specified models and potentially faulty claims.\n Figure 2: Plots of Anscombe’s quartet  This is not to undermine the importance of numerical analysis. Numeric summaries that simplify patterns are extremely useful and Statistics has at its disposal an array of tools for helping to guard against making false claims from datasets – a theme that we will return to in session 6, 7 and 8 when we think critically about the use of visual approaches for data anlysis. There remain, though, certain classes of relation and context that cannot be easily captured through statistics alone.\nGeographic context is undoubtedly challenging to capture numerically; many of the early examples of data visualization have been of spatial phenomena and generated by Geographers (see Friendly 2007). We can also probably make a special case for the use of visual approaches in Geographic Data Science (GDS) applications due to its exploratory nature. Often in GDS datasets are being repurposed for social and natural sciences research for the first time; contain complex structure and geo-spatial relations that cannot be easily captured by statistical summaries alone; and so the types of questions that can be asked and the techniques deployed to answer them cannot be easily specified in advance. In this module we will demonstrate this as we explore (Session 4 and 5), model under uncertainty (Session 6 and 7) and communicate (Session 7 and 8) with various social science datasets.\n Watch Jo Wood’s talk demonstrating how visual techniques can be used to analyse urban travel behaviours. In the video Jo argues that bikeshare schemes can help democratise cycling, but also for their potential contributions to research – he briefly contrasts new, passively collected data sets with more “traditional” actively collected data for analysing how people move around cities. A compelling case is then made for the use of visualization to support this activity. This work and further discussion is published in Beecham and Wood (2014).     Effective data visualizations should expose structure in data that would be difficult to expose through non-visual means --   What vis-for-gds? This is a very practical module. With the exception of this Introduction, the weekly sessions will blend both theory and practical coding activity. We will cover fundamentals around visual data analysis from Information Visualization and Statistics and as you read the session materials you will be writing data processing and analysis code and so be generating analysis outputs of your own. We will also be working with real datasets – from the Political Science, Urban and Transport Planning and Health domains. So we will hopefully be generating real findings and knowledge.\nTo do this in a genuine way – to generate real knowledge from datasets – we will have to cover a reasonably broad set of data processing and analysis procedures. As well as developing expertise around designing data-rich, visually compelling graphics (of the sort demonstrated in Jo Wood’s TEDx talk), we will need to cover more tedious aspects of data processing and wrangling. Additionally, if we are to learn how to generate and communicate and make claims under uncertainty with our data graphics, then we will need to cover some aspects of estimation and modelling from Statistics. In short, we will cover most of Donoho (2017)’s six key facets of a data science discipline:\ndata gathering, preparation, and exploration (Sessions 2, 3, 5); data representation and transformation (Sessions 2, 3); computing with data (Session 2); data visualization and presentation (All Sessions); data modelling (Sessions 6, 7, 8); and a more introspective “science about data science” (All Sessions, Plus Optional Extra)  There is already a rich and impressive set of open Resources practically introducing how to do modern Data Science, Visualization and Geographic Analysis. We will certainly draw on these at different stages in the module. What makes this module different from these existing resources is that we will be doing applied data science throughout – we will be identifying and diagnosing problems when gathering data, discovering patterns (some maybe even spurious) as we do exploratory analysis, and will attampt to make claims under uncertainty as we generate models based on observed patterns. We will work with both new, passively-collected datasets, as well as more traditional, actively collected datasets located within various social science domains: Political Science, Health Science and Urban and Transport Planning.\n How vis-for-gds? R Through the module we will apply modern approaches to data analysis. All data collection, analysis and reporting activity will be completed using R. Released as open source software as part of a research project in 1995, for some time R was the preserve of academics. From 2010s onwards, the R community expanded rapidly and along with Python is regarded as the key technology for doing data analysis. R is used increasingly outside of academia, by organisations such as Google [example], Facebook [example], Twitter [example], New York Times [example], BBC [example] and many more.\nThere are many benefits that come from being fully open-source, with a critical mass of users. Firstly, there is an array of online forums, tutorials and code examples from which to learn. Second, with such a large community, there are numerous expert R users who themselves contribute by developing libraries or packages that extend its use. As a result R is employed for a very wide set of use cases – this website was even built in R using amongst other things the blogdown package.\n An R package is a bundle of code, data and documentation, usually hosted centrally on the CRAN (Comprehensive R Archive Network). A particularly important, though very recent, set of packages is the tidyverse: a set of libraries authored mainly by Hadley Wickham, which share a common underlying philosophy, syntax and documentation.   https://ids-s1-20.github.io/slides/week-01/w1-d05-toolkit-r/w1-d05-toolkit-r.html#15\nReproducibility  Reproducible research is the idea that data analyses, and more generally, scientific claims, are published with their data and software code so that others may verify the findings and build upon them. Roger Peng, Jeff Leek and Brian Caffo\n In recent years there has been much introspection around how science works – around how statistical claims are made from reasoning over evidence. This came on the back of, amongst other things, a high profile paper published in Science, which found that of 100 recent peer-reviewed psychology experiments, the findings of only 39 could be replicated. The upshot is that researchers must now make every possible effort to make their work transparent, such that _all_ aspects of the answer generated by any given analysis [can] be tested' [@brunsdon_opening_2020]. In this setting, traditional data analysis software that support point-and-click interaction is unhelpful; it would be tedious to make notes describing all interactions with, for example, SPSS. As a declarative programming language, however, it is very easy to provide such a provenance trail for your workflows inR` since this necessarily exists in your analysis scripts.\nConcerns around the reproducibility crisis are not simply a function of transparency in methodology and research design. Rather, they relate to a culture and incentive structure whereby scientific claims are conferred with authority when reported within the (slightly backwards) logic of Null Hypothesis Significance Testing (NHST) and p-values. We will cover a little on this in session 7 and 8, but for an accessible read on the phenomenon of p-hacking (with interactive graphic) see this article from the excellent FiveThirtyEight website. Again, the upshot of all this introspection is a rethinking of the way in which Statistics is taught in schools and universities, with greater emphasis on understanding through computational approaches rather than traditional equations, formulas and probability tables. Where does R fit within this? Simply put: R is far better placed than traditional software tools and point-and-click paradigms for supporting computational approaches to statistics – with a set of methods and libraries for performing simulations and permutation-based tests.\nIn essence, a reproducible research philosophy is one which allows all aspects of the answer generated by any given analysis to be tested. This is especially the case as our lives are increasingly lived and shaped by a vast amount of data—often termed Big Data (upper case intentional).\nNear-term goals: Are the tables and figures reproducible from the code and data? Does the code actually do what you think it does? In addition to what was done, is it clear why it was done?\nLong-term goals: Can the code be used for other data? Can you extend the code to do other things?\n Literate programming .Rmd for code, narrative and output in one place.\nrmarkdown and the various packages that support it enable R users to write their code and prose in reproducible computational documents\nFully reproducible reports – each time you knit the analysis is ran from the beginning Simple markdown syntax for text Code goes in chunks, defined by three backticks, narrative goes outside of chunks\nAdvertise .Rmd cheat sheet\nHow we will use .Rmd :\nEvery assignment / report / project / etc. is an R Markdown document You’ll always have a template R Markdown document to start with The amount of scaffolding in the template will decrease over the semester\n Version control git!!\n  tidyverse The tidyverse is an opinionated collection of R packages designed for data science All packages share an underlying philosophy and a common grammar\n ggplot2? ggplot2 is tidyverse’s data visualization package gg in “ggplot2” stands for Grammar of Graphics Inspired by the book Grammar of Graphics by Leland Wilkinson\n  Our expectations Navigating the materials  Self-guided learning  stay engaged participate ask questions   Slack   Getting started with R and RStudio Packages are installed with the install.packages function and loaded with the library function, once per session\nObject documentation can be accessed with ?\n References Anscombe, F. 1973. “Graphs in Statistical Analysis.” American Statistician 27 (1): 17–21. doi:10.1080/00031305.1973.10478966.\n Arribas-Bel, Dani, and Jon Reades. 2018. “Geography and Computers: Past, Present, and Future.” Geography Compass 12 (10): e12403. doi:10.1111/gec3.12403.\n Beecham, Roger, and Jo Wood. 2014. “Exploring Gendered Cycling Behaviours Within a Large-Scale Behavioural Data-Set.” Transportation Planning and Technology 37 (1). Taylor \u0026amp; Francis: 83–97.\n Donoho, David. 2017. “50 Years of Data Science.” Journal of Computational and Graphical Statistics 26 (6): 745–66. doi:10.1080/10618600.2017.1384734.\n Friendly, Michael. 2007. “A Brief History of Data Visualization.” In Handbook of Computational Statistics: Data Visualization, edited by C. Chen, W. Härdle, and A Unwin, III:1–34. Heidelberg: Springer-Verlag. http://datavis.ca/papers/hbook.pdf.\n Matejka, Justin, and George Fitzmaurice. 2017. “Same Stats, Different Graphs: Generating Datasets with Varied Appearance and Identical Statistics Through Simulated Annealing.” In, 1290–4. CHI ’17. New York, NY, USA: Association for Computing Machinery. doi:10.1145/3025453.3025912.\n Munzer, Tamara. 2014. Visualization Analysis and Design. AK Peters Visualization Series. Boca Raton, FL: CRC Press.\n Singleton, Alex, and Dani Arribas-Bel. 2019. “Geographic Data Science.” Geographical Analysis. doi:10.1111/gean.12194.\n    For an excellent precis and interpretation of this for geographers, see Arribas-Bel and Reades (2018).↩︎\n Although not the case when actually reading Donoho (2017).↩︎\n Checkout Matejka and Fitzmaurice (2017)’s Same Stats, Different Graphs paper for a fun take one this.↩︎\n   ","date":1620691200,"expirydate":-62135596800,"kind":"page","lang":"en-uk","lastmod":1606644925,"objectID":"ac47977a15b3902ca3402f61e5bf9df2","permalink":"/class/01-class/","publishdate":"2021-05-11T00:00:00Z","relpermalink":"/class/01-class/","section":"class","summary":"Contents  Session outcomes Welcome to Visualization for Geographic Data Science Why vis-for-gds? Geographic Data Science Geographic Data Science and Visualization  What vis-for-gds? How vis-for-gds? R tidyverse ggplot2?  Our expectations Navigating the materials Self-guided learning Slack  Getting started with R and RStudio References   Session outcomes By the end of this session you should gain the following knowledge:\n  Appreciate the motivation for this module – why visualization, why R and why ggplot2    By the end of this session you should gain the following practical skills:","tags":null,"title":"Introduction: Vis for Geographic Data Science","type":"docs"},{"authors":null,"categories":null,"content":"  Contents  Download and Configure   Download and Configure  ","date":1580947200,"expirydate":-62135596800,"kind":"page","lang":"en-uk","lastmod":1580947200,"objectID":"7f1f54adb3ac450ad99be6af1a9f99df","permalink":"/homework/01-homework/","publishdate":"2020-02-06T00:00:00Z","relpermalink":"/homework/01-homework/","section":"homework","summary":"  Contents  Download and Configure   Download and Configure  ","tags":null,"title":"Inroduction","type":"docs"},{"authors":null,"categories":null,"content":"  ","date":1620691200,"expirydate":-62135596800,"kind":"page","lang":"en-uk","lastmod":1606644925,"objectID":"57c6d6996ee98125a5375a3865ff4c4c","permalink":"/reading/01-reading/","publishdate":"2021-05-11T00:00:00Z","relpermalink":"/reading/01-reading/","section":"reading","summary":"  ","tags":null,"title":"Introduction","type":"reading"},{"authors":null,"categories":null,"content":"  Each session has three sections.\n  Reading: Reading and other reference material.  Class: Main content – a mix of ideas/theory and worked examples.  Homework: Homework activity to complete after having worked through the main class content.    Week 1 Introduction      Week 2 Data fundamentals      Week 3 Visualization fundamentals      Week 4 Visualization for exploratory data analysis      Week 5 Visualization for exploratory geospatial data analysis      Week 6 Visualization for model building 1      Week 7 Visualization for model building 2      Week 8 Visualization for uncertainty analysis       ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en-uk","lastmod":1606644925,"objectID":"3e223d7ba58b0122b42458e4cf52e04c","permalink":"/schedule/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/schedule/","section":"","summary":"  Each session has three sections.\n  Reading: Reading and other reference material.  Class: Main content – a mix of ideas/theory and worked examples.  Homework: Homework activity to complete after having worked through the main class content.    Week 1 Introduction      Week 2 Data fundamentals      Week 3 Visualization fundamentals      Week 4 Visualization for exploratory data analysis      Week 5 Visualization for exploratory geospatial data analysis      Week 6 Visualization for model building 1      Week 7 Visualization for model building 2      Week 8 Visualization for uncertainty analysis       ","tags":null,"title":"Schedule","type":"page"},{"authors":null,"categories":null,"content":"   Overview Course Objectives Resources Primers Blogs Conferences    Overview In modern data analysis, graphics and computational statistics are increasingly used together to explore and identify complex patterns in data and to make and communicate claims under uncertainty. This course will go beyond traditional ideas of charts, graphs, maps (and also statistics!) to equip you with the critical analysis, design and technical skills to analyse and communicate with geographic datasets.\nThe course emphasises real-world applications. You will work with both new, large-scale behavioural datasets, as well as more traditional, administrative datasets located within various social science domains: Political Science, Crime Science, Urban and Transport Planning. As well as learning how to use graphics and statistics to explore patterns in these data, implementing recent ideas from data journalism you will learn how to communicate research findings – how to tell stories with data.\n Course Objectives By the end of the course you will\nDescribe, process and combine geographic datasets from a range of sources Design statistical graphics that expose structure in geographic data and that are underpinned by established principles in information visualization and cartography Use modern data science and visualization frameworks to produce coherent data analyses Apply modern statistical techniques for analysing, representing and communicating data and model uncertainty   Resources Primers  Kieran Healy, Data Visualization: A Practical Introduction (Princeton: Princeton University Press, 2018), http://socviz.co/.\n– An engaging read that manages to integrate ggplot2 code with key Information Visualization theory and using real social science datasets.\nFree online (draft version).\n Robin Lovelace, Jakub Nowosad, and Jannes Muenchow, Geocomputation with R (London, UK: CRC Press, 2019), https://geocompr.robinlovelace.net.\n– This book comprehensively introduces spatial data handling in R. It is a great complement to R for Data Science in that it draws on brand new libraries that support tidyverse-style operations on spatial data.\nFree online.\n Hadley Wickham and Garrett Grolemund, R for Data Science: Import, Tidy, Transform, Visualize, and Model Data (Sebastopol, California: O’Reilly Media, 2017), http://r4ds.had.co.nz/.\n– The primer for doing data analysis with R. Wickham and Grolemund present a thesis of the data science workflow and illustrates how R and packages that form the tidyverse support this. It is both accessible and coherent and is highly recommended.\nFree online.\n   Blogs  Flowingdata\n– Nathan Yau, a former statistics PhD from UCLA, has maintained a data vis blog and online training materials for some time. Numerous excellent examples, on the most part implemented in R and ggplot2.\n giCentre\n– World-leading group researching and developing geovisualization. Check out recent work on litvis and elm-vega.\n Multiple Views\n– Blog series by leading visualization researchers and practitioners.\n   Conferences  IEEE VIS\n– The conference at which leading Data Visualization work is published through a special issue of Transactions on Visualization \u0026amp; Computer Graphics.\n OpenVis Conf\n– New, exciting conference (though last one was in 2018!). Presenters are academics and practitioners. Videos of talks from previous conferences are published online. From the 2018 conference, I’d recommend Matt Kay’s on Uncertainty Visualization, Maarten Lambrechts’ Xenographics and Heather Krause’s F-Word.\n    ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en-uk","lastmod":1606644925,"objectID":"e4d5a4a79239f08c6ad0d7cbf1be756c","permalink":"/syllabus/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/syllabus/","section":"","summary":"Overview Course Objectives Resources Primers Blogs Conferences    Overview In modern data analysis, graphics and computational statistics are increasingly used together to explore and identify complex patterns in data and to make and communicate claims under uncertainty. This course will go beyond traditional ideas of charts, graphs, maps (and also statistics!) to equip you with the critical analysis, design and technical skills to analyse and communicate with geographic datasets.","tags":null,"title":"Syllabus","type":"page"}]