<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Course materials | Visualization for Geographic Data Science</title>
    <link>/</link>
      <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    <description>Course materials</description>
    <generator>Wowchemy (https://wowchemy.com)</generator>
    <image>
      <url>/media/vis-for-gds.png</url>
      <title>Course materials</title>
      <link>/</link>
    </image>
    
    <item>
      <title>Visualization for uncertainty analysis</title>
      <link>/class/08-class/</link>
      <pubDate>Tue, 29 Jun 2021 00:00:00 +0000</pubDate>
      <guid>/class/08-class/</guid>
      <description>
&lt;!-- BLOGDOWN-HEAD --&gt;
&lt;link href=&#34;./rmarkdown-libs/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;./rmarkdown-libs/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;
&lt;!-- /BLOGDOWN-HEAD --&gt;


&lt;p&gt;Road safety analysis : &lt;a href=&#34;https://docs.ropensci.org/stats19/&#34; class=&#34;uri&#34;&gt;https://docs.ropensci.org/stats19/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;

&lt;div class=&#34;alert alert-instruction&#34;&gt;
  &lt;div&gt;
    Matt Kay – OpenVis talk
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;div class=&#34;embed-responsive embed-responsive-16by9&#34;&gt;
&lt;iframe class=&#34;embed-responsive-item&#34; src=&#34;https://www.youtube.com/embed/vqzO-9LSoG4&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;
&lt;/iframe&gt;
&lt;/div&gt;
&lt;p&gt;Uncertainty vis book (not written but structure useful) : &lt;a href=&#34;https://mjskay.github.io/uncertainty-vis-book/&#34; class=&#34;uri&#34;&gt;https://mjskay.github.io/uncertainty-vis-book/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Visualization for data storytelling</title>
      <link>/class/09-class/</link>
      <pubDate>Tue, 29 Jun 2021 00:00:00 +0000</pubDate>
      <guid>/class/09-class/</guid>
      <description>
&lt;!-- BLOGDOWN-HEAD --&gt;
&lt;link href=&#34;./rmarkdown-libs/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;./rmarkdown-libs/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;
&lt;!-- /BLOGDOWN-HEAD --&gt;

&lt;h2&gt;Contents&lt;/h2&gt;
&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#concepts&#34;&gt;Concepts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#techniques&#34;&gt;Techniques&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;concepts&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Concepts&lt;/h2&gt;
&lt;p&gt;Introducing this :&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;That in academic visualization there has been a realisation of role of storytelling in visualization. Not a single, optimum solution to any visualization problem that expose the true picture/story – no such formulation exists.&lt;/li&gt;
&lt;li&gt;At same time: statistical literacy, scientific communication and data journalism –&amp;gt; evidence-based society. data is now embedded in most domains, and particularly in the public sphere.&lt;/li&gt;
&lt;li&gt;Storytelling not about making up stories – but constructing evidence-based arguments, with authority and uncertainty. Point at tensions – need to reduce complexity (and uncertainty) can lead to false interpretation.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;From &lt;em&gt;Data Driven Storytelling&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;*We think this movement towards data-driven stories, which is apparent in both the data visualization research community and the professional journalism community, has the potential to form a crucial part of keeping the public informed, a movement sometimes referred to as the democratization of data – the making of data understandable to the general public. This exciting new development in the use of data visualization in media has revealed an emerging professional community in the already complex group of disciplines involved in data visualization. Data visualization has roots in many research fields including perception, computer graphics, design, and human-computer interaction, though only recently has this expanded to include journalism.&lt;/p&gt;
&lt;p&gt;Data journalism
here has also been a growing consciousness that some of today’s most relevant stories are buried in data. This data can be quite hard to understand in its raw formats but can become much more generally accessible when visualized. Journalists have not only begun to use standard data visualizations such as charts and maps in their stories, but are also creating new ones that are tailored to the particular data type and to the message of the story they are writing. Since journalists are now able to easily share interactive data visualizations on the Web, the democratization of data visualization is accelerating with new compelling data visualizations emerging in the media daily…&lt;/p&gt;
&lt;p&gt;By carefully structuring the information and integrating explanation to guide the consumer, journalists help lead readers towards a valid interpretation of the underlying data.
*&lt;/p&gt;
&lt;p&gt;

&lt;div class=&#34;alert alert-instruction&#34;&gt;
  &lt;div&gt;
    Amanda Cox - &lt;a href=&#34;https://www.youtube.com/embed/ha9LA3rYD9g&#34; class=&#34;uri&#34;&gt;&lt;a href=&#34;https://www.youtube.com/embed/ha9LA3rYD9g&#34;&gt;https://www.youtube.com/embed/ha9LA3rYD9g&lt;/a&gt;&lt;/a&gt;
Robert Kosara - &lt;a href=&#34;https://www.youtube.com/watch?v=PMtWFjjVM5E&amp;amp;ab_channel=BocoupLLC&#34; class=&#34;uri&#34;&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=PMtWFjjVM5E&amp;amp;amp;ab_channel=BocoupLLC&#34;&gt;https://www.youtube.com/watch?v=PMtWFjjVM5E&amp;amp;amp;ab_channel=BocoupLLC&lt;/a&gt;&lt;/a&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;Scrollytelling : &lt;a href=&#34;https://medium.com/nightingale/from-storytelling-to-scrollytelling-a-short-introduction-and-beyond-fbda32066964&#34; class=&#34;uri&#34;&gt;https://medium.com/nightingale/from-storytelling-to-scrollytelling-a-short-introduction-and-beyond-fbda32066964&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Storytelling models?&lt;/p&gt;
&lt;p&gt;Storytelling narratives – immigration : &lt;a href=&#34;https://openaccess.city.ac.uk/id/eprint/25322/&#34; class=&#34;uri&#34;&gt;https://openaccess.city.ac.uk/id/eprint/25322/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Not sure about this resource : &lt;a href=&#34;https://datajournalism.com/read/handbook/one/delivering-data/using-visualizations-to-tell-stories&#34; class=&#34;uri&#34;&gt;https://datajournalism.com/read/handbook/one/delivering-data/using-visualizations-to-tell-stories&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Talk: John Burn-Murdoch VIS 2020 on Covid-19 comparison work. Themes – theoretical and cognitive optimal ways of displaying data. No canonical solution exists. And the objectives/purposes are different when communicating. Log-scales (focus on comparison).&lt;/p&gt;
&lt;p&gt;Animated rescaling : &lt;a href=&#34;https://twitter.com/jwoLondon/status/1347208824495726592&#34; class=&#34;uri&#34;&gt;https://twitter.com/jwoLondon/status/1347208824495726592&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Twitter stories (for data vis) : anything on this? examples?&lt;/p&gt;
&lt;p&gt;Practical : avoid legends, make labels intrinsic to vis. Sacrifice data density? Build sequentially towards complexity. Design consistency.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;techniques&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Techniques&lt;/h2&gt;
&lt;p&gt;Covid-19 data – comparing regions?
Stats19 data – cycling in London?&lt;/p&gt;
&lt;!-- Concerns around the _reproducibility crisis_ are not simply a function of transparency in methodology and research design. Rather, they relate to a culture and incentive structure whereby scientific claims are conferred with authority when reported within the (slightly backwards) logic of Null Hypothesis Significance Testing (NHST) and _p-values_. We will cover a little on this in session 7 and 8, but for an accessible read on the phenomenon of _p-hacking_ (with interactive graphic) see [this article](https://fivethirtyeight.com/features/science-isnt-broken/#part1) from the excellent [FiveThirtyEight](http://fivethirtyeight.com) website. Again, the upshot of all this introspection is a rethinking of the way in which Statistics is taught in schools and universities, with greater emphasis on understanding through computational approaches rather than traditional equations, formulas and probability tables. Where does `R` fit within this? Simply put: `R` is far better placed than traditional software tools and point-and-click paradigms for supporting computational approaches to statistics -- with a set of methods and libraries for performing simulations and permutation-based tests. --&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Visualization for model building 2: Expose, estimate, evaluate</title>
      <link>/class/07-class/</link>
      <pubDate>Tue, 22 Jun 2021 00:00:00 +0000</pubDate>
      <guid>/class/07-class/</guid>
      <description>
&lt;!-- BLOGDOWN-HEAD --&gt;
&lt;link href=&#34;./rmarkdown-libs/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;./rmarkdown-libs/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;
&lt;!-- /BLOGDOWN-HEAD --&gt;


&lt;p&gt;Multi-level modelling : &lt;a href=&#34;https://bookdown.org/roback/bookdown-BeyondMLR/&#34; class=&#34;uri&#34;&gt;https://bookdown.org/roback/bookdown-BeyondMLR/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Also : &lt;a href=&#34;http://ljwolf.org/teaching/gds/02-workbook.html&#34; class=&#34;uri&#34;&gt;http://ljwolf.org/teaching/gds/02-workbook.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Introduce Ocam’s Razor on variable selection?&lt;/p&gt;
&lt;p&gt;Partial pooling : &lt;a href=&#34;https://solomonkurz.netlify.app/post/stein-s-paradox-and-what-partial-pooling-can-do-for-you/&#34; class=&#34;uri&#34;&gt;https://solomonkurz.netlify.app/post/stein-s-paradox-and-what-partial-pooling-can-do-for-you/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Visualization for model building 1: Expose, estimate, evaluate</title>
      <link>/class/06-class/</link>
      <pubDate>Tue, 15 Jun 2021 00:00:00 +0000</pubDate>
      <guid>/class/06-class/</guid>
      <description>
&lt;!-- BLOGDOWN-HEAD --&gt;
&lt;link href=&#34;./rmarkdown-libs/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;./rmarkdown-libs/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;
&lt;!-- /BLOGDOWN-HEAD --&gt;


&lt;p&gt;Brexit analysis : &lt;a href=&#34;https://github.com/ropensci/nomisr&#34; class=&#34;uri&#34;&gt;https://github.com/ropensci/nomisr&lt;/a&gt;
Trump analysis : &lt;a href=&#34;https://walker-data.com/tidycensus/&#34; class=&#34;uri&#34;&gt;https://walker-data.com/tidycensus/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Quote from Spiegelhalter? About explanation of variation in context of what remains unexplained&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Models as functions&lt;/li&gt;
&lt;li&gt;Vocabulary: outcome variable (whose variation you are trying to understand), explanatory (other variables that you want to use to explain variation), predicted value (output o the model function – expected outcome conditioing on explanatory variables), residuals (a measure of how far each case is from the predicted value)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Why models and not graphics
* Can reveal patterns that not evident in graphics – in regression framework we can &lt;em&gt;condition&lt;/em&gt; on explanatory variables and talk about the effect of single variables net of others.
* Deal with uncertainty and false discovery – we infer/overinterpet from scatterplots&lt;/p&gt;
&lt;p&gt;Use tidymodels : &lt;a href=&#34;https://cfss.uchicago.edu/notes/start-with-models/&#34; class=&#34;uri&#34;&gt;https://cfss.uchicago.edu/notes/start-with-models/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Visualization for exploratory geospatial data analysis: Containment and connection</title>
      <link>/class/05-class/</link>
      <pubDate>Tue, 08 Jun 2021 00:00:00 +0000</pubDate>
      <guid>/class/05-class/</guid>
      <description>
&lt;!-- BLOGDOWN-HEAD --&gt;
&lt;link href=&#34;./rmarkdown-libs/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;./rmarkdown-libs/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;
&lt;!-- /BLOGDOWN-HEAD --&gt;


&lt;p&gt;OD Census Travel to work data …&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://cran.r-project.org/web/packages/stplanr/vignettes/stplanr-od.html&#34; class=&#34;uri&#34;&gt;https://cran.r-project.org/web/packages/stplanr/vignettes/stplanr-od.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Theory/content element – OD data and how to analyse it (blog post and OD vis paper)&lt;/p&gt;
&lt;p&gt;Containment – geographically arranged small multiples
Connection – lines
Connection – OD maps
Connection – bikes&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introduction: Vis for Geographic Data Science</title>
      <link>/class/01-class/</link>
      <pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate>
      <guid>/class/01-class/</guid>
      <description>
&lt;!-- BLOGDOWN-HEAD --&gt;
&lt;link href=&#34;./rmarkdown-libs/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;./rmarkdown-libs/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;
&lt;!-- /BLOGDOWN-HEAD --&gt;

&lt;h2&gt;Contents&lt;/h2&gt;
&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#session-outcomes&#34;&gt;Session outcomes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#welcome-to-visualization-for-geographic-data-science&#34;&gt;Welcome to &lt;em&gt;Visualization for Geographic Data Science&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#why-vis-for-gds&#34;&gt;Why &lt;em&gt;vis-for-gds&lt;/em&gt;?&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#geographic-data-science&#34;&gt;Geographic Data Science&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#geographic-data-science-and-visualization&#34;&gt;Geographic Data Science and &lt;em&gt;Visualization&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#what-vis-for-gds&#34;&gt;What &lt;em&gt;vis-for-gds&lt;/em&gt;?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#how-vis-for-gds&#34;&gt;How &lt;em&gt;vis-for-gds&lt;/em&gt;?&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#r-for-modern-data-analysis&#34;&gt;R for modern data analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#rmarkdown-for-reproducible-research&#34;&gt;Rmarkdown for reproducible research&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#getting-started-with-r-and-rstudio&#34;&gt;Getting started with R and RStudio&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#install-r-and-rstudio&#34;&gt;Install R and RStudio&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#open-the-rstudio-ide&#34;&gt;Open the RStudio IDE&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#compute-in-the-console&#34;&gt;Compute in the console&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#install-some-packages&#34;&gt;Install some packages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#experiment-with-r-markdown&#34;&gt;Experiment with R Markdown&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#r-scripts&#34;&gt;R Scripts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#create-an-rstudio-project&#34;&gt;Create an RStudio Project&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#conclusions&#34;&gt;Conclusions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#references&#34;&gt;References&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;session-outcomes&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Session outcomes&lt;/h2&gt;
&lt;p&gt;By the end of this session you should gain the following &lt;strong&gt;&lt;em&gt;knowledge&lt;/em&gt;&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;

&lt;div class=&#34;alert alert-objective&#34;&gt;
  &lt;div&gt;
    &lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Appreciate the motivation for this module – why visualization, why R and why ggplot2&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- - [x] An **awareness** of the challenges modern data analysis --&gt;

  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;By the end of this session you should gain the following &lt;strong&gt;&lt;em&gt;practical skills&lt;/em&gt;&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;

&lt;div class=&#34;alert alert-objective&#34;&gt;
  &lt;div&gt;
    &lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Navigate the materials on this course website, having familiarised yourself with its structure&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Open R using the RStudio Integrated Developer Environment (IDE)&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Install and enable R packages and query package documentation&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Perform basic calculations via the R Console&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Render R Markdown files&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Create R Projects&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Read-in datasets from external resources as objects (specifically &lt;code&gt;tibbles&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;

  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;welcome-to-visualization-for-geographic-data-science&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Welcome to &lt;em&gt;Visualization for Geographic Data Science&lt;/em&gt;&lt;/h2&gt;
&lt;p&gt;Welcome to &lt;em&gt;Visualization for Geographic Data Science&lt;/em&gt; (&lt;em&gt;vis-for-gds&lt;/em&gt;). In this first session we’ll cover the background to the module – the why, what and how of &lt;em&gt;&lt;strong&gt;vis&lt;/strong&gt;-for-gds&lt;/em&gt;. If you’ve not already you should check out the course outline on the &lt;a href=&#34;./syllabus/&#34;&gt;Syllabus&lt;/a&gt; page for an overall preview of the module.&lt;/p&gt;
&lt;p&gt;The main home for this module is &lt;a href=&#34;../../&#34;&gt;this website&lt;/a&gt;. However, via &lt;a href=&#34;&#34;&gt;Minerva&lt;/a&gt; you can access the &lt;a href=&#34;&#34;&gt;Module Handbook&lt;/a&gt;. You will use submission boxes in &lt;a href=&#34;&#34;&gt;Minerva&lt;/a&gt; to upload coursework in the usual way.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;why-vis-for-gds&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Why &lt;em&gt;vis-for-gds&lt;/em&gt;?&lt;/h2&gt;
&lt;!-- https://www.forbes.com/sites/bernardmarr/2020/04/09/the-vital-role-of-big-data-in-the-fight-against-coronavirus/ --&gt;
&lt;div id=&#34;geographic-data-science&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Geographic Data Science&lt;/h3&gt;
&lt;p&gt;It is now taken-for-granted that over the last decade or so new data, new technology and new ways of doing science have transformed how we approach the world’s problems. Evidence for this can be seen in the response to the Covid-19 pandemic. Enter &lt;a href=&#34;https://www.google.com/search?q=covid-19+github&amp;amp;rlz=1C5CHFA_enGB632GB632&amp;amp;oq=covid-19+github&amp;amp;aqs=chrome..69i57j69i60l3.5575j0j1&amp;amp;sourceid=chrome&amp;amp;ie=UTF-8&#34;&gt;Covid19 github&lt;/a&gt; into a search and you’ll be confronted with hundreds of repositories demonstrating how an ever-expanding array of data related to the pandemic can be collected, processed and analysed. &lt;em&gt;Data Science&lt;/em&gt; is a term used widely to capture this shift and &lt;em&gt;Geographic Data Science&lt;/em&gt; (GDS), probably first discussed coherently by &lt;span class=&#34;citation&#34;&gt;Arribas-Bel and Reades (&lt;a href=&#34;#ref-arribas_geography_2018&#34; role=&#34;doc-biblioref&#34;&gt;2018&lt;/a&gt;)&lt;/span&gt; and &lt;span class=&#34;citation&#34;&gt;Singleton and Arribas-Bel (&lt;a href=&#34;#ref-singleton_geographic_2019&#34; role=&#34;doc-biblioref&#34;&gt;2019&lt;/a&gt;)&lt;/span&gt;, when observing that many of data science’s applications are – or at least should be – of inherent interest to geographers.&lt;/p&gt;
&lt;p&gt;Since gaining traction in the corporate world, the definition of Data Science has been somewhat stretched, but it has its origins in the work of John Tukey’s &lt;em&gt;The Future of Data Analysis&lt;/em&gt; (1962). Drawing on this, and a survey of more recent work, &lt;span class=&#34;citation&#34;&gt;Donoho (&lt;a href=&#34;#ref-donoho_fifty_2017&#34; role=&#34;doc-biblioref&#34;&gt;2017&lt;/a&gt;)&lt;/span&gt; neatly identify six key facets that a data science discipline might encompass&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; :&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;data gathering, preparation, and exploration;&lt;/li&gt;
&lt;li&gt;data representation and transformation;&lt;/li&gt;
&lt;li&gt;computing with data;&lt;/li&gt;
&lt;li&gt;data visualization and presentation;&lt;/li&gt;
&lt;li&gt;data modelling;&lt;/li&gt;
&lt;li&gt;and a more introspective “science about data science”&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;geographic-data-science-and-visualization&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Geographic Data Science and &lt;em&gt;Visualization&lt;/em&gt;&lt;/h3&gt;
&lt;!-- &gt; Visualization is fundamental to meeting the unprecedented challenges and exploiting the wonderful opportunities of the ever-expanding deluge of data confronting virtually every field.&#34; \
&gt; -- Prof. Jim Hollan of UC San Diego --&gt;
&lt;!-- 

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Visual approaches to data analysis are particularly suited to Geographic Data Science applications because where datasets are being repurposed for social and natural sciences research for the first time,  contain complex structure and geo-spatial relations that cannot be easily captured by statistical summaries alone and so where the types of questions that can be asked and the techniques deployed to answer them cannot be easily specified in advance.
  &lt;/div&gt;
&lt;/div&gt;
 --&gt;
&lt;p&gt;Glancing at this list, &lt;em&gt;visualization&lt;/em&gt; could be interpreted as a single facet of Data Science process&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; – something that happens after data gathering, preparation, exploration, but before modelling. In this module you’ll learn that visualization is intrinsic to, and should inform, each of these activities, especially so when working with data sets that are spatial – for Geographic Data Science.&lt;/p&gt;
&lt;p&gt;Let’s develop this idea by asking &lt;strong&gt;why data visualizations are used in the first place&lt;/strong&gt;. In her book &lt;em&gt;Visualization Analysis and Design&lt;/em&gt;, Tamara &lt;span class=&#34;citation&#34;&gt;(&lt;span class=&#34;citeproc-not-found&#34; data-reference-id=&#34;munzer_visualization_2014&#34;&gt;&lt;strong&gt;???&lt;/strong&gt;&lt;/span&gt;)&lt;/span&gt; considers how humans and computers interface in the decision-making process. She makes the point that data visualization is ultimately about connecting people with data in order to make decisions – or to install humans in a ‘decision-making-loop’. There are occasionally decision-making loops that are entirely computational and where an automated solution exists and is trusted. However, most require some form of human intervention.&lt;/p&gt;
&lt;p&gt;The canonical example demonstrating how relying on computation alone can be problematic, and so for the use of visualization, is &lt;a href=&#34;https://en.wikipedia.org/wiki/Anscombe%27s_quartet&#34;&gt;Anscombe’s quartet&lt;/a&gt;. Here, &lt;span class=&#34;citation&#34;&gt;Anscombe (&lt;a href=&#34;#ref-anscombe_graphs_1973&#34; role=&#34;doc-biblioref&#34;&gt;1973&lt;/a&gt;)&lt;/span&gt; presents four datasets, each containing eleven observations and two variables for each observation. The data are synthetic, but let’s say that they are the weight and height of independent samples taken from a population of Postgraduate Students studying Data Science.&lt;/p&gt;
&lt;p&gt;Presented with a new dataset it makes sense to compute some summaries and doing so, we observe that the data appear identical – they contain the same means, variances and strong positive correlation coefficient. This seems appropriate since the data are measuring weight and height. Although there may be some variation, we’d expect taller students to be heavier. Given these statical summaries we can be confident that we are drawing samples from the same population of (Data Science) students.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:anscombe-data&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;./class/01-class_files/anscombe_data.png&#34; alt=&#34;Data from Anscombe&#39;s quartet&#34; width=&#34;90%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: Data from Anscombe’s quartet
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Laying out the data in a meaningful way, horizontally according to &lt;em&gt;weight&lt;/em&gt; (&lt;em&gt;x&lt;/em&gt;) and vertically according to the &lt;em&gt;height&lt;/em&gt; (&lt;em&gt;y&lt;/em&gt;) to form a scatterplot, we quickly see that whilst these data contain the same statistical properties they are very different. Only &lt;code&gt;dataset #1&lt;/code&gt; now looks plausible if it were truly a measure of weights and heights drawn from a population of students.&lt;/p&gt;
&lt;p&gt;Anscombe’s is a deliberately contrived example&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;, but there are real cases of important structure being missed, leading to poorly specified models and potentially faulty claims.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:anscombe-plot&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;./class/01-class_files/anscombe.png&#34; alt=&#34;Plots of Anscombe&#39;s quartet&#34;  /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 2: Plots of Anscombe’s quartet
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;This is not to undermine the importance of numerical analysis. Numeric summaries that simplify patterns are extremely useful and Statistics has at its disposal an array of tools for helping to guard against making false claims from datasets – a theme that we will return to in session 6, 7 and 8 when we think critically about the use of visual approaches for data anlysis. There remain, though, certain classes of relation and context that cannot be easily captured through statistics alone.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Geographic&lt;/em&gt; context is undoubtedly challenging to capture numerically; many of the early examples of data visualization have been of spatial phenomena and generated by Geographers &lt;span class=&#34;citation&#34;&gt;(see Friendly &lt;a href=&#34;#ref-friendly_brief_2007&#34; role=&#34;doc-biblioref&#34;&gt;2007&lt;/a&gt;)&lt;/span&gt;. We can also probably make a special case for the use of visual approaches in Geographic Data Science (GDS) applications due to its exploratory nature. Often in GDS datasets are being repurposed for social and natural sciences research for the first time; contain complex structure and geo-spatial relations that cannot be easily captured by statistical summaries alone; and so the types of questions that can be asked and the techniques deployed to answer them cannot be easily specified in advance. In this module we will demonstrate this as we &lt;em&gt;explore&lt;/em&gt; (Session 4 and 5), &lt;em&gt;model under uncertainty&lt;/em&gt; (Session 6 and 7) and &lt;em&gt;communicate&lt;/em&gt; (Session 7 and 8) with various social science datasets.&lt;/p&gt;
&lt;p&gt;

&lt;div class=&#34;alert alert-instruction&#34;&gt;
  &lt;div&gt;
    Watch &lt;a href=&#34;https://www.gicentre.net/jwo/index&#34;&gt;Jo Wood’s&lt;/a&gt; talk demonstrating how visual techniques can be used to analyse urban travel behaviours. In the video Jo argues that bikeshare schemes can help democratise cycling, but also for their potential contributions to research – he briefly contrasts new, passively collected data sets with more “traditional” actively collected data for analysing how people move around cities. A compelling case is then made for the use of visualization to support this activity. This work and further discussion is published in &lt;span class=&#34;citation&#34;&gt;Beecham and Wood (&lt;a href=&#34;#ref-beecham_exploring_2014&#34; role=&#34;doc-biblioref&#34;&gt;2014&lt;/a&gt;)&lt;/span&gt;.
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;div class=&#34;embed-responsive embed-responsive-16by9&#34;&gt;
&lt;iframe class=&#34;embed-responsive-item&#34; src=&#34;https://www.youtube.com/embed/FaRBUnO5PZI&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;
&lt;/iframe&gt;
&lt;/div&gt;
&lt;!-- &gt; Effective data visualizations should expose structure in data that would be difficult to expose through non-visual means --&gt;
&lt;!-- Problems are typically ill-specified, the relevant data/information informing the problem are not immediately obvious and analysis procedures and their interpretation are certainly subject to interpretation.

 &#39;computer in the loop&#39; and the &#39;human in the loop&#39;. In other words, what is it that computation can offer in supporting decision making and what is it that humans can offer. --&gt;
&lt;!-- @donoho_fifty_2017 neatly remarks that _data science_ probably has its origins in the work of John Tukey&#39;s _The Future of Data Analysis_ (1962), and that a _data science_ discipline might incorporate six key facets: data gathering, preparation, and exploration; data representation and transformation; computing with data; data modelling; data visualisation and presentation; and a more introspective “science about data science”. --&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;what-vis-for-gds&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What &lt;em&gt;vis-for-gds&lt;/em&gt;?&lt;/h2&gt;
&lt;p&gt;This is a very practical module. With the exception of this Introduction, the weekly sessions will blend both theory and practical coding activity. We will cover fundamentals around visual data analysis from Information Visualization and Statistics. As you read the session materials you will be writing data processing and analysis code and so be generating analysis outputs of your own. We will also be working with real datasets – from the Political Science, Urban and Transport Planning and Health domains. So we will hopefully be generating real findings and knowledge.&lt;/p&gt;
&lt;p&gt;To do this in a genuine way – to generate real knowledge from datasets – we will have to cover a reasonably broad set of data processing and analysis procedures. As well as developing expertise around designing data-rich, visually compelling graphics (of the sort demonstrated in &lt;a href=&#34;https://www.gicentre.net/jwo/index&#34;&gt;Jo Wood’s TEDx talk&lt;/a&gt;), we will need to cover more tedious aspects of &lt;strong&gt;data processing&lt;/strong&gt; and &lt;strong&gt;wrangling&lt;/strong&gt;. Additionally, if we are to learn how to generate and communicate and make claims under uncertainty with our data graphics, then we will need to cover some aspects of estimation and modelling from Statistics. In short, we will cover most of &lt;span class=&#34;citation&#34;&gt;Donoho (&lt;a href=&#34;#ref-donoho_fifty_2017&#34; role=&#34;doc-biblioref&#34;&gt;2017&lt;/a&gt;)&lt;/span&gt;’s six key facets of a data science discipline:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;data gathering, preparation, and exploration (Sessions 2, 3, 5);&lt;/li&gt;
&lt;li&gt;data representation and transformation (Sessions 2, 3);&lt;/li&gt;
&lt;li&gt;computing with data (Session 2);&lt;/li&gt;
&lt;li&gt;data visualization and presentation (All Sessions);&lt;/li&gt;
&lt;li&gt;data modelling (Sessions 6, 7, 8);&lt;/li&gt;
&lt;li&gt;and a more introspective “science about data science” (All Sessions, Plus Optional Extra)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;There is already a rich and impressive set of open &lt;a href=&#34;../useful&#34;&gt;Resources&lt;/a&gt; practically introducing how to do modern &lt;a href=&#34;https://r4ds.had.co.nz/index.html&#34;&gt;Data Science&lt;/a&gt;, &lt;a href=&#34;https://socviz.co/&#34;&gt;Visualization&lt;/a&gt; and &lt;a href=&#34;https://geocompr.robinlovelace.net/&#34;&gt;Geographic Analysis&lt;/a&gt;. We will certainly draw on these at different stages in the module. What makes this module different from these existing resources is that we will be &lt;strong&gt;doing&lt;/strong&gt; applied data science throughout – we will be identifying and diagnosing problems when gathering data, discovering patterns (some maybe even spurious) as we do exploratory analysis, and attempt to make claims under uncertainty as we generate models based on observed patterns. We will work with both new, passively-collected datasets, as well as more traditional, actively collected datasets located within various social science domains: Political Science, Health Science and Urban and Transport Planning.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-vis-for-gds&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;How &lt;em&gt;vis-for-gds&lt;/em&gt;?&lt;/h2&gt;
&lt;div id=&#34;r-for-modern-data-analysis&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;R for modern data analysis&lt;/h3&gt;
&lt;p&gt;Through the module we will apply modern approaches to data analysis. All data collection, analysis and reporting activity will be completed using &lt;a href=&#34;https://www.r-project.org/&#34;&gt;&lt;code&gt;R&lt;/code&gt;&lt;/a&gt; and the &lt;a href=&#34;https://rstudio.com/&#34;&gt;&lt;code&gt;RStudio&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://en.wikipedia.org/wiki/Integrated_development_environment&#34;&gt;Integrated Development Environment&lt;/a&gt; (IDE). Released as open source software as part of a research project in 1995, for some time &lt;code&gt;R&lt;/code&gt; was the preserve of academics. From 2010s onwards, the &lt;code&gt;R&lt;/code&gt; community expanded rapidly and along with &lt;a href=&#34;https://www.python.org/&#34;&gt;&lt;code&gt;Python&lt;/code&gt;&lt;/a&gt; is regarded as the key technology for doing data analysis. &lt;code&gt;R&lt;/code&gt; is used increasingly outside of academia, by organisations such as Google &lt;a href=&#34;https://research.google.com/pubs/pub37483.html&#34;&gt;[example]&lt;/a&gt;, Facebook &lt;a href=&#34;http://flowingdata.com/2010/12/13/facebook-worldwide-friendships-mapped/&#34;&gt;[example]&lt;/a&gt;, Twitter &lt;a href=&#34;https://blog.twitter.com/official/en_us/a/2013/the-geography-of-tweets.html&#34;&gt;[example]&lt;/a&gt;, New York Times &lt;a href=&#34;http://www.nytimes.com/interactive/2012/05/05/sports/baseball/mariano-rivera-and-his-peers.html?ref=baseballexample&#34;&gt;[example]&lt;/a&gt;, BBC &lt;a href=&#34;https://bbc.github.io/rcookbook/&#34;&gt;[example]&lt;/a&gt; and many more.&lt;/p&gt;
&lt;p&gt;There are many benefits that come from being fully open-source, with a critical mass of users. Firstly, there is an array of online forums, tutorials and code examples from which to learn. Second, with such a large community, there are numerous expert &lt;code&gt;R&lt;/code&gt; users who themselves contribute by developing &lt;strong&gt;libraries&lt;/strong&gt; or &lt;strong&gt;packages&lt;/strong&gt; that extend its use. As a result &lt;code&gt;R&lt;/code&gt; is employed for a very wide set of use cases – this website was even built in &lt;code&gt;R&lt;/code&gt; using amongst other things the &lt;a href=&#34;https://bookdown.org/yihui/blogdown/&#34;&gt;&lt;code&gt;blogdown&lt;/code&gt;&lt;/a&gt; package.&lt;/p&gt;
&lt;p&gt;

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    The key reason for our use of &lt;code&gt;R&lt;/code&gt; is the ecosystem of users and &lt;strong&gt;packages&lt;/strong&gt; that have emerged in recent years. An R package is a bundle of code, data and documentation, usually hosted on the &lt;a href=&#34;https://cran.r-project.org/&#34;&gt;CRAN&lt;/a&gt; (Comprehensive R Archive Network).
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;Of particular importance is the &lt;a href=&#34;http://www.tidyverse.org&#34;&gt;&lt;code&gt;tidyverse&lt;/code&gt;&lt;/a&gt; package. This is a set of packages for doing Data Science authored by a software development team at &lt;a href=&#34;https://rstudio.com/&#34;&gt;RStudio&lt;/a&gt; led by &lt;a href=&#34;http://hadley.nz&#34;&gt;Hadley Wickham&lt;/a&gt;. &lt;code&gt;tidyverse&lt;/code&gt; packages share a principled underlying philosophy, syntax and documentation. Contained within the &lt;code&gt;tidyverse&lt;/code&gt; is its data visualization package, &lt;a href=&#34;https://ggplot2.tidyverse.org/&#34;&gt;&lt;code&gt;ggplot2&lt;/code&gt;&lt;/a&gt;. This package pre-dates the &lt;code&gt;tidyverse&lt;/code&gt; – it started as &lt;a href=&#34;http://had.co.nz/thesis/practical-tools-hadley-wickham.pdf&#34;&gt;Hadley Wickham’s PhD thesis&lt;/a&gt; and is one of the most widely-used toolkits for generating data graphics. As with other heavily used visualization toolkits (&lt;a href=&#34;https://www.tableau.com/en-gb&#34;&gt;&lt;code&gt;Tableau&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://vega.github.io/vega-lite/&#34;&gt;&lt;code&gt;vega-lite&lt;/code&gt;&lt;/a&gt;) it is inspired by Leland Wilkinson’s &lt;a href=&#34;https://www.springer.com/gp/book/9780387245447&#34;&gt;The Grammar of Graphics&lt;/a&gt;, the &lt;code&gt;gg&lt;/code&gt; in &lt;code&gt;ggplot&lt;/code&gt; stands for Grammar of Graphics. Understanding the design principles behind the &lt;em&gt;Grammar of Graphics&lt;/em&gt; (and &lt;code&gt;tidyverse&lt;/code&gt;) is necessary for modern data analysis and so we will cover this in Sessions 2 and 3, as well as re-visiting later in the module.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;rmarkdown-for-reproducible-research&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Rmarkdown for reproducible research&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Reproducible research is the idea that data analyses, and more generally, scientific claims, are published with their data and software code so that others may verify the findings and build upon them.&lt;/p&gt;
&lt;p&gt;Roger Peng, Jeff Leek and Brian Caffo&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In recent years there has been much introspection around how science works – around how statistical claims are made from reasoning over evidence. This came on the back of, amongst other things, a high profile paper published in &lt;a href=&#34;http://science.sciencemag.org/content/349/6251/aac4716&#34;&gt;Science&lt;/a&gt;, which found that of 100 recent peer-reviewed psychology experiments, the findings of only 39 could be replicated. The upshot is that researchers must now make every possible effort to make their work transparent, such that “&lt;em&gt;all&lt;/em&gt; aspects of the answer generated by any given analysis [can] be tested” &lt;span class=&#34;citation&#34;&gt;(Brunsdon and Comber &lt;a href=&#34;#ref-brunsdon_opening_2020&#34; role=&#34;doc-biblioref&#34;&gt;2020&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;A reproducible research project should be accompanied with:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;code&lt;/em&gt; and &lt;em&gt;data&lt;/em&gt; that allows tables and figures presented in research outputs to be regenerated&lt;/li&gt;
&lt;li&gt;&lt;em&gt;code&lt;/em&gt; and &lt;em&gt;data&lt;/em&gt; that &lt;em&gt;does&lt;/em&gt; what it &lt;em&gt;claims&lt;/em&gt; (the code works)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;code&lt;/em&gt; and &lt;em&gt;data&lt;/em&gt; that can be justified and explained through proper documentation&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If these goals are met, then it may be possible for others to use the code on new and different data to study whether the findings reported in one project might be &lt;strong&gt;replicated&lt;/strong&gt; or to use the same data, but update the code to, for example, extend the original analysis (to perform a re-analysis). This model – generate findings, test for replicability in new contexts and re-analysis – is essentially how knowledge development has always worked. However, to achieve this the data and procedures on which findings were generated must be made open and transparent.&lt;/p&gt;
&lt;p&gt;In this setting, traditional proprietary data analysis software such as SPSS and Esri’s ArcGIS that support point-and-click interaction is problematic. First, whilst these software may rely on the sorts of packages and libraries with bundled code that &lt;code&gt;R&lt;/code&gt; and &lt;code&gt;Python&lt;/code&gt; uses for implementing statistical procedures, those libraries are closed. It is not possible, and therefore less common, for the researcher to fully interrogate into the underlying processes that are being implemented and the results need to be taken more or less on faith. Second, but probably most significantly (for us), it would be tedious to make notes describing all interactions performed when working with a dataset in SPSS or ArcGIS.&lt;/p&gt;
&lt;p&gt;As a declarative programming language, it is very easy to provide such a provenance trail for your workflows in &lt;code&gt;R&lt;/code&gt; since this necessarily exists in the analysis scripts. But more importantly, the &lt;a href=&#34;https://en.wikipedia.org/wiki/Integrated_development_environment&#34;&gt;Integrated Development Environments&lt;/a&gt; (IDEs) through which &lt;code&gt;R&lt;/code&gt; (and &lt;code&gt;Python&lt;/code&gt;) are most often accessed provide notebook environments that allow users to curate reproducible computational documents that blend &lt;strong&gt;input code&lt;/strong&gt;, &lt;strong&gt;explanatory prose&lt;/strong&gt; and &lt;strong&gt;outputs&lt;/strong&gt;. In this module we will prepare these sorts of notebooks using &lt;a href=&#34;https://rmarkdown.rstudio.com/&#34;&gt;R Markdown&lt;/a&gt;.&lt;/p&gt;
&lt;!-- Within Spatial Statistics, results from a Geographically Weighted Regression analysis implemented in ArcGIS were found to be inconsistent with those generated in `R` and `Python` [] -- inconsistencies that could not be examined as the code behind ArcGIS is closed. --&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;getting-started-with-r-and-rstudio&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Getting started with R and RStudio&lt;/h2&gt;
&lt;p&gt;I mentioned that the weekly sessions will blend both theory and practical coding activity. This Introduction has been dedicated more towards conceptual and procedural matters. For the practical element this time, we want to get you configured and familiar with &lt;code&gt;R&lt;/code&gt; and RStudio.&lt;/p&gt;
&lt;div id=&#34;install-r-and-rstudio&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Install R and RStudio&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Install the latest version of &lt;a href=&#34;https://cloud.r-project.org/&#34;&gt;R&lt;/a&gt;. Note that there are installations for &lt;a href=&#34;https://cloud.r-project.org/bin/windows/&#34;&gt;Windows&lt;/a&gt;, &lt;a href=&#34;https://cloud.r-project.org/&#34;&gt;macOS&lt;/a&gt; and &lt;a href=&#34;https://cloud.r-project.org/&#34;&gt;Linux&lt;/a&gt;. Run the installation from the file you downloaded (an &lt;code&gt;.exe&lt;/code&gt; or &lt;code&gt;.pkg&lt;/code&gt; extension).&lt;/li&gt;
&lt;li&gt;Install the latest version of &lt;a href=&#34;https://rstudio.com/products/rstudio/download/#download&#34;&gt;RStudio Desktop&lt;/a&gt;. Note again that there are separate installations depedning on operating system – for Windows an &lt;code&gt;.exe&lt;/code&gt; extension, macOS a &lt;code&gt;.dmg&lt;/code&gt; extension.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;open-the-rstudio-ide&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Open the RStudio IDE&lt;/h3&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:rstudio-annotate&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;./class/01-class_files/rstudio_annotate.png&#34; alt=&#34;The RStudio IDE&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 3: The RStudio IDE
&lt;/p&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Once installed, open the RStudio IDE.&lt;/li&gt;
&lt;li&gt;Open an R Script by clicking &lt;code&gt;File&lt;/code&gt; &amp;gt; &lt;code&gt;New File&lt;/code&gt; &amp;gt; &lt;code&gt;R Script&lt;/code&gt; .&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You should see a set of windows roughly similar to those in the Figure (although I’ve already started on some of the computing exercises in the next section). The top left pane is used either as a &lt;em&gt;Code Editor&lt;/em&gt; (the tab named &lt;code&gt;Untitled1&lt;/code&gt;) or data viewer. This is where you’ll write, organise and comment R code for execution or inspect datasets as a spreadsheet representation. Below this in the bottom left pane is the R Console, in which you write and execute commands directly. To the top right is a pane with the tabs Environment and History. This displays all objects – data and plot items, calculated functions – stored in-memory during an R session. In the bottom right is a pane for navigating through project directories, displaying plots, details of installed and loaded packages and documentation on their functions.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;compute-in-the-console&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Compute in the console&lt;/h3&gt;
&lt;p&gt;You will write and execute almost all code from the code editor pane. To start though let’s use &lt;code&gt;R&lt;/code&gt; as a calculator by typing some commands into the Console. You’ll create an object (&lt;code&gt;x&lt;/code&gt;) and assign it a value using the assignment operator (&lt;code&gt;&amp;lt;-&lt;/code&gt;), then perform some simple statistical calculations using functions that are held within the &lt;code&gt;base&lt;/code&gt; package.&lt;/p&gt;
&lt;p&gt;

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    The &lt;code&gt;base&lt;/code&gt; package is core and native to &lt;code&gt;R&lt;/code&gt;. Unlike all other packages, it does not need to be installed and called explicitly. One means of checking the package to which a function you are using belongs is to call the help command (&lt;code&gt;?&lt;/code&gt;) on that function: e.g. &lt;code&gt;?mean()&lt;/code&gt;.
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Type the commands contained in the code block below into your R Console. Notice that since you are assigning values to each of these objects they are stored in memory and appear under the Global Environment pane.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Create variable and assign a value.
x &amp;lt;- 4
# Perform some calculations using R as a calculator.
x_2 &amp;lt;- x^2
# Perform some calculations using functions that form baseR.
x_root &amp;lt;- sqrt(x_2)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;install-some-packages&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Install some packages&lt;/h3&gt;
&lt;p&gt;There are two steps to getting packages down and available in your working environment:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;code&gt;install.packages(&amp;lt;package-name&amp;gt;)&lt;/code&gt; downloads the named package from a repository.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;library(&amp;lt;package-name&amp;gt;)&lt;/code&gt; makes the package available in your current session.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Install the &lt;code&gt;tidyverse&lt;/code&gt;, the core collection of packages for doing Data Science in &lt;code&gt;R&lt;/code&gt;, by running the code below:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;install.packages(&amp;quot;tidyverse&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you have little or no experience in &lt;code&gt;R&lt;/code&gt;, it is easy to get confused around downloading and then using packages in a session. For example, let’s say we want to make use of the simple features package (&lt;a href=&#34;https://r-spatial.github.io/sf/index.html&#34;&gt;&lt;code&gt;sf&lt;/code&gt;&lt;/a&gt;), which we will drawn on heavily in the module for performing spatial operations.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Run the code below:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(sf)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Unless you’ve previously installed &lt;code&gt;sf&lt;/code&gt;, you’ll probably get an error message that looks like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; Error in library(sf): there is no package called ‘sf’&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So let’s install it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Run the code below:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;install.packages(&amp;quot;sf&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And now it’s installed, why not bring up some documentation on one of its functions (&lt;a href=&#34;https://r-spatial.github.io/sf/reference/geos_binary_pred.html&#34;&gt;&lt;code&gt;st_contains()&lt;/code&gt;&lt;/a&gt;).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Run the code below:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;?st_contains()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Since you’ve downloaded the package but not made it available to your session, you should get the message:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; No documentation for ‘st_contains’ in specified packages and libraries&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So let’s try again, by first calling &lt;code&gt;library(sf)&lt;/code&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Run the code below:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(sf)
## Linking to GEOS 3.7.2, GDAL 2.4.1, PROJ 6.1.0
?st_contains()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let’s install some of the remaining core packages on which the module depends.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Run the block below, which passes a &lt;a href=&#34;https://r4ds.had.co.nz/vectors.html&#34;&gt;vector&lt;/a&gt; of package names to the &lt;code&gt;install.packages()&lt;/code&gt; function:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;install.packages(c(&amp;quot;devtools&amp;quot;,&amp;quot;usethis&amp;quot;, &amp;quot;rmarkdown&amp;quot;, &amp;quot;knitr&amp;quot;,&amp;quot;fst&amp;quot;,
&amp;quot;lubridate&amp;quot;, &amp;quot;tidymodels&amp;quot;, &amp;quot;rmapshaper&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    If you wanted to make use of a package only very occasionally in a single session, you could access it without explicitly loading it via &lt;code&gt;library(&amp;lt;package-name&amp;gt;)&lt;/code&gt;, using this syntax: &lt;code&gt;&amp;lt;package-name&amp;gt;::&amp;lt;function_name&amp;gt;&lt;/code&gt;, e.g. &lt;code&gt;?sf::st_contains()&lt;/code&gt;.
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;experiment-with-r-markdown&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Experiment with R Markdown&lt;/h3&gt;
&lt;p&gt;R Markdown documents are suffixed with the extension &lt;code&gt;.Rmd&lt;/code&gt; and based partly on &lt;a href=&#34;https://en.wikipedia.org/wiki/Markdown&#34;&gt;Markdown&lt;/a&gt;, a lightweight markup language originally used as a means of minimising tedious mark-up tags (&lt;code&gt;&amp;lt;header&amp;gt;&amp;lt;/header&amp;gt;&lt;/code&gt;) when preparing HTML documents. The idea is that you trade some flexibility in the formatting of your HTML for ease-of-writing. Working with R Markdown is very similar to Markdown. Sections are denoted hierarchically with hashes (&lt;code&gt;#&lt;/code&gt;, &lt;code&gt;##&lt;/code&gt;, &lt;code&gt;###&lt;/code&gt;) and emphasis using &lt;code&gt;*&lt;/code&gt; symbols (&lt;code&gt;*emphasis* **added**&lt;/code&gt; reads &lt;em&gt;emphasis&lt;/em&gt; &lt;strong&gt;added&lt;/strong&gt; ). Different from standard Markdown, however, R Markdown documents can also contain code chunks that can be run when the document is typeset – they are a mechanism for producing elegant reproducible notebooks.&lt;/p&gt;
&lt;p&gt;Each session of the module has an accompanying R Markdown file. in later sessions you will use these to author computational notebooks that blend code, analysis prose and outputs.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Download the &lt;a href=&#34;./homework/01-homework_files/01-template.Rmd&#34;&gt;&lt;i class=&#34;fab fa-r-project&#34;&gt;&lt;/i&gt; 01-template.Rmd&lt;/a&gt; file for this session and open it in RStudio by clicking &lt;code&gt;File&lt;/code&gt; &amp;gt; &lt;code&gt;Open File ...&lt;/code&gt; &amp;gt; &lt;code&gt;&amp;lt;your-downloads&amp;gt;/01-template.Rmd&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A quick anatomy of an R Markdown files :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/YAML&#34;&gt;YAML&lt;/a&gt; - positioned at the head of the document and contains metadata determining amongst other things the author details and the output format when typesetting.&lt;/li&gt;
&lt;li&gt;TEXT - incorporated throughout to document and comment on your analysis.&lt;/li&gt;
&lt;li&gt;CODE chunks - containing discrete that are to be run when the .Rmd file is typeset or &lt;em&gt;knit&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:rmarkdown-annotate&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;./class/01-class_files/rmarkdown_annotate.png&#34; alt=&#34;The anatomy of R Markdown&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 4: The anatomy of R Markdown
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The &lt;a href=&#34;https://en.wikipedia.org/wiki/YAML&#34;&gt;YAML&lt;/a&gt; section of an &lt;code&gt;.Rmd&lt;/code&gt; file controls how your file is typeset and consists of &lt;code&gt;key: value&lt;/code&gt; pairs enclosed by &lt;code&gt;---&lt;/code&gt;. Notice that you can change the output format – so should you wish you can generate for example &lt;code&gt;.pdf&lt;/code&gt;, &lt;code&gt;.docx&lt;/code&gt; files for your reports.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;---
author: &amp;quot;Roger Beecham&amp;quot;
date: &amp;#39;2021-05-01&amp;#39;
title: &amp;quot;Session 01&amp;quot;
output:html_document
---&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;R Markdown files are rendered or typeset with the &lt;strong&gt;Knit&lt;/strong&gt; button, annotated in the Figure above. This starts the &lt;code&gt;knitr&lt;/code&gt; package and executes all the code chunks and outputs a &lt;strong&gt;markdown&lt;/strong&gt; (&lt;code&gt;.md&lt;/code&gt;) file. The markdown file can then be converted to many different output formats via &lt;a href=&#34;https://pandoc.org/&#34;&gt;pandoc&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Knit&lt;/strong&gt; the &lt;a href=&#34;./homework/01-homework_files/01-template.Rmd&#34;&gt;&lt;i class=&#34;fab fa-r-project&#34;&gt;&lt;/i&gt; 01-template.Rmd&lt;/a&gt; file for this session, either by clicking the &lt;em&gt;Knit&lt;/em&gt; button or by typing &lt;kbd&gt;ctrl&lt;/kbd&gt; + &lt;kbd&gt;⇧&lt;/kbd&gt; + &lt;kbd&gt;K&lt;/kbd&gt; on Windows, &lt;kbd&gt;⌘&lt;/kbd&gt; + &lt;kbd&gt;⇧&lt;/kbd&gt; + &lt;kbd&gt;K&lt;/kbd&gt; on macOS.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You will notice that R Markdown &lt;strong&gt;code chunks&lt;/strong&gt; can be customised in different ways. This is achieved by populating fields in the curly brackets at the start of the code chunk:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```{r &amp;lt;chunk-name&amp;gt;, echo=TRUE, eval=FALSE, cache=FALSE}
  # Some code that is either run or rendered.
```&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A quick overview of the parameters.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;chunk-name&amp;gt;&lt;/code&gt; - Chunks can be given distinct names. This is useful for navigating R markdown file. It also supports chaching – chunks with distinct names are only run once, important if certain chunks take some time to execute.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;echo=&amp;lt;TRUE|FALSE&amp;gt;&lt;/code&gt; - Determines whether the code is visible or hidden from the typeset file. If you output file is a data analysis report you may not wish to expose lengthy code chunks as these may disrupt the discursive text that appears outside of the code chunks.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;eval=&amp;lt;TRUE|FALSE&amp;gt;&lt;/code&gt; - Determines whether the code is evaluated (executed). This is useful if you wish to present some code in your document for display purposes.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cache=&amp;lt;TRUE|FALSE&amp;gt;&lt;/code&gt; - Determines where the results from the code chunk are cached.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As part of the &lt;a href=&#34;./homework/&#34;&gt;homework&lt;/a&gt; from this session you will do some more research on R Markdown. It is worth in advance downloading RStudio’s cheatsheets, which provide comprehensive details on how to configure R Markdown documents:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Open RStudio and select &lt;code&gt;Help&lt;/code&gt; &amp;gt; &lt;code&gt;Cheatsheets&lt;/code&gt; &amp;gt; &lt;code&gt;R Markdown Cheat Sheet&lt;/code&gt; | &lt;code&gt;R Markdown Reference Guide&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;r-scripts&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;R Scripts&lt;/h3&gt;
&lt;p&gt;Whilst there are obvious benefits to working in R Markdown documents when doing data analysis, there may be occasions where working in an script is preferable. Scripts are plain text files with the extension &lt;code&gt;.R&lt;/code&gt;. Comments – text that are not executed as code – are denoted with the &lt;code&gt;#&lt;/code&gt; symbol.&lt;/p&gt;
&lt;p&gt;I tend to use R Scripts for writing discrete but substantial code blocks that are to be executed. For example, I might generate a set of &lt;a href=&#34;https://r4ds.had.co.nz/functions.html&#34;&gt;functions&lt;/a&gt; that relate to a particular use case and bundle these together in an R script. These then might be referred to in a data analysis from an &lt;code&gt;.Rmd&lt;/code&gt;, which makes various use of these functions in a similar way as one might import a package. Below is an example script that we will encounter later in the module when creating flow visualizations in R very similar to those that appear in Jo Wood’s TEDx talk. This script is saved with the fie name &lt;code&gt;bezier_path.R&lt;/code&gt;. If it were stored in a sensible location, like a project’s &lt;code&gt;code&lt;/code&gt; folder, it could be called from an R Markdown file with &lt;code&gt;source(./code/bezier_path)&lt;/code&gt;. R Scripts can be edited in the same way as R Markdown files in RStudio, via the &lt;em&gt;Code Editor&lt;/em&gt; pane.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# bezier_path.R
#
# Author: Roger Beecham
##############################################################################

#&amp;#39; Functions for generating input data for asymmetric bezier curve for OD data,
#&amp;#39; such that the origin is straight and destination curve. The retuned tibble
#&amp;#39; is passed to geom_bezier().Parametrtisation follows that published in
#&amp;#39; Wood et al. 2011. doi: 10.3138/carto.46.4.239.
#&amp;#39; @param data A df with origin and destination pairs representing 2D locations
#&amp;#39; (o_east, o_north, d_east, d_north) in cartesian (OSGB) space.
#&amp;#39; @param degrees For converting to radians.
#&amp;#39; @return A tibble of coordinate pairs representing asymmetric curve

get_trajectory &amp;lt;- function(data) {
  o_east=data$o_east
  o_north=data$o_north
  d_east=data$d_east
  d_north=data$d_north
  od_pair=data$od_pair

  curve_angle=get_radians(-90)
  east=(o_east-d_east)/6
  north=(o_north-d_north)/6
  c_east=d_east + east*cos(curve_angle) - north*sin(curve_angle)
  c_north=d_north + north*cos(curve_angle) + east*sin(curve_angle)
  d &amp;lt;- tibble(
    x=c(o_east,c_east,d_east),
    y=c(o_north,c_north,d_north),
    od_pair=od_pair
  )
}

# Convert degrees to radians.
get_radians &amp;lt;- function(degrees) {
  (degrees * pi) / (180)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To an extent R Scripts are more straightforward than R Markdown files in that you don’t have to worry about configuring code chunks. They are really useful for quickly developing bits of code. This can be achieved by highlighting over the code that you wish to execute and clicking the &lt;code&gt;Run&lt;/code&gt; icon at the top of the &lt;em&gt;Code Editor&lt;/em&gt; pane or by typing &lt;kbd&gt;ctrl&lt;/kbd&gt; + &lt;kbd&gt;rtn&lt;/kbd&gt; on Windows, &lt;kbd&gt;⌘&lt;/kbd&gt; + &lt;kbd&gt;rtn&lt;/kbd&gt; on macOS&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;create-an-rstudio-project&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Create an RStudio Project&lt;/h3&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:rstudio-project&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;./class/01-class_files/rstudio_project.png&#34; alt=&#34;Creating an RStudio Project&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 5: Creating an RStudio Project
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Throughout this module we will use project-oriented workflows. This is where all files pertaining to a data analysis – data, code and outputs – are organised from a single root folder and where &lt;em&gt;file path discipline&lt;/em&gt; is used such that all paths are relative to the project’s root folder (see &lt;a href=&#34;https://rstats.wtf/project-oriented-workflow.html&#34;&gt;Bryan &amp;amp; Hester 2020&lt;/a&gt;). You can imagine that this sort of self-contained project set-up is necessary for achieving reproducibility of your research. They allow anyone to take a project and run it on their own machines without having to make any adjustments.&lt;/p&gt;
&lt;p&gt;You might have noticed that when you open RStudio it automatically &lt;em&gt;points to&lt;/em&gt; a working directory, likely the home folder for your local machine, denoted with &lt;code&gt;~/&lt;/code&gt; in the Console. RStudio will by default save any outputs to this folder and will also expect any data you use to be saved there. Clearly if you want to incorporate neat, self-contained project workflows then you will want to organise your work from a dedicated project folder rather than the default home folder for your machine. This can be achieved with the &lt;code&gt;setwd(&amp;lt;path-to-your-project&amp;gt;)&lt;/code&gt; function. The problem with doing this is that you insert a path which cannot be understood outside of your local machine at the time it was created. This is a real pain. It makes simple things like moving projects around on your machine an arduous task and most importantly it hinders reproducibility if others are to reuse your work.&lt;/p&gt;
&lt;p&gt;RStudio Projects are a really excellent feature of the RStudio IDE that resolve these problems. Whenever you load up an RStudio Project, R starts up and the working directory is automatically set to the project’s root folder. If you were to move the project elsewhere on your machine, or to another machine, a new root is automatically generated – so RStudio projects ensure that relative paths work.&lt;/p&gt;
&lt;p&gt;Let’s create a new Project for this module:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Select &lt;code&gt;File&lt;/code&gt; &amp;gt; &lt;code&gt;New Project&lt;/code&gt; &amp;gt; &lt;code&gt;New Directory&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Browse to a sensible location and give the project a suitable name. Then click &lt;code&gt;Create Project&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You will notice that the top of the Console window now indicates the root for this new project, in my case &lt;code&gt;~projects/vis-for-gds&lt;/code&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In the root of your project, create folders called &lt;code&gt;reports&lt;/code&gt;, &lt;code&gt;code&lt;/code&gt;, &lt;code&gt;data&lt;/code&gt;, &lt;code&gt;figures&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Save this session’s &lt;a href=&#34;./homework/01-homework_files/01-template.Rmd&#34;&gt;&lt;i class=&#34;fab fa-r-project&#34;&gt;&lt;/i&gt; 01-template.Rmd&lt;/a&gt; file to the &lt;code&gt;reports&lt;/code&gt; folder.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Your project’s folder structure should now look like this:&lt;/p&gt;
&lt;pre class=&#34;text&#34;&gt;&lt;code&gt;vis-for-gds\
  vis-for-gds.Rproj
  code\
  data\
  figures\
  reports\
    01-template.Rmd&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;Visual data analysis approaches are necessary for exploring complex patterns in data and to make and communicate claims under uncertainty. This is especially true of Geographic Data Science applications, where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;datasets are being repurposed for social and natural sciences research for the first time;&lt;/li&gt;
&lt;li&gt;contain complex structure and geo-spatial relations that cannot be easily captured by statistical summaries alone;&lt;/li&gt;
&lt;li&gt;and, consequently, where the types of questions that can be asked and the techniques deployed to answer them cannot be easily specified in advance.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this module we will demonstrate this as we explore (Session 4 and 5), model under uncertainty (Session 6 and 7) and communicate (Session 7 and 8) with various social science datasets. We will work with both new, large-scale behavioural datasets, as well as more traditional, administrative datasets located within various social science domains: Political Science, Crime Science, Urban and Transport Planning.&lt;/p&gt;
&lt;p&gt;We will do so using the statistical programming environment &lt;code&gt;R&lt;/code&gt;, which along with &lt;a href=&#34;https://www.python.org/&#34;&gt;&lt;code&gt;Python&lt;/code&gt;&lt;/a&gt;, is &lt;em&gt;the&lt;/em&gt; programming environment for modern data analysis. We will make use of various tools, software libraries that form part of the &lt;code&gt;R&lt;/code&gt; ecosystem – the &lt;a href=&#34;https://www.tidyverse.org/&#34;&gt;&lt;code&gt;tidyverse&lt;/code&gt;&lt;/a&gt; for doing modern data science and &lt;a href=&#34;https://rmarkdown.rstudio.com/&#34;&gt;R Markdown&lt;/a&gt; for authoring reproducible research projects.&lt;/p&gt;
&lt;!-- https://www.sciencedirect.com/science/article/pii/S1353829220311758?via%3Dihub --&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2 unnumbered&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-anscombe_graphs_1973&#34;&gt;
&lt;p&gt;Anscombe, F. 1973. “Graphs in Statistical Analysis.” &lt;em&gt;American Statistician&lt;/em&gt; 27 (1): 17–21. doi:&lt;a href=&#34;https://doi.org/10.1080/00031305.1973.10478966&#34;&gt;10.1080/00031305.1973.10478966&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-arribas_geography_2018&#34;&gt;
&lt;p&gt;Arribas-Bel, Dani, and Jon Reades. 2018. “Geography and Computers: Past, Present, and Future.” &lt;em&gt;Geography Compass&lt;/em&gt; 12 (10): e12403. doi:&lt;a href=&#34;https://doi.org/10.1111/gec3.12403&#34;&gt;10.1111/gec3.12403&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-beecham_exploring_2014&#34;&gt;
&lt;p&gt;Beecham, Roger, and Jo Wood. 2014. “Exploring Gendered Cycling Behaviours Within a Large-Scale Behavioural Data-Set.” &lt;em&gt;Transportation Planning and Technology&lt;/em&gt; 37 (1). Taylor &amp;amp; Francis: 83–97.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-brunsdon_opening_2020&#34;&gt;
&lt;p&gt;Brunsdon, Chris, and Alexis Comber. 2020. “Opening Practice: Supporting Reproducibility and Critical Spatial Data Science.” &lt;em&gt;Journal of Geographical Systems&lt;/em&gt;. doi:&lt;a href=&#34;https://doi.org/10.1007/s10109-020-00334-2&#34;&gt;10.1007/s10109-020-00334-2&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-donoho_fifty_2017&#34;&gt;
&lt;p&gt;Donoho, David. 2017. “50 Years of Data Science.” &lt;em&gt;Journal of Computational and Graphical Statistics&lt;/em&gt; 26 (6): 745–66. doi:&lt;a href=&#34;https://doi.org/10.1080/10618600.2017.1384734&#34;&gt;10.1080/10618600.2017.1384734&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-friendly_brief_2007&#34;&gt;
&lt;p&gt;Friendly, Michael. 2007. “A Brief History of Data Visualization.” In &lt;em&gt;Handbook of Computational Statistics: Data Visualization&lt;/em&gt;, edited by C. Chen, W. Härdle, and A Unwin, III:1–34. Heidelberg: Springer-Verlag. &lt;a href=&#34;http://datavis.ca/papers/hbook.pdf&#34;&gt;http://datavis.ca/papers/hbook.pdf&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-matejka_same_2017&#34;&gt;
&lt;p&gt;Matejka, Justin, and George Fitzmaurice. 2017. “Same Stats, Different Graphs: Generating Datasets with Varied Appearance and Identical Statistics Through Simulated Annealing.” In, 1290–4. CHI ’17. New York, NY, USA: Association for Computing Machinery. doi:&lt;a href=&#34;https://doi.org/10.1145/3025453.3025912&#34;&gt;10.1145/3025453.3025912&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-singleton_geographic_2019&#34;&gt;
&lt;p&gt;Singleton, Alex, and Dani Arribas-Bel. 2019. “Geographic Data Science.” &lt;em&gt;Geographical Analysis&lt;/em&gt;. doi:&lt;a href=&#34;https://doi.org/10.1111/gean.12194&#34;&gt;10.1111/gean.12194&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;For an excellent precis and interpretation of this for geographers, see &lt;span class=&#34;citation&#34;&gt;Arribas-Bel and Reades (&lt;a href=&#34;#ref-arribas_geography_2018&#34; role=&#34;doc-biblioref&#34;&gt;2018&lt;/a&gt;)&lt;/span&gt;.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Although not the case when actually reading &lt;span class=&#34;citation&#34;&gt;Donoho (&lt;a href=&#34;#ref-donoho_fifty_2017&#34; role=&#34;doc-biblioref&#34;&gt;2017&lt;/a&gt;)&lt;/span&gt;.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;Checkout &lt;span class=&#34;citation&#34;&gt;Matejka and Fitzmaurice (&lt;a href=&#34;#ref-matejka_same_2017&#34; role=&#34;doc-biblioref&#34;&gt;2017&lt;/a&gt;)&lt;/span&gt;’s Same Stats, Different Graphs paper for a fun take one this.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Introduction</title>
      <link>/homework/01-homework/</link>
      <pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate>
      <guid>/homework/01-homework/</guid>
      <description>
&lt;!-- BLOGDOWN-HEAD --&gt;
&lt;link href=&#34;./rmarkdown-libs/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;./rmarkdown-libs/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;
&lt;!-- /BLOGDOWN-HEAD --&gt;

&lt;h2&gt;Contents&lt;/h2&gt;
&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#session-outcomes&#34;&gt;Session Outcomes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#task-1-read-and-complete-basicbasics&#34;&gt;Task 1: &lt;strong&gt;Read&lt;/strong&gt; and complete BasicBasics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#task-2-watch-thomas-mocks-introduction-to-tidy-statistics&#34;&gt;Task 2: &lt;strong&gt;Watch&lt;/strong&gt; Thomas Mock’s Introduction to Tidy Statistics&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;session-outcomes&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Session Outcomes&lt;/h2&gt;
&lt;p&gt;By the end of this homework session you should:&lt;/p&gt;
&lt;p&gt;

&lt;div class=&#34;alert alert-objective&#34;&gt;
  &lt;div&gt;
    &lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Be familiar with RStudio, R Markdown and R Projects.&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Know how to install and enable R packages and query package documentation.&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Understand the purpose R Markdown files and their anatomy.&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Know how to create R Projects and understand their benefits&lt;/li&gt;
&lt;/ul&gt;

  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;For each session I will post some additional exercises that relate to the practical learning you will be doing in-class. You will be populating R Markdown files as you complete the exercises. The exercises will vary in detail and challenge but you should try your best effort to complete them as they will form a portfolio of work that will contribute 25% of the module mark. Doing these exercises will also help you build the skills necessary to complete the project coursework that forms the main contribution to your module mark (75%).&lt;/p&gt;
&lt;p&gt;There has been a lot to take in this session. There are no formal exercises to complete as part of this session’s homework. Instead we want you to really try to solidify your understanding of the core technology for the module.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;task-1-read-and-complete-basicbasics&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Task 1: &lt;strong&gt;Read&lt;/strong&gt; and complete BasicBasics&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/R-Ladies&#34;&gt;R-Ladies&lt;/a&gt; is an excellent initiative and the &lt;a href=&#34;https://rladiessydney.org/courses/ryouwithme/01-basicbasics-0/&#34;&gt;R-Ladies Sydney BasicBasics&lt;/a&gt; pages are really great for introducing the R and RStudio ecosystem, and a little of the &lt;code&gt;tidyverse&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Read and work your way through:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://rladiessydney.org/courses/ryouwithme/01-basicbasics-1/&#34;&gt;BasicBasics 1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://rladiessydney.org/courses/ryouwithme/01-basicbasics-2/&#34;&gt;BasicBasics 2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://rladiessydney.org/courses/ryouwithme/01-basicbasics-3/&#34;&gt;BasicBasics 3&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This repeats some of the work that you have done in class this session. If you’re entirely new to R programming, this repetition is probably useful (and necessary) at this stage.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;task-2-watch-thomas-mocks-introduction-to-tidy-statistics&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Task 2: &lt;strong&gt;Watch&lt;/strong&gt; Thomas Mock’s Introduction to Tidy Statistics&lt;/h2&gt;
&lt;p&gt;Thomas Mock’s &lt;a href=&#34;https://rstudio.com/resources/webinars/a-gentle-introduction-to-tidy-statistics-in-r/&#34;&gt;Gentle Introduction to Tidy Statistics&lt;/a&gt; is pitched those coming to R after previously working with point-and-click interfaces (SPSS, STATA, ArcGIS). I strongly recommend that you watch this now as you start to embark on the “pain” of doing data analysis programmatically.&lt;/p&gt;
&lt;div class=&#34;embed-responsive embed-responsive-16by9&#34;&gt;
&lt;iframe class=&#34;embed-responsive-item&#34; src=&#34;https://rstudio.com/resources/webinars/a-gentle-introduction-to-tidy-statistics-in-r/&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;
&lt;/iframe&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Introduction</title>
      <link>/reading/01-reading/</link>
      <pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate>
      <guid>/reading/01-reading/</guid>
      <description>
&lt;!-- BLOGDOWN-HEAD --&gt;
&lt;link href=&#34;./rmarkdown-libs/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;./rmarkdown-libs/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;
&lt;!-- /BLOGDOWN-HEAD --&gt;


&lt;div id=&#34;defining-geographic-data-science&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Defining (Geographic) Data science&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;citation&#34;&gt;Dani Arribas-Bel and Jon Reades, “Geography and Computers: Past, Present, and Future,” &lt;em&gt;Geography Compass&lt;/em&gt; 12, no. 10 (&lt;a href=&#34;#ref-arribas_geography_2018&#34; role=&#34;doc-biblioref&#34;&gt;2018&lt;/a&gt;): e12403, doi:&lt;a href=&#34;https://doi.org/10.1111/gec3.12403&#34; role=&#34;doc-biblioref&#34;&gt;10.1111/gec3.12403&lt;/a&gt;.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;citation&#34;&gt;Alex Singleton and Dani Arribas-Bel, “Geographic Data Science,” &lt;em&gt;Geographical Analysis&lt;/em&gt; (&lt;a href=&#34;#ref-singleton_geographic_2019&#34; role=&#34;doc-biblioref&#34;&gt;2019&lt;/a&gt;), doi:&lt;a href=&#34;https://doi.org/10.1111/gean.12194&#34; role=&#34;doc-biblioref&#34;&gt;10.1111/gean.12194&lt;/a&gt;.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;reproducibility-agenda&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Reproducibility agenda&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;citation&#34;&gt;Chris Brunsdon and Alexis Comber, “Opening Practice: Supporting Reproducibility and Critical Spatial Data Science,” &lt;em&gt;Journal of Geographical Systems&lt;/em&gt; (&lt;a href=&#34;#ref-brunsdon_opening_2020&#34; role=&#34;doc-biblioref&#34;&gt;2020&lt;/a&gt;), doi:&lt;a href=&#34;https://doi.org/10.1007/s10109-020-00334-2&#34; role=&#34;doc-biblioref&#34;&gt;10.1007/s10109-020-00334-2&lt;/a&gt;.&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;introducing-r-for-data-science&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Introducing R for Data Science&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;citation&#34;&gt;Hadley Wickham and Garrett Grolemund, &lt;em&gt;R for Data Science: Import, Tidy, Transform, Visualize, and Model Data&lt;/em&gt; (Sebastopol, California: O’Reilly Media, &lt;a href=&#34;#ref-wickham_r_2017&#34; role=&#34;doc-biblioref&#34;&gt;2017&lt;/a&gt;), &lt;a href=&#34;http://r4ds.had.co.nz/&#34; role=&#34;doc-biblioref&#34;&gt;http://r4ds.had.co.nz/&lt;/a&gt;.&lt;/span&gt;&lt;br /&gt;
– Chapters 1,2,6,8.&lt;br /&gt;
&lt;a href=&#34;https://r4ds.had.co.nz/&#34;&gt;Free online&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Data Fundamentals</title>
      <link>/homework/02-homework/</link>
      <pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate>
      <guid>/homework/02-homework/</guid>
      <description>
&lt;!-- BLOGDOWN-HEAD --&gt;
&lt;link href=&#34;./rmarkdown-libs/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;./rmarkdown-libs/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;
&lt;!-- /BLOGDOWN-HEAD --&gt;

&lt;h2&gt;Contents&lt;/h2&gt;
&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#session-outcomes&#34;&gt;Session Outcomes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#task-1-describe-data&#34;&gt;Task 1: Describe data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#task-2-diagnose-data&#34;&gt;Task 2: Diagnose data&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#uk-general-election-results-2019&#34;&gt;UK General Election Results 2019&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#uk-general-election-results-2017-and-2019&#34;&gt;UK General Election Results 2017 and 2019&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#task-3-fix-data&#34;&gt;Task 3: Fix data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#task-4-compute-from-data&#34;&gt;Task 4: Compute from data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;session-outcomes&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Session Outcomes&lt;/h2&gt;
&lt;p&gt;By the end of this homework session you should be able to:&lt;/p&gt;
&lt;p&gt;

&lt;div class=&#34;alert alert-objective&#34;&gt;
  &lt;div&gt;
    &lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Describe data according to its structure and contents.&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Calculate descriptive summaries over datasets.&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Apply high-level functions in &lt;code&gt;dplyr&lt;/code&gt; and &lt;code&gt;tidyr&lt;/code&gt; for working with data.&lt;/li&gt;
&lt;/ul&gt;

  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;This homework requires you to apply the concepts and skills developed in the class session on &lt;a href=&#34;./02-class/&#34;&gt;data fundamentals&lt;/a&gt;. Do complete each of the tasks and be sure to save your work as this homework will be submitted as part of your portfolio for Assignment 1.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;task-1-describe-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Task 1: Describe data&lt;/h2&gt;
&lt;p&gt;Complete the data description table below identifying the &lt;strong&gt;measurement level&lt;/strong&gt; of each variable in the (fictional) New York bikeshare stations dataset below.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;Variable name&lt;/th&gt;
&lt;th&gt;Variable value&lt;/th&gt;
&lt;th&gt;Measurement level&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;code&gt;name&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;“Central Park”&lt;/td&gt;
&lt;td&gt;&lt;enter here&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;code&gt;capacity&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;80&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;code&gt;rank_capacity&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;45&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;code&gt;date_opened&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;“2014-05-23”&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;code&gt;longitude&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;-74.00149746&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;code&gt;latitude&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;40.74177603&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;task-2-diagnose-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Task 2: Diagnose data&lt;/h2&gt;
&lt;p&gt;Below are two different tables with results from UK General Elections. We will be working with these data in the next session. Identify whether or not each is in &lt;strong&gt;tidy&lt;/strong&gt; format [&lt;span class=&#34;citation&#34;&gt;H. Wickham “Tidy Data,” &lt;em&gt;Journal of Statistical Software&lt;/em&gt; 59, no. 10 (&lt;a href=&#34;#ref-wickham_tidy_2014&#34; role=&#34;doc-biblioref&#34;&gt;2014&lt;/a&gt;): 1–23.&lt;/span&gt; If they are not, provide a layout for a tidy version. No need to use code here, just edit the markdown table. If you’re struggling to work out how to organise markdown tables, you may wish to use this &lt;a href=&#34;https://www.tablesgenerator.com/markdown_tables&#34;&gt;tables generator&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;uk-general-election-results-2019&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;UK General Election Results 2019&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;party&lt;/th&gt;
&lt;th&gt;percent_vote&lt;/th&gt;
&lt;th&gt;num_mps&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Conservative&lt;/td&gt;
&lt;td&gt;43.6&lt;/td&gt;
&lt;td&gt;365&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Labour&lt;/td&gt;
&lt;td&gt;32.2&lt;/td&gt;
&lt;td&gt;202&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Scottish National Party&lt;/td&gt;
&lt;td&gt;3.9&lt;/td&gt;
&lt;td&gt;48&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Liberal Democrats&lt;/td&gt;
&lt;td&gt;11.6&lt;/td&gt;
&lt;td&gt;11&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Democratic Union Party&lt;/td&gt;
&lt;td&gt;0.8&lt;/td&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;uk-general-election-results-2017-and-2019&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;UK General Election Results 2017 and 2019&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;party&lt;/th&gt;
&lt;th&gt;percent_vote_2017&lt;/th&gt;
&lt;th&gt;num_mps_2017&lt;/th&gt;
&lt;th&gt;percent_vote_2019&lt;/th&gt;
&lt;th&gt;num_mps_2019&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Conservative&lt;/td&gt;
&lt;td&gt;42.4&lt;/td&gt;
&lt;td&gt;317&lt;/td&gt;
&lt;td&gt;43.6&lt;/td&gt;
&lt;td&gt;365&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Labour&lt;/td&gt;
&lt;td&gt;40.0&lt;/td&gt;
&lt;td&gt;262&lt;/td&gt;
&lt;td&gt;32.2&lt;/td&gt;
&lt;td&gt;202&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Scottish National Party&lt;/td&gt;
&lt;td&gt;3.0&lt;/td&gt;
&lt;td&gt;35&lt;/td&gt;
&lt;td&gt;3.9&lt;/td&gt;
&lt;td&gt;48&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Liberal Democrats&lt;/td&gt;
&lt;td&gt;7.4&lt;/td&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;td&gt;11.6&lt;/td&gt;
&lt;td&gt;11&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Democratic Union Party&lt;/td&gt;
&lt;td&gt;0.9&lt;/td&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;0.8&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;task-3-fix-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Task 3: Fix data&lt;/h2&gt;
&lt;p&gt;In the &lt;a href=&#34;./homework/02-homework_files/02-template.Rmd&#34;&gt;&lt;i class=&#34;fab fa-r-project&#34;&gt;&lt;/i&gt; 02-template.Rmd&lt;/a&gt; file for this session I have provided links to two derived tables (&lt;code&gt;ny_spread_columns&lt;/code&gt; and &lt;code&gt;ny_spread_rows&lt;/code&gt;) from the New York bikeshare trip data that are not in a tidy format.&lt;/p&gt;
&lt;p&gt;Using functions from &lt;code&gt;dplyr&lt;/code&gt; and &lt;code&gt;tidyr&lt;/code&gt; reorganise these data so that they are conform to the rules of &lt;strong&gt;tidy&lt;/strong&gt; data &lt;span class=&#34;citation&#34;&gt;Wickham, “Tidy Data.”&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;A candidate tidy organisation of the data is below. Each row is an origin-destination pair for a weekday or weekend, and each variable describes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;o_station&lt;/code&gt;: station id of the origin station&lt;/li&gt;
&lt;li&gt;&lt;code&gt;d_station&lt;/code&gt;: station ide of the destination station&lt;/li&gt;
&lt;li&gt;&lt;code&gt;wkday&lt;/code&gt;: identifies whether the OD pair describes weekday or weekend ny_trips&lt;/li&gt;
&lt;li&gt;&lt;code&gt;count&lt;/code&gt;: count of trips recorded for that observation (OD pair and weekday/weekend)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dist&lt;/code&gt;: total distance (cumulative) in kms of all trips recorded for that observation (OD pair and weekday/weekend)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;duration&lt;/code&gt;: total duration in minutes (cumulative) of all trips recorded for that observation (OD pair and weekday/weekend)&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 386,762 x 6
##    o_station d_station wkday   count  dist duration
##        &amp;lt;int&amp;gt;     &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
##  1        72       116 weekend     1  1.15     18.2
##  2        72       127 weekend    10 18.0     339.
##  3        72       128 weekend     2  3.18     69.6
##  4        72       146 weekend    12 27.6     402.
##  5        72       151 weekend     2  2.87     54.9
##  6        72       161 weekend     2  2.52     64.8
##  7        72       164 weekend     5 13.3      73.3
##  8        72       167 weekend     1  2.07     17.2
##  9        72       168 weekend     2  1.70     42.7
## 10        72       173 weekend     9  9.59    194.
## # … with 386,752 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;task-4-compute-from-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Task 4: Compute from data&lt;/h2&gt;
&lt;p&gt;Using &lt;code&gt;dplyr&lt;/code&gt; functions, calculate the average distance, duration and speed of trips occuring for each observation. Print out to the Console the top 10 most heavily cycled OD pairs (and their associated summary statistics) separately for weekdays and weekends. You may wish to join on your &lt;code&gt;ny_stations&lt;/code&gt; table in order to fetch the station names corresponding to the origin and destination stations.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Data Fundamentals</title>
      <link>/reading/02-reading/</link>
      <pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate>
      <guid>/reading/02-reading/</guid>
      <description>
&lt;!-- BLOGDOWN-HEAD --&gt;
&lt;link href=&#34;./rmarkdown-libs/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;./rmarkdown-libs/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;
&lt;!-- /BLOGDOWN-HEAD --&gt;


&lt;div id=&#34;tidy-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Tidy Data&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;citation&#34;&gt;&lt;span class=&#34;citeproc-not-found&#34; data-reference-id=&#34;wickham_tidy_2010&#34;&gt;&lt;strong&gt;???&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;r-for-data-science&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;R for Data Science&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;citation&#34;&gt;Hadley Wickham and Garrett Grolemund, &lt;em&gt;R for Data Science: Import, Tidy, Transform, Visualize, and Model Data&lt;/em&gt; (Sebastopol, California: O’Reilly Media, &lt;a href=&#34;#ref-wickham_r_2017&#34; role=&#34;doc-biblioref&#34;&gt;2017&lt;/a&gt;), &lt;a href=&#34;http://r4ds.had.co.nz/&#34; role=&#34;doc-biblioref&#34;&gt;http://r4ds.had.co.nz/&lt;/a&gt;.&lt;/span&gt;&lt;br /&gt;
– Chapters 2-12.&lt;br /&gt;
&lt;a href=&#34;https://r4ds.had.co.nz/&#34;&gt;Free online&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;bikedata&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;bikedata&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;citation&#34;&gt;Mark Padgham and Richard Ellison, “Bikedata,” &lt;em&gt;The Journal of Open Source Software&lt;/em&gt; 2, no. 20 &lt;a href=&#34;#ref-padgham_bikedata_2017&#34; role=&#34;doc-biblioref&#34;&gt;(December &lt;a href=&#34;#ref-padgham_bikedata_2017&#34; role=&#34;doc-biblioref&#34;&gt;2017&lt;/a&gt;)&lt;/a&gt;, doi:&lt;a href=&#34;https://doi.org/10.21105/joss.00471&#34; role=&#34;doc-biblioref&#34;&gt;10.21105/joss.00471&lt;/a&gt;.&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Visualization Fundamentals</title>
      <link>/homework/03-homework/</link>
      <pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate>
      <guid>/homework/03-homework/</guid>
      <description>
&lt;!-- BLOGDOWN-HEAD --&gt;
&lt;link href=&#34;./rmarkdown-libs/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;./rmarkdown-libs/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;
&lt;!-- /BLOGDOWN-HEAD --&gt;

&lt;h2&gt;Contents&lt;/h2&gt;
&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#session-outcomes&#34;&gt;Session Outcomes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#task-1-describe-and-evaluate&#34;&gt;Task 1: Describe and evaluate&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#task-2-reproduce&#34;&gt;Task 2: Reproduce&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#histograms-faceted-by-region&#34;&gt;Histograms faceted by region&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#scatterplots-with-multiple-encodings&#34;&gt;Scatterplots with multiple encodings&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#task-3-create-a-map&#34;&gt;Task 3: Create a map&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;session-outcomes&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Session Outcomes&lt;/h2&gt;
&lt;p&gt;By the end of this homework session you should be able to:&lt;/p&gt;
&lt;p&gt;

&lt;div class=&#34;alert alert-objective&#34;&gt;
  &lt;div&gt;
    &lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Formally describe data graphics according to their visual encoding.&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Reproduce graphics by writing &lt;code&gt;ggplot2&lt;/code&gt; specifications.&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Combine &lt;code&gt;dplyr&lt;/code&gt; and conditional statements to prep data for plotting.&lt;/li&gt;
&lt;/ul&gt;

  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;This homework requires you to apply the concepts and skills developed in the class session on &lt;a href=&#34;./02-class/&#34;&gt;data fundamentals&lt;/a&gt;. Do complete each of the tasks and be sure to save your work as this homework will be submitted as part of your portfolio for Assignment 1.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;task-1-describe-and-evaluate&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Task 1: Describe and evaluate&lt;/h2&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:spoke-map&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;./class/03-class_files/spoke-map.png&#34; alt=&#34;Map of Butler Con-Lab Swing in 2019 General Election.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: Map of Butler Con-Lab Swing in 2019 General Election.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Complete the description table below identifying each &lt;strong&gt;data item&lt;/strong&gt; that is encoded along with its &lt;strong&gt;measurement level&lt;/strong&gt;, &lt;strong&gt;visual mark&lt;/strong&gt; and &lt;strong&gt;visual&lt;/strong&gt; channel** and the effectiveness rank, according to &lt;span class=&#34;citation&#34;&gt;Tamara Munzner &lt;em&gt;Visualization Analysis and Design&lt;/em&gt;, AK Peters Visualization Series (Boca Raton, FL: CRC Press, &lt;a href=&#34;#ref-munzner_visualization_2014&#34; role=&#34;doc-biblioref&#34;&gt;2014&lt;/a&gt;).&lt;/span&gt;, of this encoding.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;Data item&lt;/th&gt;
&lt;th&gt;Measurement level&lt;/th&gt;
&lt;th&gt;Visual mark&lt;/th&gt;
&lt;th&gt;Visual channel&lt;/th&gt;
&lt;th&gt;Rank&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;code&gt;location&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;enter here&gt;&lt;/td&gt;
&lt;td&gt;&lt;enter here&gt;&lt;/td&gt;
&lt;td&gt;&lt;enter here&gt;&lt;/td&gt;
&lt;td&gt;&lt;enter here&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;code&gt;...&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;...&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;...&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;...&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;...&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;code&gt;...&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;...&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;...&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;...&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;...&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;code&gt;...&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;...&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;...&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;...&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;...&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;code&gt;...&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;...&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;...&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;...&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;...&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;code&gt;...&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;...&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;...&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;...&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;...&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;task-2-reproduce&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Task 2: Reproduce&lt;/h2&gt;
&lt;div id=&#34;histograms-faceted-by-region&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Histograms faceted by region&lt;/h3&gt;
&lt;p&gt;Write some code for reproducing something similar to the graphic below – a set of histograms of the Swing variable, faceted by region. Place your code into the &lt;a href=&#34;./homework/03-homework_files/03-template.Rmd&#34;&gt;&lt;i class=&#34;fab fa-r-project&#34;&gt;&lt;/i&gt; 03-template.Rmd&lt;/a&gt; file for this session.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#######################
# Enter your code in the chunk provided.
######################&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:hist-region&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;./class/03-class_files/hist-region.png&#34; alt=&#34;Histograms of Swing variable, grouped by region.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 2: Histograms of Swing variable, grouped by region.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;scatterplots-with-multiple-encodings&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Scatterplots with multiple encodings&lt;/h3&gt;
&lt;p&gt;Write some code for reproducing something similar to the graphic below – a scatterplot comparing 2017 and 2019 vote shares for Labour. Be sure to include &lt;strong&gt;every&lt;/strong&gt; encoding (&lt;code&gt;shape&lt;/code&gt; and &lt;code&gt;alpha&lt;/code&gt;) as it appears in the graphic. Hint: you may need to use a &lt;strong&gt;conditional statement&lt;/strong&gt; to generate a variable for emphasising constituencies that flipped parties between 2017 and 2019. Place your code into the &lt;a href=&#34;./homework/03-homework_files/03-template.Rmd&#34;&gt;&lt;i class=&#34;fab fa-r-project&#34;&gt;&lt;/i&gt; 03-template.Rmd&lt;/a&gt; file for this session.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#######################
# Enter your code in the chunk provided.
######################&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:scatters-lab&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;./class/03-class_files/scatters-lab.png&#34; alt=&#34;Plots of 2019 versus 2017 vote shares.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 3: Plots of 2019 versus 2017 vote shares.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;task-3-create-a-map&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Task 3: Create a map&lt;/h2&gt;
&lt;p&gt;Write some code for reproducing something similar to the graphic below – a map of the estimated Leave:Remain vote margin by Parliamentary Constituency. Note that I am using a &lt;a href=&#34;https://colorbrewer2.org/#type=diverging&amp;amp;scheme=BrBG&amp;amp;n=3&#34;&gt;diverging&lt;/a&gt; colour scheme here to distinguish whether the Constituency was majority Leave and Remain – brown or green – and also the &lt;em&gt;size&lt;/em&gt; of that majority – the darker the colour, the larger the majority.&lt;/p&gt;
&lt;p&gt;Place your code into the &lt;a href=&#34;./homework/03-homework_files/03-template.Rmd&#34;&gt;&lt;i class=&#34;fab fa-r-project&#34;&gt;&lt;/i&gt; 03-template.Rmd&lt;/a&gt; file for this session.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#######################
# Enter your code in the chunk provided.
######################&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:referendum-map&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;./class/03-class_files/referendum-map.png&#34; alt=&#34;Map of 2016 EU Referendum vote, estimated by Parliamentary Constituency in GB.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 4: Map of 2016 EU Referendum vote, estimated by Parliamentary Constituency in GB.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Visualization Fundamentals</title>
      <link>/reading/03-reading/</link>
      <pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate>
      <guid>/reading/03-reading/</guid>
      <description>
&lt;!-- BLOGDOWN-HEAD --&gt;
&lt;link href=&#34;./rmarkdown-libs/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;./rmarkdown-libs/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;
&lt;!-- /BLOGDOWN-HEAD --&gt;


&lt;div id=&#34;visualization-concepts&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Visualization concepts&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;citation&#34;&gt;Tamara Munzner, &lt;em&gt;Visualization Analysis and Design&lt;/em&gt;, AK Peters Visualization Series (Boca Raton, FL: CRC Press, &lt;a href=&#34;#ref-munzner_visualization_2014&#34; role=&#34;doc-biblioref&#34;&gt;2014&lt;/a&gt;).&lt;/span&gt;&lt;br /&gt;
– Chapters 1,2,5.&lt;br /&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;data-visualization-in-ggplot2&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Data Visualization in ggplot2&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;citation&#34;&gt;Kieran Healy, &lt;em&gt;Data Visualization: A Practical Introduction&lt;/em&gt; (Princeton: Princeton University Press, &lt;a href=&#34;#ref-healy_data_2018&#34; role=&#34;doc-biblioref&#34;&gt;2018&lt;/a&gt;), &lt;a href=&#34;http://socviz.co/&#34; role=&#34;doc-biblioref&#34;&gt;http://socviz.co/&lt;/a&gt;.&lt;/span&gt;&lt;br /&gt;
– Chapters 1,3,4,7.&lt;br /&gt;
&lt;a href=&#34;https://socviz.co/&#34;&gt;Free online&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;citation&#34;&gt;Hadley Wickham and Garrett Grolemund, &lt;em&gt;R for Data Science: Import, Tidy, Transform, Visualize, and Model Data&lt;/em&gt; (Sebastopol, California: O’Reilly Media, &lt;a href=&#34;#ref-wickham_r_2017&#34; role=&#34;doc-biblioref&#34;&gt;2017&lt;/a&gt;), &lt;a href=&#34;http://r4ds.had.co.nz/&#34; role=&#34;doc-biblioref&#34;&gt;http://r4ds.had.co.nz/&lt;/a&gt;.&lt;/span&gt;&lt;br /&gt;
– Chapters 3.&lt;br /&gt;
&lt;a href=&#34;https://r4ds.had.co.nz/&#34;&gt;Free online&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Visualization for exploratory data analysis: Colour and layout</title>
      <link>/class/04-class/</link>
      <pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate>
      <guid>/class/04-class/</guid>
      <description>
&lt;!-- BLOGDOWN-HEAD --&gt;
&lt;link href=&#34;./rmarkdown-libs/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;./rmarkdown-libs/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;
&lt;!-- /BLOGDOWN-HEAD --&gt;


&lt;blockquote&gt;
&lt;p&gt;The simple graph has brought more information to the data analyst’s mind than any other device.&#34; –&amp;gt; – John Tukey&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Theory – EDA?&lt;/p&gt;
&lt;p&gt;Stats19 data – preference – that will return to this in week 07
bikes data – second preference – though not too sure. Could link to the whole, bit sure if will be discriminating structure from start&lt;/p&gt;
&lt;p&gt;Stats19 – large, attribute-rich. Underanalysed. Not sure how discriminating structure will be.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Faceting
&lt;a href=&#34;https://ids-s1-20.github.io/slides/week-02/w2-d03-ggplot2/w2-d03-ggplot2.html#38&#34; class=&#34;uri&#34;&gt;https://ids-s1-20.github.io/slides/week-02/w2-d03-ggplot2/w2-d03-ggplot2.html#38&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&#34;https://ids-s1-20.github.io/slides/week-02/w2-d02-data-viz/w2-d02-data-viz.html#18&#34; class=&#34;uri&#34;&gt;https://ids-s1-20.github.io/slides/week-02/w2-d02-data-viz/w2-d02-data-viz.html#18&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Code out loud a good idea
&lt;a href=&#34;https://ids-s1-20.github.io/slides/week-02/w2-d03-ggplot2/w2-d03-ggplot2.html#6&#34; class=&#34;uri&#34;&gt;https://ids-s1-20.github.io/slides/week-02/w2-d03-ggplot2/w2-d03-ggplot2.html#6&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Approach to analysing data to summarise its main characetristics
Often visual
Also here would calculate summary stats, perform data wrangling/manipulation/transformation&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Visualization fundamentals: Codify, map, evaluate</title>
      <link>/class/03-class/</link>
      <pubDate>Tue, 25 May 2021 00:00:00 +0000</pubDate>
      <guid>/class/03-class/</guid>
      <description>
&lt;!-- BLOGDOWN-HEAD --&gt;
&lt;link href=&#34;./rmarkdown-libs/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;./rmarkdown-libs/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;./rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;./rmarkdown-libs/lightable/lightable.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;!-- /BLOGDOWN-HEAD --&gt;

&lt;h2&gt;Contents&lt;/h2&gt;
&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#concepts&#34;&gt;Concepts&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#characteristics-of-effective-data-graphics&#34;&gt;Characteristics of effective data graphics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#grammar-of-graphics&#34;&gt;Grammar of Graphics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#marks-and-visual-channels&#34;&gt;Marks and visual channels&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#evaluating-designs&#34;&gt;Evaluating designs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#symbolisation&#34;&gt;Symbolisation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#checking-perceptual-rankings&#34;&gt;Checking perceptual rankings&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#colour&#34;&gt;Colour&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#techniques&#34;&gt;Techniques&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#import&#34;&gt;Import&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#summarise&#34;&gt;Summarise&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#plot-distributions&#34;&gt;Plot distributions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#plot-ranksmagnitudes&#34;&gt;Plot ranks/magnitudes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#plot-relationships&#34;&gt;Plot relationships&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#plot-geography&#34;&gt;Plot geography&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#conclusions&#34;&gt;Conclusions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#references&#34;&gt;References&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;By the end of this session you should gain the following &lt;strong&gt;&lt;em&gt;knowledge&lt;/em&gt;&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;

&lt;div class=&#34;alert alert-objective&#34;&gt;
  &lt;div&gt;
    &lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Recognise the characteristics of effective data graphics.&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Understand that there is a &lt;strong&gt;grammar&lt;/strong&gt; of graphics, and that this grammar underpins modern visualization toolkits (&lt;code&gt;ggplot&lt;/code&gt;, vega-lite and Tableau).&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Be aware of the vocabulary used by these toolkits – that of encoding data through visual channels.&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Be able to select appropriate &lt;strong&gt;visual channels&lt;/strong&gt; given a data item’s measurement type.&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Appreciate how &lt;strong&gt;visual channels&lt;/strong&gt; and evidence of their &lt;strong&gt;encoding effectiveness&lt;/strong&gt; can be used to evaluate data graphics.&lt;/li&gt;
&lt;/ul&gt;

  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;By the end of this session you should gain the following &lt;strong&gt;&lt;em&gt;practical skills&lt;/em&gt;&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;

&lt;div class=&#34;alert alert-objective&#34;&gt;
  &lt;div&gt;
    &lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Write &lt;code&gt;ggplot2&lt;/code&gt; specifications that map data to &lt;strong&gt;colour&lt;/strong&gt; and &lt;strong&gt;position&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; ??&lt;/li&gt;
&lt;/ul&gt;

  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;This session outlines the fundamentals of visualization design. It offers a position on what effective data graphics should do, before discussing in detail the processes that take place when creating data graphics. You will learn that there is a framework – a vocabulary and grammar – for supporting this process which, combined with established knowledge around visual perception, can be used to &lt;em&gt;describe&lt;/em&gt;, &lt;em&gt;evaluate&lt;/em&gt; and &lt;em&gt;create&lt;/em&gt; effective data graphics. Talking about a vocabulary and grammar of data and graphics may sound alien and abstract, the preserve of Computer Scientists. However, through an analysis of 2019 General Election results data we will demonstrate that these concepts underpin most visual data analysis.&lt;/p&gt;
&lt;p&gt;

&lt;div class=&#34;alert alert-instruction&#34;&gt;
  &lt;div&gt;
    Watch &lt;a href=&#34;https://www.cs.utah.edu/~miriah/&#34;&gt;Miriah Meyer’s&lt;/a&gt; TEDx talk, &lt;em&gt;Information Visualization for Scientific Discovery&lt;/em&gt;, which provides a nice introduction to many of the concepts covered in the session.
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;div class=&#34;embed-responsive embed-responsive-16by9&#34;&gt;
&lt;iframe class=&#34;embed-responsive-item&#34; src=&#34;https://www.youtube.com/embed/Sua0xDCf8MA&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;
&lt;/iframe&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;concepts&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Concepts&lt;/h2&gt;
&lt;div id=&#34;characteristics-of-effective-data-graphics&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Characteristics of effective data graphics&lt;/h3&gt;
&lt;p&gt;Data graphics take numerous forms and are used in many different ways by scientists, journalists, designers and many more. Whilst the intentions of those producing data graphics varies, those that are &lt;em&gt;effective&lt;/em&gt; generally have the following characteristics:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Represent complex datasets graphically to expose structure, connections and comparisons that could not be achieved easily via other means.&lt;/li&gt;
&lt;li&gt;Are data rich: present many numbers in a small space.&lt;/li&gt;
&lt;li&gt;Reveal patterns at several levels of detail: from broad overview to fine structure.&lt;/li&gt;
&lt;li&gt;Have elegance – emphasise dimensions of a dataset without extraneous details.&lt;/li&gt;
&lt;li&gt;Generate an aesthetic response that encourages people to engage with the data or question.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;

&lt;div class=&#34;alert alert-instruction&#34;&gt;
  &lt;div&gt;
    Considering these characteristics, take a look at the data graphics below, which present an analysis of the 2016 US Presidential Election. Use the links to read the full stories and accompanying data analyses.
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:wp-map&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;./class/03-class_files/trump_maps.png&#34; alt=&#34;Maps of 2016 US presidential election results. Left - two-colour choropleth in [Medium](https://pensivepost.com/understanding-rural-america-d9695a6b3516). Right - information-rich data graphic in [The Washington Post](https://www.washingtonpost.com/graphics/politics/2016-election/election-results-from-coast-to-coast/).&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: Maps of 2016 US presidential election results. Left - two-colour choropleth in &lt;a href=&#34;https://pensivepost.com/understanding-rural-america-d9695a6b3516&#34;&gt;Medium&lt;/a&gt;. Right - information-rich data graphic in &lt;a href=&#34;https://www.washingtonpost.com/graphics/politics/2016-election/election-results-from-coast-to-coast/&#34;&gt;The Washington Post&lt;/a&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Both maps use 2016 county-level results data, but the &lt;a href=&#34;https://www.washingtonpost.com/graphics/politics/2016-election/election-results-from-coast-to-coast/&#34;&gt;The Washington Post&lt;/a&gt; graphic encodes many more data items than the Medium post (see Table &lt;a href=&#34;#tab:wp-data&#34;&gt;1&lt;/a&gt; below).&lt;/p&gt;
&lt;p&gt;It is not simply the data density that makes the Washington Post graphic successful. The authors usefully incorporate annotations and transformations in order to support comparison and emphasise structure. By varying the height of triangles according to the number of votes cast, the thickness according to whether or not the result for Trump/Clinton was a landslide and rotating the scrollable map 90 degrees, the very obvious differences between metropolitan, densely populated coastal counties that voted emphatically for Clinton and the vast number of suburban, provincial town and rural counties (everywhere else) that voted Trump, are exposed.&lt;/p&gt;
&lt;table&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:wp-data&#34;&gt;Table 1: &lt;/span&gt;Data items encoded in the Washington Post and Medium articles.
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Data item
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Data measurement level
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Washington Post
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Medium
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
county location
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;code&gt;Ratio&lt;/code&gt; (&lt;code&gt;cyclic&lt;/code&gt;)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;a href=&#34;www.google.com&#34;&gt;&lt;svg style=&#34;height:0.8em;top:.04em;position:relative;&#34; viewBox=&#34;0 0 512 512&#34;&gt;&lt;path d=&#34;M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z&#34;/&gt;&lt;/svg&gt;&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;a href=&#34;www.google.com&#34;&gt;&lt;svg style=&#34;height:0.8em;top:.04em;position:relative;&#34; viewBox=&#34;0 0 512 512&#34;&gt;&lt;path d=&#34;M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z&#34;/&gt;&lt;/svg&gt;&lt;/a&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
county result
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;code&gt;Nominal&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;a href=&#34;www.google.com&#34;&gt;&lt;svg style=&#34;height:0.8em;top:.04em;position:relative;&#34; viewBox=&#34;0 0 512 512&#34;&gt;&lt;path d=&#34;M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z&#34;/&gt;&lt;/svg&gt;&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;a href=&#34;www.google.com&#34;&gt;&lt;svg style=&#34;height:0.8em;top:.04em;position:relative;&#34; viewBox=&#34;0 0 512 512&#34;&gt;&lt;path d=&#34;M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z&#34;/&gt;&lt;/svg&gt;&lt;/a&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
state result
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;code&gt;Nominal&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;a href=&#34;www.google.com&#34;&gt;&lt;svg style=&#34;height:0.8em;top:.04em;position:relative;&#34; viewBox=&#34;0 0 512 512&#34;&gt;&lt;path d=&#34;M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z&#34;/&gt;&lt;/svg&gt;&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
county votes cast (~pop size)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;code&gt;Ratio&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;a href=&#34;www.google.com&#34;&gt;&lt;svg style=&#34;height:0.8em;top:.04em;position:relative;&#34; viewBox=&#34;0 0 512 512&#34;&gt;&lt;path d=&#34;M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z&#34;/&gt;&lt;/svg&gt;&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
county result margin
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;code&gt;Ratio&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;a href=&#34;www.google.com&#34;&gt;&lt;svg style=&#34;height:0.8em;top:.04em;position:relative;&#34; viewBox=&#34;0 0 512 512&#34;&gt;&lt;path d=&#34;M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z&#34;/&gt;&lt;/svg&gt;&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
county result landslide
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;code&gt;Nominal&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;a href=&#34;www.google.com&#34;&gt;&lt;svg style=&#34;height:0.8em;top:.04em;position:relative;&#34; viewBox=&#34;0 0 512 512&#34;&gt;&lt;path d=&#34;M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z&#34;/&gt;&lt;/svg&gt;&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;grammar-of-graphics&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Grammar of Graphics&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Data graphics visually display measured quantities by means of the combined use of points, lines, a coordinate system, numbers, symbols, words, shading, and color.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;citation&#34;&gt;Tufte (&lt;a href=&#34;#ref-tufte_visual_1983&#34; role=&#34;doc-biblioref&#34;&gt;1983&lt;/a&gt;)&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In evidence in the Washington Post graphic is a judicious &lt;strong&gt;mapping&lt;/strong&gt; of data to visuals, underpinned by a secure understanding of analysis context. This act of carefully considering how best to leverage visual systems given the available data and analysis priorities is key to designing effective data graphics.&lt;/p&gt;
&lt;p&gt;In the late 1990s Leland Wilkinson, a Computer Scientist and Statistician, introduced the &lt;a href=&#34;https://www.springer.com/gp/book/9780387245447&#34;&gt;Grammar of Graphics&lt;/a&gt; as an approach that formalises this process of turning data into visuals. &lt;span class=&#34;citation&#34;&gt;Wilkinson (&lt;a href=&#34;#ref-wilkinson_grammar_1999&#34; role=&#34;doc-biblioref&#34;&gt;1999&lt;/a&gt;)&lt;/span&gt;’s thesis is that if graphics can be described in a consistent way according to their structure and composition, then the process of &lt;strong&gt;generating&lt;/strong&gt; graphics of different types can be systematised. This has obvious benefits for building visualization toolkits: it makes it easy to specify chart types and combinations and helps formalise the process of designing data visualizations. &lt;a href=&#34;https://vega.github.io/vega-lite/&#34;&gt;vega-lite&lt;/a&gt;, &lt;a href=&#34;https://www.tableau.com/en-gb&#34;&gt;Tableau&lt;/a&gt; and &lt;a href=&#34;https://ggplot2.tidyverse.org/&#34;&gt;&lt;code&gt;ggplot2&lt;/code&gt;&lt;/a&gt; are all underpinned by &lt;a href=&#34;https://www.springer.com/gp/book/9780387245447&#34;&gt;Grammar of Graphics&lt;/a&gt; thinking.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;citation&#34;&gt;Wilkinson (&lt;a href=&#34;#ref-wilkinson_grammar_1999&#34; role=&#34;doc-biblioref&#34;&gt;1999&lt;/a&gt;)&lt;/span&gt;’s grammar separates the construction of a data graphic into a series of components. Below are the components of the &lt;em&gt;Layered Grammar of Graphics&lt;/em&gt; on which &lt;a href=&#34;https://ggplot2.tidyverse.org/&#34;&gt;&lt;code&gt;ggplot2&lt;/code&gt;&lt;/a&gt; is based &lt;span class=&#34;citation&#34;&gt;(Wickham &lt;a href=&#34;#ref-wickham_layered_2010&#34; role=&#34;doc-biblioref&#34;&gt;2010&lt;/a&gt;)&lt;/span&gt;, a slight edit on &lt;span class=&#34;citation&#34;&gt;Wilkinson (&lt;a href=&#34;#ref-wilkinson_grammar_1999&#34; role=&#34;doc-biblioref&#34;&gt;1999&lt;/a&gt;)&lt;/span&gt;’s original work.&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: left&#34;&gt;&lt;span id=&#34;fig:gog&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;./class/03-class_files/gog.png&#34; alt=&#34;Components of @wickham_layered_2010&#39;s Layered Grammar of Graphics.&#34; width=&#34;80%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 2: Components of &lt;span class=&#34;citation&#34;&gt;Wickham (&lt;a href=&#34;#ref-wickham_layered_2010&#34; role=&#34;doc-biblioref&#34;&gt;2010&lt;/a&gt;)&lt;/span&gt;’s Layered Grammar of Graphics.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The seven components in Figure &lt;a href=&#34;#fig:gog&#34;&gt;2&lt;/a&gt; are together used to create &lt;a href=&#34;https://ggplot2.tidyverse.org/&#34;&gt;&lt;code&gt;ggplot2&lt;/code&gt;&lt;/a&gt; specifications. The aspects to emphasise at this stage are those in emphasis, which are required in any &lt;code&gt;ggplot2&lt;/code&gt; specification: the &lt;span style=&#34;color:#5A91CA;font-weight:bold&#34;&gt;data&lt;/span&gt; containing the variables of interest, the &lt;code&gt;geom&lt;/code&gt; or &lt;span style=&#34;color:#E17637;font-weight:bold&#34;&gt;marks&lt;/span&gt; to be used to represent data and the &lt;strong&gt;aesthetic&lt;/strong&gt; (&lt;code&gt;mapping=aes(...)&lt;/code&gt;) attributes, or visual &lt;span style=&#34;color:#62B743;font-weight:bold&#34;&gt;channels&lt;/span&gt; through which variables are to be encoded.&lt;/p&gt;
&lt;p&gt;To demonstrate this, let’s generate some scatterplots based on the 2019 General Election data we will be analysing later in the session. Two variables worth exploring for association here are: &lt;code&gt;con_1719&lt;/code&gt;, the change in Conservative vote share by constituency between 2017-2019, and &lt;code&gt;leave_hanretty&lt;/code&gt;, the size of the Leave vote in the 2016 EU referendum, estimated at Parliamentary Constituency level &lt;span class=&#34;citation&#34;&gt;(see Hanretty &lt;a href=&#34;#ref-hanretty_areal_2017&#34; role=&#34;doc-biblioref&#34;&gt;2017&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:gog-demo&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;./class/03-class_files/gog-demo.png&#34; alt=&#34;Plots, grammars and associated `ggplot2` specifications for the scatterplot.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 3: Plots, grammars and associated &lt;code&gt;ggplot2&lt;/code&gt; specifications for the scatterplot.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;In Figure &lt;a href=&#34;#fig:gog-demo&#34;&gt;3&lt;/a&gt; are three plots and associated &lt;code&gt;ggplot2&lt;/code&gt; specifications. Reading-off the graphics and the associated code, you should get a feel for how &lt;code&gt;ggplot2&lt;/code&gt; specifications are constructed:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;We start with a data frame, in this case each observation is an electoral result for a Parliamentary Constituency. In the &lt;code&gt;ggplot2&lt;/code&gt; spec this is passed using the pipe operator (&lt;code&gt;data_ge %&amp;gt;%&lt;/code&gt;). We also identify the variables we wish to encode and their measurement &lt;span style=&#34;color:#5A91CA;font-weight:bold&#34;&gt;type&lt;/span&gt;. Remembering last session’s materials, both &lt;code&gt;con_1719&lt;/code&gt; and &lt;code&gt;leave_hanretty&lt;/code&gt; are &lt;code&gt;ratio&lt;/code&gt; scale variables.&lt;/li&gt;
&lt;li&gt;Next is the encoding (&lt;code&gt;mapping=aes()&lt;/code&gt;), which determines how the data are to be mapped to visual &lt;span style=&#34;color:#62B743;font-weight:bold&#34;&gt;channels&lt;/span&gt;. A scatterplot is a 2d representation in which horizontal and vertical position varies in a meaningful way, in response to the values of a data set. Here the values of &lt;code&gt;leave_hanretty&lt;/code&gt; are mapped along the x-axis and the values of &lt;code&gt;con_1719&lt;/code&gt; are mapped along the y-axis.&lt;/li&gt;
&lt;li&gt;Finally, we represent individual data items with &lt;span style=&#34;color:#E17637;font-weight:bold&#34;&gt;marks&lt;/span&gt; using the &lt;code&gt;geom_point&lt;/code&gt; geometry.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In the middle plot, the grammar is updated such that the points are coloured according to &lt;code&gt;winning_party&lt;/code&gt;, a variable of type categorical &lt;code&gt;nominal&lt;/code&gt;. In the bottom plot constituencies that flipped from Labour-to-Conservative between 2017-19 are emphasised by varying the transparency (&lt;code&gt;alpha&lt;/code&gt;) of points. I have described &lt;code&gt;flipped&lt;/code&gt; as an &lt;code&gt;ordinal&lt;/code&gt; variable, but strictly it is a &lt;code&gt;nominal&lt;/code&gt; (binary) variable. Due to the way it is encoded in the plot – constituencies that flipped (&lt;code&gt;flipped=TRUE&lt;/code&gt;) are given greater visual emphasis – I think it is more appropriate to call it an ordinal variable.&lt;/p&gt;
&lt;p&gt;

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    It is understandable if at this stage the specifications in Figure &lt;a href=&#34;#fig:gog-demo&#34;&gt;3&lt;/a&gt; still seem alien to you. We will be updating, expanding and refining &lt;code&gt;ggplot2&lt;/code&gt; specifications throughout this module to support all aspects of modern data analysis – from data cleaning and exploratory analysis through to model evaluation and communication.
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;marks-and-visual-channels&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Marks and visual channels&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Effective data visualization design is concerned with representing data through marks and visual channels in a way that best conveys the properties of the data that are to be depicted.&lt;/p&gt;
&lt;p&gt;via &lt;a href=&#34;https://www.gicentre.net/jwo/index&#34;&gt;Jo Wood&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;You might have noticed that in my descriptions of &lt;code&gt;ggplot2&lt;/code&gt; specifications I introduced &lt;span style=&#34;color:#E17637;font-weight:bold&#34;&gt;marks&lt;/span&gt; as another term for &lt;strong&gt;geometry&lt;/strong&gt; and visual encoding &lt;span style=&#34;color:#62B743;font-weight:bold&#34;&gt;channels&lt;/span&gt; as another term for &lt;strong&gt;aesthetics&lt;/strong&gt;. I also paid special attention to the &lt;span style=&#34;color:#5A91CA;font-weight:bold&#34;&gt;data types&lt;/span&gt; that are being encoded.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Marks&lt;/strong&gt; are graphical elements such as &lt;em&gt;bars&lt;/em&gt;, &lt;em&gt;lines&lt;/em&gt;, &lt;em&gt;points&lt;/em&gt;, &lt;em&gt;ellipses&lt;/em&gt; that can be used to represent data items – in &lt;code&gt;ggplot2&lt;/code&gt;, these are accessed through the functions prefaced with &lt;a href=&#34;https://ggplot2.tidyverse.org/reference/#section-geoms&#34;&gt;&lt;code&gt;geom_*&lt;/code&gt;&lt;/a&gt;. Visual &lt;strong&gt;channels&lt;/strong&gt; are attributes such as &lt;em&gt;colour&lt;/em&gt;, &lt;em&gt;size&lt;/em&gt;, &lt;em&gt;position&lt;/em&gt; that, when mapped to data, control the appearance of marks in response to the values of a dataset. Not all &lt;strong&gt;channels&lt;/strong&gt; are equally effective. In fact we can say confidently that for particular &lt;strong&gt;data types&lt;/strong&gt; and tasks, some &lt;strong&gt;channels&lt;/strong&gt; perform better than others.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Marks&lt;/strong&gt; and &lt;strong&gt;channels&lt;/strong&gt; are terms used in the interface of &lt;a href=&#34;https://www.tableau.com/en-gb&#34;&gt;Tableau&lt;/a&gt; and in &lt;a href=&#34;https://vega.github.io/vega-lite/&#34;&gt;vega-lite&lt;/a&gt; specifications. They are also used widely in Information Visualization, an academic discipline devoted to the study of data graphics, and most notably by Tamara &lt;span class=&#34;citation&#34;&gt;Munzner (&lt;a href=&#34;#ref-munzner_visualization_2014&#34; role=&#34;doc-biblioref&#34;&gt;2014&lt;/a&gt;)&lt;/span&gt; in her textbook &lt;a href=&#34;https://www.routledge.com/Visualization-Analysis-and-Design/Munzner/p/book/9781466508910&#34;&gt;&lt;em&gt;Visualization Analysis and Design&lt;/em&gt;&lt;/a&gt;. &lt;span class=&#34;citation&#34;&gt;Munzner (&lt;a href=&#34;#ref-munzner_visualization_2014&#34; role=&#34;doc-biblioref&#34;&gt;2014&lt;/a&gt;)&lt;/span&gt;’s work is important and widely adopted as it synthesises over foundational research in Information Visualization and Cognitive Science testing how effective different visual channels are at supporting different tasks.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:munzner&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;./class/03-class_files/munzner.png&#34; alt=&#34;Visual channels to which data items can be encoded, as they appear in @munzner_visualization_2014.&#34; width=&#34;90%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 4: Visual channels to which data items can be encoded, as they appear in &lt;span class=&#34;citation&#34;&gt;Munzner (&lt;a href=&#34;#ref-munzner_visualization_2014&#34; role=&#34;doc-biblioref&#34;&gt;2014&lt;/a&gt;)&lt;/span&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Figure
&lt;a href=&#34;#fig:munzner&#34;&gt;4&lt;/a&gt; is taken from Chapter 5 of &lt;span class=&#34;citation&#34;&gt;Munzner (&lt;a href=&#34;#ref-munzner_visualization_2014&#34; role=&#34;doc-biblioref&#34;&gt;2014&lt;/a&gt;)&lt;/span&gt; and lists the main visual channels with which data might be encoded. The grouping and order of the Figure is meaningful. Channels are grouped according to the tasks to which they are best suited and then ordered according to their effectiveness at supporting those tasks. To the left are &lt;strong&gt;magnitude:order&lt;/strong&gt; channels – those that are best suited to tasks aimed at quantifying data items. Tothe Right are &lt;strong&gt;identify:category&lt;/strong&gt; channels – those that are most suited to supporting tasks that involve isolating, grouping and associating data items.&lt;/p&gt;
&lt;p&gt;We can use this organisation of visual channels to make decisions about appropriate encodings given a variable’s measurement level. If we wished to convey the magnitude of something, for example a quantitative (&lt;code&gt;ratio&lt;/code&gt;) variable like the size of the Conservative vote share in a constituency, we might select a channel that has good quantitative effectiveness – &lt;em&gt;position on a common scale&lt;/em&gt; or &lt;em&gt;length&lt;/em&gt;. If we wished to also effectively identify and associate constituencies according to the political party that was elected, a categorical &lt;code&gt;nominal&lt;/code&gt; variable, we might select a channel that has good associative properties such as &lt;em&gt;colour hue&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;evaluating-designs&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Evaluating designs&lt;/h3&gt;
&lt;p&gt;The effectiveness rankings of visual channels in Figure &lt;a href=&#34;#fig:munzner&#34;&gt;4&lt;/a&gt; are not simply based on Munzner’s preference. They are informed by detailed experimental work – &lt;span class=&#34;citation&#34;&gt;Cleveland and McGill (&lt;a href=&#34;#ref-cleveland_graphical_1984&#34; role=&#34;doc-biblioref&#34;&gt;1984&lt;/a&gt;)&lt;/span&gt;, later replicated by &lt;span class=&#34;citation&#34;&gt;Heer and Bostock (&lt;a href=&#34;#ref-heer_crowdsourcing_2010&#34; role=&#34;doc-biblioref&#34;&gt;2010&lt;/a&gt;)&lt;/span&gt; – which involved conducting controlled experiments testing people’s ability to make judgements from graphical elements. We can use Figure &lt;a href=&#34;#fig:munzner&#34;&gt;4&lt;/a&gt; to help make decisions around which data item to encode with which
visual channel. This is particularly useful when designing data-rich graphics, where several data items are to be encoded
simultaneously. The Figure also offers a low cost way of &lt;strong&gt;evaluating&lt;/strong&gt; different designs against their encoding effectiveness. To illustrate this, we can use Munzner’s ranking of channels to evaluate the Washington Post graphic discussed in Figure &lt;a href=&#34;#fig:wp-map&#34;&gt;1&lt;/a&gt;.&lt;/p&gt;
&lt;table&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:wp-eval-size&#34;&gt;Table 2: &lt;/span&gt;Encoding effectiveness for Washington Post graphic that emphasises &lt;em&gt;vote margin and size&lt;/em&gt; of counties using triangle marks.
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Mark
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Data item
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Type
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Channel
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Rank
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr grouplength=&#34;4&#34;&gt;
&lt;td colspan=&#34;5&#34; style=&#34;border-bottom: 0px solid;&#34;&gt;
&lt;strong&gt;Magnitude:Order&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left; padding-left:  2em;width: 7em; &#34; indentlevel=&#34;1&#34;&gt;
&lt;html&gt;
&lt;body&gt;
&lt;img src=&#34;./class/03-class_files/location.png&#34;&gt;
&lt;/body&gt;
&lt;/html&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Location
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;code&gt;ratio&lt;/code&gt; (&lt;code&gt;cyclic&lt;/code&gt;)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
position in x,y
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;quant
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left; padding-left:  2em;width: 7em; &#34; indentlevel=&#34;1&#34;&gt;
&lt;html&gt;
&lt;body&gt;
&lt;img src=&#34;./class/03-class_files/height.png&#34;&gt;
&lt;/body&gt;
&lt;/html&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Votes cast (~pop size)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;code&gt;ratio&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
length
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;ol start=&#34;3&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;quant
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left; padding-left:  2em;width: 7em; &#34; indentlevel=&#34;1&#34;&gt;
&lt;html&gt;
&lt;body&gt;
&lt;img src=&#34;./class/03-class_files/width.png&#34;&gt;
&lt;/body&gt;
&lt;/html&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Margin
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;code&gt;ratio&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
length
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;ol start=&#34;3&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;quant
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left; padding-left:  2em;width: 7em; &#34; indentlevel=&#34;1&#34;&gt;
&lt;html&gt;
&lt;body&gt;
&lt;img src=&#34;./class/03-class_files/landslide.png&#34;&gt;
&lt;/body&gt;
&lt;/html&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Landslide
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;code&gt;ordinal&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
area
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;ol start=&#34;5&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;quant
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr grouplength=&#34;1&#34;&gt;
&lt;td colspan=&#34;5&#34; style=&#34;border-bottom: 0px solid;&#34;&gt;
&lt;strong&gt;Identify:Category&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left; padding-left:  2em;width: 7em; &#34; indentlevel=&#34;1&#34;&gt;
&lt;html&gt;
&lt;body&gt;
&lt;img src=&#34;./class/03-class_files/winner.png&#34;&gt;
&lt;/body&gt;
&lt;/html&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Winner
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;code&gt;nominal&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
colour hue
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;cat
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Table &lt;a href=&#34;#tab:wp-eval-size&#34;&gt;2&lt;/a&gt; provides a summary of the encodings used in the version of the graphic emphasising &lt;em&gt;vote margin and size&lt;/em&gt;. US counties are represented using a peak-shaped &lt;strong&gt;mark&lt;/strong&gt; (&lt;i class=&#34;fas fa-angle-up&#34;&gt;&lt;/i&gt;). The key purpose of the graphic is to depict the geography of voting outcomes, and so the most effective quantitative channel – position on an aligned scale – is used to order the county marks (&lt;i class=&#34;fas fa-angle-up&#34;&gt;&lt;/i&gt;) with a 2D geographic arrangement. With the positional channels taken, the two quantitive measures, &lt;em&gt;votes cast&lt;/em&gt; and &lt;em&gt;result margin&lt;/em&gt;, are encoded with the next highest ranked channel, 1D length: height varies according to number of &lt;em&gt;votes cast&lt;/em&gt; and width according to &lt;em&gt;result margin&lt;/em&gt;. The marks are additionally encoded with two categorical variables: whether the county-level result was a &lt;em&gt;landslide&lt;/em&gt; and also the ultimate &lt;em&gt;winner&lt;/em&gt;. Since the intention is to give greater visual saliency to counties that resulted in a &lt;em&gt;landslide&lt;/em&gt;, this as an &lt;code&gt;ordinal&lt;/code&gt; variable, encoded with a quantitative channel: 2D area. The &lt;em&gt;winning party&lt;/em&gt;, a categorical &lt;code&gt;nominal&lt;/code&gt; variable, is encoded using colour hue.&lt;/p&gt;
&lt;p&gt;Each of the encoding choices used in the graphic follow conventional wisdom in that data items are encoded using visual channels that are appropriate to their measurement level. Glancing down the “rank” column we can also argue that the graphic has high effectiveness. Whilst technically &lt;em&gt;spatial region&lt;/em&gt; is the most effective channel for encoding &lt;code&gt;nominal&lt;/code&gt; data, it is already in use in our graphic as the &lt;i class=&#34;fas fa-angle-up&#34;&gt;&lt;/i&gt; marks are arranged by geographic position. Additionally, it makes sense to distinguish &lt;span style=&#34;color:#DB534D;font-weight:bold&#34;&gt;Republican&lt;/span&gt; and &lt;span style=&#34;color:#3879A1;font-weight:bold&#34;&gt;Democrat&lt;/span&gt; wins using the colours with which they are always represented. Given the fact that the positional channels are in use to represent geographic &lt;em&gt;location&lt;/em&gt;, length to represent &lt;em&gt;votes cast&lt;/em&gt; and &lt;em&gt;vote margin&lt;/em&gt;, the only superior visual channel to 2D area that could be used to encode the &lt;em&gt;landslide&lt;/em&gt; variable is &lt;em&gt;orientation&lt;/em&gt;. There are very good reasons for not varying the orientation of the &lt;i class=&#34;fas fa-angle-up&#34;&gt;&lt;/i&gt; marks. Most obvious is that this would clearly undermine perception of length encodings used to represent the vote margin (width) and absolute vote size (height).&lt;/p&gt;
&lt;p&gt;

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Data visualization design almost always involves trade-offs. When deciding on a design configuration, it is necessary to prioritise analysis tasks and data and match representations and encodings that are most effective to the tasks that are most important. This then constrains the encoding options for less important data items and tasks. Good visualization design is sensitive to this interplay between tasks, data and encoding.
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;symbolisation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Symbolisation&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Symbolization is the process of encoding something with meaning in order to represent something else. Effective symbol design requires that the relationship between a symbol and the information that symbol represents (the referent) be clear and easily interpreted.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;citation&#34;&gt;White (&lt;a href=&#34;#ref-white_symbolization_2017&#34; role=&#34;doc-biblioref&#34;&gt;2017&lt;/a&gt;)&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Implicit in the discussion above, and when making design decisions, is the importance of &lt;a href=&#34;https://gistbok.ucgis.org/bok-topics/symbolization-and-visual-variables&#34;&gt;&lt;strong&gt;symbolisation&lt;/strong&gt;&lt;/a&gt;. Scrolling through the original Washington Post article, the overall pattern that can be discerned is of population-dense coastal and metropolitan counties voting Democrat – densely-packed, tall, wide and blue &lt;i style=&#34;color:#3879A1;font-weight:bold&#34; class=&#34;fas fa-lg fa-angle-up&#34;&gt;&lt;/i&gt; marks – contrasted against population-sparse rural and small town areas voting Republican – short, wide and red &lt;i style=&#34;color:#DB534D;font-weight:bold&#34; class=&#34;fas fa-angle-up&#34;&gt;&lt;/i&gt; marks. The graphic evokes a distinctive landscape of voting behaviour, emphasised by its caption: “&lt;em&gt;The peaks and valleys of Trump and Clinton’s support&lt;/em&gt;”.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Symbolisation&lt;/strong&gt; is used equally well in the variant of the graphic emphasising two-party &lt;em&gt;Swing&lt;/em&gt; between the 2012 and 2016 elections. Each county is represented as a &lt;span style=&#34;font-weight:bolder&#34;&gt;|&lt;/span&gt; mark. The &lt;em&gt;Swing&lt;/em&gt; variable is then encoded by continuously varying mark angles: counties swinging Republican are angled to the right &lt;span style=&#34;color:#DB534D;font-weight:bold&#34;&gt;/&lt;/span&gt;; counties swinging Democrat are angled to the left &lt;span style=&#34;color:#3879A1;font-weight:bolder&#34;&gt;\&lt;/span&gt;. Although &lt;em&gt;angle&lt;/em&gt; is a less effective channel at encoding quantities than is &lt;em&gt;length&lt;/em&gt;, there are obvious links to the political phenomena in the symbolisation – angled right for counties that moved to the right politically. Additionally, the variable itself might be regarded as cyclic – or at least it has a ceiling with an important mid-point that requires emphasis. It is worth taking a second look at the full graphic here. Since there is spatial autocorrelation in case trajectories, we quickly assemble from the graphic dominant patterns of Swing to the Republicans (Great Lakes, rural East Coast), predictable Republican stasis (the mid west) and to detect more isolated, locally exceptional Swings to the Democrats (rapidly urbanising counties in the deep south).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;checking-perceptual-rankings&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Checking perceptual rankings&lt;/h3&gt;
&lt;p&gt;I mentioned that Munzner’s effectiveness ordering of visual channels is informed by empirical evidence – controlled experiments that examine perceptual abilities at making judgements from graphical primitives. It is worth elaborating a little on this experimental work, and on how established knowledge in Cognitive Science can be used to inform design choices.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;citation&#34;&gt;Cleveland (&lt;a href=&#34;#ref-cleveland_elements_1993&#34; role=&#34;doc-biblioref&#34;&gt;1993&lt;/a&gt;)&lt;/span&gt; emphasises three perceptual activities that take place when we make sense of data graphics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Detection&lt;/strong&gt; : the element of the graphic must be easily discernible.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Assembly&lt;/strong&gt; : the process of identifying patterns and structure within the graphical elements of the
visualization.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Estimation&lt;/strong&gt; : the process of making comparisons of the magnitudes of data items from the visual elements used.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These activities can be related to the categories of task outlined earlier. &lt;strong&gt;Detection&lt;/strong&gt; is especially important for &lt;strong&gt;selective&lt;/strong&gt; and &lt;strong&gt;associative&lt;/strong&gt; tasks that involve isolating and grouping data items, whilst &lt;strong&gt;estimation&lt;/strong&gt; is necessary for tasks that are &lt;strong&gt;orderable&lt;/strong&gt; and &lt;strong&gt;quantitative&lt;/strong&gt;, involving the ranking and reading-off of quantities.&lt;/p&gt;
&lt;div id=&#34;detection-and-preattentive-processing&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Detection and preattentive processing&lt;/h4&gt;
&lt;p&gt;A useful distinction when considering graphical cognition is between processes that are attentive and pre-attentive &lt;span class=&#34;citation&#34;&gt;(Ware &lt;a href=&#34;#ref-ware_visual_2008&#34; role=&#34;doc-biblioref&#34;&gt;2008&lt;/a&gt;)&lt;/span&gt;. Attentive processing describes the conscious processing that happens when we attempt to make sense of a visual field. Preattentive processing happens unconsciously and is the type of cognitive processing that allows something to be understood ‘at a glance’. Visual items that immediately pop-out to us induce preattentive processing.&lt;/p&gt;
&lt;p&gt;The ability to provoke pop-out – making some things on a data graphic more easily detectible than others – relates to &lt;strong&gt;detection&lt;/strong&gt;. It can be useful for supporting &lt;strong&gt;selective&lt;/strong&gt; and &lt;strong&gt;associative&lt;/strong&gt; tasks, and so is often used in a data graphic to encode categorical variables. For example, in the Washington Post graphic the use of colour hue to differentiate and group together counties that voted Republican or Democrat. Preattentive processes can also apply to &lt;strong&gt;assembly&lt;/strong&gt;. We naturally construct and assemble patterns that are smooth and continuous when perceiving a graphic and so deviations from this continuity are often attended to unconsciously. An example here would be those urbanising counties in the deep South, which were locally exceptional in swinging to Democrat (to the left).&lt;/p&gt;
&lt;p&gt;We can test this preattentive processing by using visual encoding channels to assist a task that requires us to &lt;strong&gt;select&lt;/strong&gt; and &lt;strong&gt;associate&lt;/strong&gt; visual items. Below are a set of data graphics containing 200 numbers. The graphics are currently hidden, but can be revealed by clicking the &lt;i class=&#34;fa fa-xs fa-play&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt; icon. For each graphic I want you to scan across the number, isolate or select the number &lt;code&gt;3&lt;/code&gt;, then group or associate the &lt;code&gt;3&lt;/code&gt;s together and count the number of instances that they occur. Speed is important here – so work as quickly as you can.&lt;/p&gt;
&lt;p&gt;First, a set of numbers without applying any special encoding to the number &lt;code&gt;3&lt;/code&gt;.&lt;/p&gt;


&lt;div class=&#34;alert alert-instruction&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;Encoding: &lt;strong&gt;none&lt;/strong&gt;&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-0&#34;&gt;
  &lt;summary&gt;&lt;/summary&gt;
  &lt;p&gt;&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:no-encoding&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;./class/03-class_files/no-encoding.png&#34; alt=&#34;Encoding: *none*.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 5: Encoding: &lt;em&gt;none&lt;/em&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;/p&gt;
&lt;/details&gt;
Isolate/select &lt;code&gt;3&lt;/code&gt; from the list of numbers and count its number of occurrences.

  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;If you were racing to complete the task, I imagine you found it moderately stressful. Let’s explore using visual encoding to off-load some of this cognitive effort. We’ll start with a visual channel that does not have particularly strong preattentive properties: &lt;em&gt;area&lt;/em&gt;.&lt;/p&gt;


&lt;div class=&#34;alert alert-instruction&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;Encoding: &lt;strong&gt;area&lt;/strong&gt;&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-0&#34;&gt;
  &lt;summary&gt;&lt;/summary&gt;
  &lt;p&gt;&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:area-encoding&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;./class/03-class_files/area-encoding.png&#34; alt=&#34;Encoding: *area*.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 6: Encoding: &lt;em&gt;area&lt;/em&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;/p&gt;
&lt;/details&gt;
Isolate/select &lt;code&gt;3&lt;/code&gt; from the list of numbers and count its number of occurrences.

  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;Using visualization to support the task makes it an order of magnitude easier. But let’s explore some visual channels that have even more powerful properties. I mentioned that tilt/angle has preattentive properties where the data items to be emphasised deviate from some regular pattern. In the graphic below, the number &lt;code&gt;3&lt;/code&gt; is encoded with &lt;em&gt;tilt&lt;/em&gt; or &lt;em&gt;angle&lt;/em&gt;.&lt;/p&gt;


&lt;div class=&#34;alert alert-instruction&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;Encoding: &lt;strong&gt;angle&lt;/strong&gt;&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-0&#34;&gt;
  &lt;summary&gt;&lt;/summary&gt;
  &lt;p&gt;&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:angle-encoding&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;./class/03-class_files/angle-encoding.png&#34; alt=&#34;Encoding: *tilt/angle*.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 7: Encoding: &lt;em&gt;tilt/angle&lt;/em&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;/p&gt;
&lt;/details&gt;
Isolate/select &lt;code&gt;3&lt;/code&gt; from the list of numbers and count its number of occurrences.

  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;This is in fact more challenging than the size encoding. I think this is most likely because the geometric patterns of the marks used (numbers) is being varied and so this limits the extent to which we unconsciously perceive smoothness and continuity (e.g. limits &lt;strong&gt;assembly&lt;/strong&gt;).&lt;/p&gt;
&lt;p&gt;Next we’ll use a visual channel with known effectiveness at assisting select and associate tasks. &lt;em&gt;Colour hue&lt;/em&gt; appears as the second-ranked most effective in &lt;span class=&#34;citation&#34;&gt;Munzner (&lt;a href=&#34;#ref-munzner_visualization_2014&#34; role=&#34;doc-biblioref&#34;&gt;2014&lt;/a&gt;)&lt;/span&gt;’s ordering.&lt;/p&gt;


&lt;div class=&#34;alert alert-instruction&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;Encoding: &lt;strong&gt;colour hue&lt;/strong&gt;&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-0&#34;&gt;
  &lt;summary&gt;&lt;/summary&gt;
  &lt;p&gt;&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:hue-encoding&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;./class/03-class_files/hue-encoding.png&#34; alt=&#34;Encoding: *colour hue*.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 8: Encoding: &lt;em&gt;colour hue&lt;/em&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;/p&gt;
&lt;/details&gt;
Isolate/select &lt;code&gt;3&lt;/code&gt; from the list of numbers and count its number of occurrences.

  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;Finally, though a slightly contrived example, we can use the top-ranked channel according to &lt;span class=&#34;citation&#34;&gt;Munzner (&lt;a href=&#34;#ref-munzner_visualization_2014&#34; role=&#34;doc-biblioref&#34;&gt;2014&lt;/a&gt;)&lt;/span&gt;: &lt;em&gt;spatial region&lt;/em&gt;.&lt;/p&gt;


&lt;div class=&#34;alert alert-instruction&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;Encoding: &lt;strong&gt;spatial region&lt;/strong&gt;&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-0&#34;&gt;
  &lt;summary&gt;&lt;/summary&gt;
  &lt;p&gt;&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:spatial-encoding&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;./class/03-class_files/spatial-encoding.png&#34; alt=&#34;Encoding: *spatial region*.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 9: Encoding: &lt;em&gt;spatial region&lt;/em&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;/p&gt;
&lt;/details&gt;
Isolate/select &lt;code&gt;3&lt;/code&gt; from the list of numbers and count its number of occurrences.

  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;estimation&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Estimation&lt;/h4&gt;
&lt;p&gt;The informal tests above hopefully persuade you of &lt;span class=&#34;citation&#34;&gt;Munzner (&lt;a href=&#34;#ref-munzner_visualization_2014&#34; role=&#34;doc-biblioref&#34;&gt;2014&lt;/a&gt;)&lt;/span&gt;’s ordering of &lt;em&gt;identity:category&lt;/em&gt; channels in the right side of Figure &lt;a href=&#34;#fig:munzner&#34;&gt;4&lt;/a&gt;. The ranking of &lt;em&gt;magnitude:order&lt;/em&gt; channels is also informed by established theory and evidence.&lt;/p&gt;
&lt;p&gt;When using data graphics to communicate quantities, certain visual channels are known to induce biases. &lt;a href=&#34;https://en.wikipedia.org/wiki/Psychophysics&#34;&gt;Psychophysics&lt;/a&gt; is a branch of psychology that develops methods aimed at capturing the often non-linear relationship between the properties of a &lt;em&gt;stimuli&lt;/em&gt; such as symbol length, area or colour value, and their &lt;em&gt;perceived response&lt;/em&gt;. Stevens’ power law is an empirically-derived relationship that models this effect. The power function takes the form:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(R=kS_n\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Where &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt; is the magnitude of the stimulus, for example, the absolute length of a line or area of a circle, &lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt; is the response, the perceived length and area, and &lt;span class=&#34;math inline&#34;&gt;\(_n\)&lt;/span&gt; is the power law exponent that varies with the type of stimulus. If there is a perfect linear mapping between the stimulus and response, &lt;span class=&#34;math inline&#34;&gt;\(_n\)&lt;/span&gt; is 1.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;citation&#34;&gt;Stevens and Guirao (&lt;a href=&#34;#ref-stevens_subjective_1963&#34; role=&#34;doc-biblioref&#34;&gt;1963&lt;/a&gt;)&lt;/span&gt;’ experimental work involved varying the length of lines and areas of squares and deriving power functions for their perception. For length, an exponent of ~1.0 was estimated; for area an exponent of 0.7. So whilst variation in length is accurately perceived, we &lt;em&gt;underestimate&lt;/em&gt; the size of areas as they increase. &lt;span class=&#34;citation&#34;&gt;Flannery (&lt;a href=&#34;#ref-flannery_subjective_1963&#34; role=&#34;doc-biblioref&#34;&gt;1971&lt;/a&gt;)&lt;/span&gt;’s work, which was concerned with the perception of quantities in graduated point maps, estimated an exponent of 0.87 for the perception of circle size.&lt;/p&gt;
&lt;p&gt;Experimental findings vary and so these models of human perception are also subject to variation. Nevertheless, corrections can be applied. In cartography a &lt;a href=&#34;https://makingmaps.net/2007/08/28/perceptual-scaling-of-map-symbols/&#34;&gt;Flannery compensation&lt;/a&gt; is used when representing quantities with area.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:perception&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;./class/03-class_files/perception.png&#34; alt=&#34;Differences in power law exponents for the perception of variation in length and area.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 10: Differences in power law exponents for the perception of variation in length and area.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    This early experimental work that tries to understand how encoded quantities are perceived is clearly important. But we use data graphics to do much more than estimate single quantities. If data graphics are to serve as tools for analysis, we also need some confidence that the &lt;strong&gt;inferences&lt;/strong&gt; made when studying data using graphics are accurate and reliable. In the Information Visualization domain, experimental work has recently been published exploring the perception of statistical quantities – dispersion &lt;span class=&#34;citation&#34;&gt;(Correll and Gleicher &lt;a href=&#34;#ref-correll_error_2014&#34; role=&#34;doc-biblioref&#34;&gt;2014&lt;/a&gt;)&lt;/span&gt;, correlation &lt;span class=&#34;citation&#34;&gt;(Rensink and Baldridge &lt;a href=&#34;#ref-rensink_perception_2010&#34; role=&#34;doc-biblioref&#34;&gt;2010&lt;/a&gt;; Chang &lt;a href=&#34;#ref-harrison_ranking_2014&#34; role=&#34;doc-biblioref&#34;&gt;2014&lt;/a&gt;; Kay and Heer &lt;a href=&#34;#ref-kay_beyond_2016&#34; role=&#34;doc-biblioref&#34;&gt;2016&lt;/a&gt;)&lt;/span&gt; and spatial autocorrelation &lt;span class=&#34;citation&#34;&gt;(Klippel, Hardisty, and Li &lt;a href=&#34;#ref-klippel_interpreting_2011&#34; role=&#34;doc-biblioref&#34;&gt;2011&lt;/a&gt;; Beecham et al. &lt;a href=&#34;#ref-beecham_maplineups_2017&#34; role=&#34;doc-biblioref&#34;&gt;2017&lt;/a&gt;)&lt;/span&gt; – in commonly used chart types. More on this later in the module.
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;colour&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Colour&lt;/h3&gt;
&lt;p&gt;As demonstrated in the section on &lt;a href=&#34;#detection-and-preattentive-processing-1&#34;&gt;preattentive processing&lt;/a&gt;, colour is very powerful visual channel. When considering how to encode data with colour, it is helpful to consider three properties:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Hue&lt;/strong&gt; : what we generally refer to as “colour” in everyday life – red, blue green, etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Saturation&lt;/strong&gt; : how much of a colour there is.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Luminance/Brightness&lt;/strong&gt; : how dark or light a colour is.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The underlying rule when using colour in data graphics is to use properties of colour that match the properties of the data. Categorical &lt;code&gt;nominal&lt;/code&gt; data – data that cannot be easily ordered – should be encoded using discrete colours with no obvious order: colour hue. Categorical &lt;code&gt;ordinal&lt;/code&gt; data – data whose categories can be ordered – should be encoded with colours that contain an intrinsic order: saturation or brightness, usually allocated into gradients. &lt;code&gt;Quantitative&lt;/code&gt; data – data that can be ordered and contain values on a continuous scale – should also be encoded with colours that contain an intrinsic order: saturation or brightness, expressed on a continuous scale.&lt;/p&gt;
&lt;p&gt;As we will discover shortly, these principles are applied by default in &lt;code&gt;ggplot2&lt;/code&gt;, along with access to perceptually uniform schemes. Its &lt;a href=&#34;https://ggplot2.tidyverse.org/reference/scale_brewer.html&#34;&gt;&lt;code&gt;brewer&lt;/code&gt;&lt;/a&gt; scales, for example.&lt;/p&gt;
&lt;p&gt;

&lt;div class=&#34;alert alert-instruction&#34;&gt;
  &lt;div&gt;
    There are many considerations when using colour to support visual data analysis and communication – and we will return to these at various points in the module. Read Lisa Charotte-Rost’s &lt;a href=&#34;https://blog.datawrapper.de/colorguide/&#34;&gt;Guide to Colours in Data Visualization&lt;/a&gt; before processing to the &lt;a href=&#34;#techniques-1&#34;&gt;Techniques&lt;/a&gt; section.
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;techniques&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Techniques&lt;/h2&gt;
&lt;p&gt;The technical element to this session involves analysing data from the 2019 UK General Election, reported by Parliamentary Constituency. After importing and describing the dataset, you will generate data graphics that expose patterns in voting behaviour. You will do so by writing &lt;code&gt;ggplot2&lt;/code&gt; specifications.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Download the &lt;a href=&#34;./homework/03-homework_files/03-template.Rmd&#34;&gt;&lt;i class=&#34;fab fa-r-project&#34;&gt;&lt;/i&gt; 03-template.Rmd&lt;/a&gt; file for this session and save it to the &lt;code&gt;reports&lt;/code&gt; folder of your &lt;code&gt;vis-for-gds&lt;/code&gt; project.&lt;/li&gt;
&lt;li&gt;Open your &lt;code&gt;vis-for-gds&lt;/code&gt; project in RStudio and load the template file by clicking &lt;code&gt;File&lt;/code&gt; &amp;gt; &lt;code&gt;Open File ...&lt;/code&gt; &amp;gt; &lt;code&gt;reports/03-template.Rmd&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;import&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Import&lt;/h3&gt;
&lt;p&gt;The template file lists the required packages – &lt;code&gt;tidyverse&lt;/code&gt;, &lt;code&gt;sf&lt;/code&gt; and also the &lt;a href=&#34;https://cran.r-project.org/web/packages/parlitools/index.html&#34;&gt;&lt;code&gt;parlitools&lt;/code&gt;&lt;/a&gt;. Installing &lt;code&gt;parlitools&lt;/code&gt; brings down the 2019 UK General Election dataset, along with other constituency-level datasets. Loading it with &lt;code&gt;library(parlitools)&lt;/code&gt; makes these data available to your R session.&lt;/p&gt;
&lt;p&gt;The dataset containing 2019 UK General Election data is called &lt;code&gt;bes_2019&lt;/code&gt;. This contains results data released by &lt;a href=&#34;https://commonslibrary.parliament.uk/research-briefings/cbp-8749/&#34;&gt;House of Commons Library&lt;/a&gt;. We can get a quick overview in the usual way – with a call to &lt;code&gt;glimpse(&amp;lt;dataset-name&amp;gt;)&lt;/code&gt;. The dataset’s variables are also described on the &lt;code&gt;parlitools&lt;/code&gt; &lt;a href=&#34;https://docs.evanodell.com/parlitools/articles/bes-2019.html&#34;&gt;web pages&lt;/a&gt;. You will notice that &lt;code&gt;bes_2019&lt;/code&gt; contains 650 rows, one for each Parliamentary Constituency, and 118 columns. Contained in the columns are variables reporting vote numbers and shares for the main political parties for 2019 and 2017 General Elections, as well as names and codes (&lt;code&gt;ID&lt;/code&gt;s) for each Parliamentary Constituency and the county, region and country in which they are contained. You might want to count the number of counties and regions in the UK, and the number of constituencies contained by counties and regions, using some of the &lt;code&gt;dplyr&lt;/code&gt; functions introduced in the last session – for example with calls to &lt;code&gt;group_by()&lt;/code&gt; and &lt;code&gt;count()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The aim of this analysis session is to get you familiar with &lt;code&gt;ggplot2&lt;/code&gt; specifications. We will be replicating some of the visual data analysis of the 2019 UK General Election in &lt;span class=&#34;citation&#34;&gt;Beecham (&lt;a href=&#34;#ref-beecham_using_2020&#34; role=&#34;doc-biblioref&#34;&gt;2020&lt;/a&gt;)&lt;/span&gt;, inspired by the &lt;a href=&#34;https://www.washingtonpost.com/graphics/politics/2016-election/election-results-from-coast-to-coast/&#34;&gt;Washington Post&lt;/a&gt; graphic. For this we need to calculate an additional variable – Butler Swing &lt;span class=&#34;citation&#34;&gt;(Butler and Van Beek &lt;a href=&#34;#ref-butler_why_1990&#34; role=&#34;doc-biblioref&#34;&gt;1990&lt;/a&gt;)&lt;/span&gt; – which represents the average change in share of the vote won by two parties contesting successive elections. Code for calculating this variable (named &lt;code&gt;swing_con_lab&lt;/code&gt;) is in the &lt;a href=&#34;./homework/03-homework_files/03-template.Rmd&#34;&gt;&lt;i class=&#34;fab fa-r-project&#34;&gt;&lt;/i&gt; 03-template.Rmd&lt;/a&gt;. Although initially intuitive, the measure takes a little interpretation. A Swing to the Conservatives, which we observe most often in this dataset, could happen in three ways:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;An increase in Conservative vote share and a decrease in Labour vote share.&lt;/li&gt;
&lt;li&gt;An increase in both Conservative and Labour vote share, but with the Conservative increase outstripping that of Labour’s.&lt;/li&gt;
&lt;li&gt;A decrease in both Conservative and Labour vote share, but with the Conservative decline being less severe than that of Labour’s.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Different from the US where “third parties” play a negligible role, scenarios 2 and 3 do occur in the UK. You will notice that &lt;code&gt;swing_con_lab&lt;/code&gt; is a signed value: positive indicates a Swing to Conservative, negative a Swing to Labour.&lt;/p&gt;
&lt;p&gt;The only other dataset to load is a &lt;code&gt;.geojson&lt;/code&gt; file containing the geometries of constituencies, collected originally from &lt;a href=&#34;https://geoportal.statistics.gov.uk/&#34;&gt;ONS Open Geography Portal&lt;/a&gt; and simplified using &lt;a href=&#34;https://github.com/mbloch/mapshaper&#34;&gt;mapshaper&lt;/a&gt;. This is a special class of data frame containing a &lt;a href=&#34;https://r-spatial.github.io/sf/articles/sf1.html&#34;&gt;Simple Features&lt;/a&gt; &lt;code&gt;geometry&lt;/code&gt; column – more on this later in the module.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;summarise&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Summarise&lt;/h3&gt;
&lt;p&gt;You will no doubt be familiar with the ultimate result of the 2019 General Election – a landslide Conservative victory that confounded expectations. To start, we can quickly compute some summary statistics around the vote. In the code block below, we count the number of seats won by party and overall vote share by party. For the latter, my code is a little more elaborate than I intended it to be. I needed to reshape the data frame using &lt;code&gt;pivot_wider()&lt;/code&gt; such that each row represents a vote for a party in a constituency. From here I computed in a single function the vote share for each party.&lt;/p&gt;
&lt;p&gt;Whilst the Conservative party hold 56% of constituencies, they won only 44% of the vote share. The equivalent stats for Labour are 31% and 32% respectively. Incidentally, whilst the Conservatives increased their share of constituencies from 2017 (where they had just 317, 49% of constituencies) their vote share increase was reasonably small – in 2017 they gained 42.5% of the vote.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Number of constituencies won by party.
bes_2019 %&amp;gt;%
  group_by(winner_19) %&amp;gt;%
  summarise(count=n()) %&amp;gt;%
  arrange(desc(count))
## # A tibble: 11 x 2
##    winner_19                        count
##    &amp;lt;chr&amp;gt;                            &amp;lt;int&amp;gt;
##  1 Conservative                       365
##  2 Labour                             202
##  3 Scottish National Party             48
##  4 Liberal Democrat                    11
##  5 Democratic Unionist Party            8
##  6 Sinn Fein                            7
##  7 Plaid Cymru                          4
##  8 Social Democratic &amp;amp; Labour Party     2
##  9 Alliance                             1
## 10 Green                                1
## 11 Speaker                              1

# Share of vote by party.
bes_2019 %&amp;gt;%
  select(constituency_name, total_vote_19, con_vote_19:alliance_vote_19) %&amp;gt;% # Select cols containing vote counts by party.
  pivot_longer(cols=con_vote_19:alliance_vote_19, names_to=&amp;quot;party&amp;quot;, values_to=&amp;quot;votes&amp;quot;) %&amp;gt;% # Pivot to make each row a vote for a party in a constituency.
  mutate(party=str_extract(party, &amp;quot;[^_]+&amp;quot;)) %&amp;gt;% # Use some regex to pull out party name.
  group_by(party) %&amp;gt;%
  summarise(vote_share=sum(votes, na.rm=TRUE)/sum(total_vote_19)) %&amp;gt;%
  arrange(desc(vote_share))

## # A tibble: 12 x 2
##    party    vote_share
##    &amp;lt;chr&amp;gt;         &amp;lt;dbl&amp;gt;
##  1 con         0.436
##  2 lab         0.321
##  3 ld          0.115
##  4 snp         0.0388
##  5 green       0.0270
##  6 brexit      0.0201
##  7 dup         0.00763
##  8 sf          0.00568
##  9 pc          0.00479
## 10 alliance    0.00419
## 11 sdlp        0.00371
## 12 uup         0.00291&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Below are some summary statistics computed over the newly created &lt;code&gt;swing_con_lab&lt;/code&gt; variable. As the Conservative and Labour votes are negligible in Northern Ireland, it makes sense to focus on Great Britain for our analysis of Con-Lab Swing and so the first step in the code is to create a new data frame filtering out Northern Ireland. We will work with this for the rest of the session.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data_gb &amp;lt;- bes_2019 %&amp;gt;%
  filter(region!=&amp;quot;Northern Ireland&amp;quot;)

data_gb %&amp;gt;%
  summarise(
    min_swing=min(swing_con_lab),
    max_swing=max(swing_con_lab),
    median_swing=median(swing_con_lab),
    num_swing=sum(swing_con_lab&amp;gt;0),
    num_landslide_con=sum(con_19&amp;gt;50, na.rm=TRUE),
    num_landslide_lab=sum(lab_19&amp;gt;50, na.rm=TRUE)
    )

## # A tibble: 1 x 6
##   min_swing max_swing median_swing num_swing num_landslide_con num_landslide_lab
##       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;     &amp;lt;int&amp;gt;             &amp;lt;int&amp;gt;             &amp;lt;int&amp;gt;
## 1     -6.47      18.4         4.44       599               280               120&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;plot-distributions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Plot distributions&lt;/h3&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:histogram&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;./class/03-class_files/hist.png&#34; alt=&#34;Histograms of Swing variable.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 11: Histograms of Swing variable.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Let’s get going with some &lt;code&gt;ggplot2&lt;/code&gt; specifications by plotting some of these variables. Below is the code for plotting a histogram of the Swing variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data_gb %&amp;gt;%
  ggplot(mapping=aes(swing_con_lab)) +
  geom_histogram()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A reminder of the general form of the &lt;code&gt;ggplot2&lt;/code&gt; specification (first covered in&lt;a href=&#34;#grammar-of-graphics-1&#34;&gt;Grammar of Graphics&lt;/a&gt; section):&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Start with some &lt;strong&gt;data&lt;/strong&gt;: &lt;code&gt;data_gb&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Define the &lt;strong&gt;encoding&lt;/strong&gt;: &lt;code&gt;mapping=aes()&lt;/code&gt;. In this case, we want to summarise over the &lt;code&gt;swing_con_lab&lt;/code&gt; variable.&lt;/li&gt;
&lt;li&gt;Specify the &lt;strong&gt;marks&lt;/strong&gt; to be used: &lt;code&gt;geom_histogram()&lt;/code&gt; in this case.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Different from the scatterplot example, there is more happening in the internals of &lt;code&gt;ggplot2&lt;/code&gt; when creating a histogram. Technically &lt;code&gt;geom_histogram&lt;/code&gt; is what &lt;span class=&#34;citation&#34;&gt;Munzner (&lt;a href=&#34;#ref-munzner_visualization_2014&#34; role=&#34;doc-biblioref&#34;&gt;2014&lt;/a&gt;)&lt;/span&gt; would describe as a &lt;em&gt;chart idiom&lt;/em&gt; rather than a &lt;em&gt;mark&lt;/em&gt; (geometric primitive). The Swing variable is partitioned into bins and observations in each bin are counted. The x-axis (bins) and y-axis (counts by bin) is therefore derived from the supplied variable (&lt;code&gt;swing_con_lab&lt;/code&gt;). Should you wish, you could enter &lt;code&gt;?geom_histogram&lt;/code&gt; for fuller detail and documentation around controlling bin sizes amongst other things.&lt;/p&gt;
&lt;p&gt;You will notice that by default the histogram’s bars are given a grey colour. To &lt;em&gt;set&lt;/em&gt; them to a different colour, add a &lt;code&gt;fill=&lt;/code&gt; argument to &lt;code&gt;geom_histogram()&lt;/code&gt;. In the code block below, colour is set using &lt;a href=&#34;https://en.wikipedia.org/wiki/Web_colors&#34;&gt;hex codes&lt;/a&gt; – &lt;code&gt;&#34;#003c8f&#34;&lt;/code&gt;, based on the theme for this course website. I use the term &lt;em&gt;set&lt;/em&gt; here and not &lt;em&gt;map&lt;/em&gt; or &lt;em&gt;encode&lt;/em&gt; and there is a principled explanation for this. Any part of a &lt;code&gt;ggplot2&lt;/code&gt; specification that involves encoding data – mapping data to a visual channel – should be specified through the &lt;code&gt;mapping=aes()&lt;/code&gt; argument. Anything else, for example changing the default colour of marks, their thickness and transparency, needs to be &lt;em&gt;set&lt;/em&gt; outside of this argument.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data_gb %&amp;gt;%
  ggplot(mapping=aes(swing_con_lab)) +
  geom_histogram(fill=&amp;quot;#003c8f&amp;quot;) +
  labs(
    title=&amp;quot;Butler two-party Labour-Conservative Swing for Constituencies in GB&amp;quot;,
    subtitle=&amp;quot;-- 2019 versus 2017 election&amp;quot;,
    caption=&amp;quot;Data published by House of Commons Library, accessed via `parlitools`&amp;quot;,
    x=&amp;quot;Swing&amp;quot;, y=&amp;quot;count&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You might have noticed that different elements of a &lt;code&gt;ggplot2&lt;/code&gt; specification are added (&lt;code&gt;+&lt;/code&gt;) as layers. In the example above, the additional layer of labels (&lt;code&gt;labs()&lt;/code&gt;) is not intrinsic to the graphic. However, often you will add layers that do affect the graphic itself: for example the scaling of encoded values (e.g. &lt;code&gt;scale_*_continuous()&lt;/code&gt;) or whether the graphic is to be conditioned on another variable to generate &lt;a href=&#34;https://flowingdata.com/tag/small-multiples/&#34;&gt;small multiples&lt;/a&gt; for comparison (e.g. &lt;code&gt;facet_*()&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Read this design story by &lt;a href=&#34;http://tinlizzie.org/histograms/&#34;&gt;Lunzner and McNamara, 2020&lt;/a&gt; for an excellent discussion of the analysis and design considerations when working with histograms. There are of course other &lt;em&gt;geoms&lt;/em&gt; for summarising over 1D distributions: &lt;code&gt;geom_boxplot()&lt;/code&gt;, &lt;code&gt;geom_dotplot()&lt;/code&gt;, &lt;code&gt;geom_violin()&lt;/code&gt;.
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;div id=&#34;faceting-by-region&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Faceting by region&lt;/h4&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:hist-region&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;./class/03-class_files/hist-region.png&#34; alt=&#34;Histograms of Swing variable, grouped by region.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 12: Histograms of Swing variable, grouped by region.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Adding a call to &lt;code&gt;facet_*()&lt;/code&gt;, we can quickly compare how Swing varies by region (as in Figure &lt;a href=&#34;#fig:hist-region&#34;&gt;12&lt;/a&gt;). The plot is annotated with the &lt;em&gt;median&lt;/em&gt; value for Swing (4.4) by adding a vertical line layer (&lt;code&gt;geom_vline()&lt;/code&gt;) and setting its x-intercept at this value. From this, there is some evidence of a regional geography to the 2019 vote: London and Scotland are particularly distinctive in containing relatively few constituencies swinging greater than the expected midpoint; North East, Yorkshire &amp;amp; The Humber, and to a lesser extent West and East Midlands, appear to show the largest relative number of constituencies swinging greater than the midpoint. It was this graphic, especially the fact that London and Scotland look different from the rest of the country, that prompted the scatterplots in Figure &lt;a href=&#34;#fig:gog-demo&#34;&gt;3&lt;/a&gt; comparing gain in Conservative vote shares against the Brexit vote.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;plot-ranksmagnitudes&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Plot ranks/magnitudes&lt;/h3&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:bars&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;./class/03-class_files/bars.png&#34; alt=&#34;Plots of vote shares by party.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 13: Plots of vote shares by party.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Previously we calculated overall vote share by Political Party. We could continue the exploration of votes by region by re-using this code to generate plots displaying quantities but also comparing region, using marks and encoding channels that are suitable for magnitudes.&lt;/p&gt;
&lt;p&gt;To generate a bar chart similar to the left of Figure &lt;a href=&#34;#fig:bars&#34;&gt;13&lt;/a&gt; the &lt;code&gt;ggplot2&lt;/code&gt; specification would be:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data_gb %&amp;gt;%
  &amp;lt;some dplyr code&amp;gt; %&amp;gt;% # The code block summarising vote by party.
  ...  %&amp;gt;% #
  &amp;lt;summarised data frame&amp;gt;  %&amp;gt;% # The summarised data frame of vote share by party, piped to ggplot2.
  ggplot(aes(x=reorder(party, -vote_share), y=vote_share)) + # Categorical-ordinal x-axis (party, reordered), Ratio y-axis (vote_share).
  geom_col(fill=&amp;quot;#003c8f&amp;quot;) + # Set colour by website theme.
  labs(
    title=&amp;quot;Vote share by party in GB&amp;quot;,
    subtitle=&amp;quot;-- 2019 UK General Election&amp;quot;,
    caption=&amp;quot;Data published by House of Commons Library, accessed via `parlitools`&amp;quot;,
    x=&amp;quot;party&amp;quot;, y=&amp;quot;vote share&amp;quot;
  )+
  theme_v_gds() # A theme I&amp;#39;ve created for.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A quick breakdown of the specification:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Data&lt;/strong&gt;: This is the summarised data frame in which each row is a political party and the column describes the vote share recorded for that party.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Encoding&lt;/strong&gt;: I have dropped the &lt;code&gt;mapping=&lt;/code&gt;. &lt;code&gt;ggplot2&lt;/code&gt; always looks for &lt;code&gt;aes()&lt;/code&gt; and so can save some code clutter. In this case we are mapping &lt;code&gt;party&lt;/code&gt; to the x-axis, a categorical variable made ordinal by the fact that we reorder the axis left-to-right descending according to &lt;code&gt;vote_share&lt;/code&gt;. &lt;code&gt;vote_share&lt;/code&gt; is mapped to the y-axis – so encoded using bar length, on an aligned scale, an effective channel for conveying magnitudes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Marks&lt;/strong&gt;: &lt;code&gt;geom_col()&lt;/code&gt; for generating the bars.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Setting&lt;/strong&gt;: Again, I’ve set bar colour according to the website theme and included titles and captions. I also set the theme to a custom theme I have created for this module &lt;code&gt;theme_v_gds()&lt;/code&gt;. Optionally we add a &lt;code&gt;coord_flip()&lt;/code&gt; layer in order to display the bars horizontally. This makes the category axis labels easier to read and also seems more appropriate for the visual “ranking” of bars.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;code&gt;ggplot2&lt;/code&gt; themes control the appearance of all non-data items – font sizes and types, gridlines, axes labels. Checkout the complete list of &lt;code&gt;ggplot2&lt;/code&gt;’s &lt;a href=&#34;https://ggplot2.tidyverse.org/reference/ggtheme.html&#34;&gt;default themes&lt;/a&gt;. If you like the look of the BBC’s in-house data graphics – I do (or at least I like many of them) – explore their &lt;a href=&#34;https://bbc.github.io/rcookbook/&#34;&gt;Data Journalism cookbook&lt;/a&gt;. In fact I’d recommend working through the cookbook as it is a great resource for distilling many of the non-data-related decisions that are made when communicating graphically.
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;div id=&#34;faceting-by-region-1&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Faceting by region&lt;/h4&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:bars-region&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;./class/03-class_files/bars-region.png&#34; alt=&#34;Plots of vote shares by party and region.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 14: Plots of vote shares by party and region.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;In Figure &lt;a href=&#34;#fig:bars-region&#34;&gt;14&lt;/a&gt; the graphic is faceted by region. This requires an updated derived dataset grouping by &lt;code&gt;vote_share&lt;/code&gt; &lt;em&gt;and&lt;/em&gt; &lt;code&gt;region&lt;/code&gt; and of course adding a faceting layer (&lt;code&gt;geom_facet(~region)&lt;/code&gt;) to the &lt;code&gt;ggplot2&lt;/code&gt; specification. The graphic is more data-rich, but additional cognitive effort is required in relating the bars representing political parties between different graphical subsets. We can assist this &lt;em&gt;identify&lt;/em&gt; and &lt;em&gt;associate&lt;/em&gt; task by encoding the bars with an appropriate visual channel: &lt;em&gt;colour hue&lt;/em&gt;. The &lt;code&gt;ggplot2&lt;/code&gt; specification for this is as you would expect – we add a mapping to &lt;code&gt;geom_col()&lt;/code&gt; and pass the variable name &lt;code&gt;party&lt;/code&gt; to the fill argument (&lt;code&gt;aes(fill=party)&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;lt;derived_data&amp;gt; %&amp;gt;%
  ggplot(aes(x=reorder(party, vote_share), y=vote_share)) +
  geom_col(aes(fill=party)) +
  coord_flip() +
  facet_wrap(~region) +
  labs(
    title=&amp;quot;Vote share by party in GB&amp;quot;,
    subtitle=&amp;quot;-- 2019 UK General Election&amp;quot;,
    caption=&amp;quot;Data published by House of Commons Library, accessed via `parlitools`&amp;quot;,
    x=&amp;quot;party&amp;quot;, y=&amp;quot;vote share&amp;quot;
  )+
  theme_v_gds()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Trying this for yourself, you will observe that the &lt;code&gt;ggplot2&lt;/code&gt; internals are clever here. Since &lt;code&gt;party&lt;/code&gt; is a categorical variable, a categorical (hue-based) colour scheme is automatically applied. Try passing a quantitative variable (&lt;code&gt;fill=vote_share&lt;/code&gt;) and see what happens.&lt;/p&gt;
&lt;p&gt;Clever as this is, when encoding political parties with colour &lt;strong&gt;symbolisation&lt;/strong&gt; is important. More control over the encoding is necessary in order to specify the colours with which parties are most commonly represented. We can override &lt;code&gt;ggplot2&lt;/code&gt;’s default colour by adding a &lt;code&gt;scale_fill_manual()&lt;/code&gt; layer into which a vector of hex codes describing the colour of each political party is passed (&lt;code&gt;party_colours&lt;/code&gt;). We also need to tell &lt;code&gt;ggplot2&lt;/code&gt; which element of &lt;code&gt;party_colours&lt;/code&gt; to apply to which value of &lt;code&gt;party&lt;/code&gt;. In the code below, a derived table is generated summarising &lt;code&gt;vote_share&lt;/code&gt; by political party and region. In the final line the &lt;code&gt;party&lt;/code&gt; variable is recoded as a &lt;a href=&#34;https://r4ds.had.co.nz/factors.html&#34;&gt;&lt;code&gt;factor&lt;/code&gt;&lt;/a&gt;. You might recall from last session that factors are categorical variables of fixed and potentially orderable values, called &lt;code&gt;levels&lt;/code&gt;. The call to &lt;code&gt;mutate()&lt;/code&gt; recodes &lt;code&gt;party&lt;/code&gt; as a factor variable and orders the levels according to overall vote share.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Generate derived data.
temp_party_shares_region &amp;lt;- data_gb %&amp;gt;%
  select(constituency_name, region, total_vote_19, con_vote_19:alliance_vote_19) %&amp;gt;%
  pivot_longer(cols=con_vote_19:alliance_vote_19, names_to=&amp;quot;party&amp;quot;, values_to=&amp;quot;votes&amp;quot;) %&amp;gt;%
  mutate(party=str_extract(party, &amp;quot;[^_]+&amp;quot;)) %&amp;gt;%
  group_by(party, region) %&amp;gt;%
  summarise(vote_share=sum(votes, na.rm=TRUE)/sum(total_vote_19)) %&amp;gt;%
  filter(party %in% c(&amp;quot;con&amp;quot;, &amp;quot;lab&amp;quot;, &amp;quot;ld&amp;quot;, &amp;quot;snp&amp;quot;, &amp;quot;green&amp;quot;, &amp;quot;brexit&amp;quot;, &amp;quot;pc&amp;quot;)) %&amp;gt;%
  mutate(party=factor(party, levels=c(&amp;quot;con&amp;quot;, &amp;quot;lab&amp;quot;, &amp;quot;ld&amp;quot;, &amp;quot;snp&amp;quot;, &amp;quot;green&amp;quot;, &amp;quot;brexit&amp;quot;, &amp;quot;pc&amp;quot;)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, a vector of objects is created containing the hex codes for the colours of political parties (&lt;code&gt;party_colours&lt;/code&gt;). This is a named vector, with names assigned from the &lt;code&gt;levels&lt;/code&gt; of the &lt;code&gt;party&lt;/code&gt; variable that was just created.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Define colours.
con &amp;lt;- &amp;quot;#0575c9&amp;quot;
lab &amp;lt;- &amp;quot;#ed1e0e&amp;quot;
ld &amp;lt;- &amp;quot;#fe8300&amp;quot;
snp &amp;lt;- &amp;quot;#ebc31c&amp;quot;
green &amp;lt;- &amp;quot;#78c31e&amp;quot;
pc &amp;lt;- &amp;quot;#4e9f2f&amp;quot;
brexit &amp;lt;- &amp;quot;#25b6ce&amp;quot;
other &amp;lt;- &amp;quot;#bdbdbd&amp;quot;

party_colours &amp;lt;- c(con, lab, ld, snp, green, brexit, pc)
names(party_colours) &amp;lt;- levels(temp_party_shares %&amp;gt;% pull(party))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;ggplot2&lt;/code&gt; specification is then updated with the &lt;code&gt;scale_fill_manual()&lt;/code&gt; layer:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# ggplot2 spec.
temp_party_shares_region %&amp;gt;%
  ggplot(aes(x=reorder(party, vote_share), y=vote_share)) +
  geom_col(aes(fill=party)) +
  scale_fill_manual(values=party_colours) +
  coord_flip() +
  facet_wrap(~region) +
  labs(
    title=&amp;quot;Vote share by party in GB&amp;quot;,
    subtitle=&amp;quot;-- 2019 UK General Election&amp;quot;,
    caption=&amp;quot;Data published by House of Commons Library, accessed via `parlitools`&amp;quot;,
    x=&amp;quot;party&amp;quot;, y=&amp;quot;vote share&amp;quot;
  )+
  theme_v_gds()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;The idea behind visualization toolkits such as &lt;a href=&#34;https://vega.github.io/vega-lite/&#34;&gt;vega-lite&lt;/a&gt;, &lt;a href=&#34;https://www.tableau.com/en-gb&#34;&gt;Tableau&lt;/a&gt; and &lt;a href=&#34;https://ggplot2.tidyverse.org/&#34;&gt;&lt;code&gt;ggplot2&lt;/code&gt;&lt;/a&gt; is to insert visual data analysis approaches into the Data Scientist’s workflow. Rather than being overly concerned with low-level aspects of drawing, mapping to screen coordinates and scaling factors, the analyst instead focuses on aspects crucial to analysis – exposing patterns in the data by carefully specifying an encoding of data to visuals. Hadley Wickham talks about the type of workflow you will see used throughout this module – bits of &lt;code&gt;dplyr&lt;/code&gt; to prepare data for charting before being piped (&lt;code&gt;%&amp;gt;%&lt;/code&gt;) to a &lt;code&gt;ggplot2&lt;/code&gt; specification – as equivalent to a &lt;a href=&#34;https://channel9.msdn.com/Events/useR-international-R-User-conference/useR2016/Towards-a-grammar-of-interactive-graphics&#34;&gt;grammar of interactive graphics&lt;/a&gt;.&lt;/p&gt;&lt;/p&gt;
&lt;p&gt;The process of searching for, defining and inserting manual colour schemes for creating Figure &lt;a href=&#34;#fig:bars-region&#34;&gt;14&lt;/a&gt; might seem inimical to this. Indeed I was reluctant to include this code so early in the module – there is some reasonably advanced &lt;code&gt;dplyr&lt;/code&gt; and a little &lt;a href=&#34;https://stat.ethz.ch/R-manual/R-devel/library/base/html/regex.html&#34;&gt;regular expression&lt;/a&gt; in the data preparation code that I don’t want you to be overly concerned with. However, having control of these slightly more low-level properties is sometimes necessary even for supporting exploratory analysis, in this case for enabling a &lt;strong&gt;symbolisation&lt;/strong&gt; that is clear and easily interpretable. Try relating the bars without our manual setting of colours by political party – it certainly requires some mental gymnastics.

  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;faceting-by-region-2&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Faceting by region&lt;/h4&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;plot-relationships&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Plot relationships&lt;/h3&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:scatters-con&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;./class/03-class_files/scatters-con.png&#34; alt=&#34;Plots of 2019 versus 2017 vote shares.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 15: Plots of 2019 versus 2017 vote shares.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;In the &lt;a href=&#34;./#grammar-of-graphics-1/&#34;&gt;Grammar of Graphics&lt;/a&gt; section we demonstrated how scatterplots are specified in &lt;code&gt;ggplot2&lt;/code&gt;. Scatterplots are useful examples for introducing &lt;code&gt;ggplot2&lt;/code&gt; specifications as they involve working with genuine mark primitives (&lt;code&gt;geom_point()&lt;/code&gt;) and can be built up using a wide range of encoding channels.&lt;/p&gt;
&lt;p&gt;To continue the investigation of change in vote shares for the major parties between 2017 and 2019, Figure &lt;a href=&#34;#fig:scatters-con&#34;&gt;15&lt;/a&gt; contains scatterplots of vote share in 2019 (y-axis) against vote share in 2017 (x-axis) for Conservative and Labour. The graphics are annotated with a diagonal line. If constituencies voted in 2019 in exactly the same way as 2017, the points would all converge on the diagonal, points above the diagonal indicate a larger vote share than 2017, those below the diagonal represent a smaller vote share than 2017. Points are coloured according to the winning party in 2019 and constituencies that flipped from Labour to Conservative are emphasised using transparency and shape.&lt;/p&gt;
&lt;p&gt;The code for generating most of the scatterplot comparing Conservative vote shares is below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data_gb %&amp;gt;%
  mutate(winner_19=case_when(
           winner_19 == &amp;quot;Conservative&amp;quot; ~ &amp;quot;Conservative&amp;quot;,
           winner_19 == &amp;quot;Labour&amp;quot; ~ &amp;quot;Labour&amp;quot;,
           TRUE ~ &amp;quot;Other&amp;quot;
         )) %&amp;gt;%
  ggplot(aes(x=con_17, y=con_19)) +
  geom_point(aes(colour=winner_19), alpha=.8) +
  geom_abline(intercept = 0, slope = 1) +
  scale_colour_manual(values=c(con,lab,other)) +
  ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Hopefully there is little surprising here:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Data&lt;/strong&gt;: The &lt;code&gt;data_gb&lt;/code&gt; data frame. Values of &lt;code&gt;winner_19&lt;/code&gt; that are not &lt;em&gt;Conservative&lt;/em&gt; or &lt;em&gt;Labour&lt;/em&gt; are recoded to &lt;em&gt;Other&lt;/em&gt; using a &lt;strong&gt;conditional statement&lt;/strong&gt;. This is because points are eventually coloured according to winning party, but the occlusion of points adds visual complexity and so I’ve chosen to prioritise the two main parties and recode remaining parties to other.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Encoding&lt;/strong&gt;: Conservative vote share in 2017 and 2019 are mapped to the x- and y- axes respectively and &lt;code&gt;winner_19&lt;/code&gt; to colour. &lt;code&gt;scale_colour_manual()&lt;/code&gt; is used for customising the colours.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Marks&lt;/strong&gt;: &lt;code&gt;geom_point()&lt;/code&gt; for generating the points of the scatterplot; geom_abline() for drawing the reference diagonal.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;You will have encountered conditionals in the reading from last session. &lt;code&gt;case_when&lt;/code&gt; allows you to avoid writing multiple &lt;code&gt;if_else()&lt;/code&gt; statements. It wasn’t really necessary here – I could have used a single if_else with something like:&lt;/p&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;data_gb %&amp;gt;%
  mutate(
    winner_19=if_else(!winner_19 %in% c(&amp;quot;Conservative&amp;quot;, &amp;quot;Labour&amp;quot;), &amp;quot;Other&amp;quot;, winner_19)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A general point from the code blocks in this session is of the importance of proficiency in &lt;code&gt;dplyr&lt;/code&gt;. Throughout the module you will find yourself needing to calculate new variables, recode variables, and reorganise data frames before passing through to &lt;code&gt;ggplot2&lt;/code&gt;.

  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;plot-geography&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Plot geography&lt;/h3&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:map-winners&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;./class/03-class_files/map-winners.png&#34; alt=&#34;Choropleth of elected parties in 2019 General Election.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 16: Choropleth of elected parties in 2019 General Election.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;In the graphics that facet by region, our analysis suggests at a geography to voting and certainly to observed changes in voting comparing the 2017 and 2019 elections (e.g. Figure &lt;a href=&#34;#fig:hist-region&#34;&gt;12&lt;/a&gt;). We end the session by encoding the results data with a spatial arrangement – we’ll generate some maps.&lt;/p&gt;
&lt;p&gt;To do this we need to define a join on the boundary data (&lt;code&gt;cons_outline&lt;/code&gt;):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Join constituency boundaries.
data_gb &amp;lt;- cons_outline %&amp;gt;%
  inner_join(data_gb, by=c(&amp;quot;pcon19cd&amp;quot;=&amp;quot;ons_const_id&amp;quot;))
# Check class.
## [1] &amp;quot;sf&amp;quot;         &amp;quot;data.frame&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The code for generating the &lt;a href=&#34;https://en.wikipedia.org/wiki/Choropleth_map&#34;&gt;Choropleth maps&lt;/a&gt; of winning party by constituency in Figure &lt;a href=&#34;#fig:map-winners&#34;&gt;16&lt;/a&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Recode winner_19 as a factor variable for assigning colours.
data_gb &amp;lt;- data_gb %&amp;gt;%
  mutate(
    winner_19=if_else(winner_19==&amp;quot;Speaker&amp;quot;, &amp;quot;Other&amp;quot;, winner_19),
    winner_19=as_factor(winner_19))

# Create a named vector of colours
party_colours &amp;lt;- c(con, lab, ld, green, other, snp, pc)
names(party_colours) &amp;lt;- levels(data_gb %&amp;gt;% pull(winner_19))

# Plot map.
data_gb %&amp;gt;%
  ggplot(aes(fill=winner_19)) +
  geom_sf(colour=&amp;quot;#eeeeee&amp;quot;, size=0.01)+
  # Optionally add a layer for regional boundaries.
  # geom_sf(data=. %&amp;gt;% group_by(region) %&amp;gt;% summarise(), colour=&amp;quot;#eeeeee&amp;quot;, fill=&amp;quot;transparent&amp;quot;, size=0.08)+
  coord_sf(crs=27700, datum=NA) +
  scale_fill_manual(values=party_colours) +&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A breakdown of the &lt;code&gt;ggplot2&lt;/code&gt; spec:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Data&lt;/strong&gt;: The &lt;code&gt;dplyr&lt;/code&gt; code updates &lt;code&gt;data_gb&lt;/code&gt; by recoding &lt;code&gt;winner_19&lt;/code&gt; as a factor and defining a named vector of colours to supply to &lt;code&gt;scale_fill_manual()&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Encoding&lt;/strong&gt;: No surprises here – &lt;code&gt;fill&lt;/code&gt; according to &lt;code&gt;winner_19&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Marks&lt;/strong&gt;: &lt;code&gt;geom_sf()&lt;/code&gt; is a special class of geometry. It draws objects depending on the contents of the &lt;code&gt;geometry&lt;/code&gt; column. In this case &lt;code&gt;MULTIPOLYGON&lt;/code&gt;, so read this as a &lt;em&gt;polygon&lt;/em&gt; geometric primitive.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Coordinates&lt;/strong&gt;: &lt;code&gt;coord_sf&lt;/code&gt; – we set the coordinate system (CRS) explicitly. In this case &lt;a href=&#34;https://spatialreference.org/ref/epsg/osgb-1936-british-national-grid/&#34;&gt;OS British National Grid&lt;/a&gt;. More on this later in the module.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Setting&lt;/strong&gt;: Again, the &lt;code&gt;theme_v_gds()&lt;/code&gt; theme. I’ve also subtly introduced light grey (&lt;code&gt;colour=&#34;#eeeeee&#34;&lt;/code&gt;) and thin (&lt;code&gt;size=0.01&lt;/code&gt;) constituency boundaries to the &lt;code&gt;geom_sf&lt;/code&gt; mark. On the map to the right outlines for regions are added as another &lt;code&gt;geom_sf&lt;/code&gt; layer.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:spoke-map&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;./class/03-class_files/spoke-map.png&#34; alt=&#34;Map of Butler Con-Lab Swing in 2019 General Election.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 17: Map of Butler Con-Lab Swing in 2019 General Election.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;This has been a packed session. I’m providing a very abbreviated introduction to map design with &lt;code&gt;ggplot2&lt;/code&gt; and want to reserve the details of how &lt;code&gt;ggplot2&lt;/code&gt; can be used in more involved visualization design for later in the module. Since the graphic has been discussed at length, it would be strange not to demonstrate how the encoding in the Washington Post piece can be applied here to analyse our Butler two-party swing variable &lt;span class=&#34;citation&#34;&gt;(e.g. Beecham &lt;a href=&#34;#ref-beecham_using_2020&#34; role=&#34;doc-biblioref&#34;&gt;2020&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;First, some helper functions – converting degrees to radians and centring &lt;code&gt;geom_spoke()&lt;/code&gt; geometries. Don’t bother yourself with these details, just run the code.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Convert degrees to radians.
get_radians &amp;lt;- function(degrees) {
  (degrees * pi) / (180)
}
# Rescaling function.
map_scale &amp;lt;- function(value, min1, max1, min2, max2) {
  return  (min2+(max2-min2)*((value-min1)/(max1-min1)))
}
# Position subclass for centred geom_spoke as per --
# https://stackoverflow.com/questions/55474143/how-to-center-geom-spoke-around-their-origin
position_center_spoke &amp;lt;- function() PositionCenterSpoke
PositionCenterSpoke &amp;lt;- ggplot2::ggproto(&amp;#39;PositionCenterSpoke&amp;#39;, ggplot2::Position,
                                        compute_panel = function(self, data, params, scales) {
                                          data$x &amp;lt;- 2*data$x - data$xend
                                          data$y &amp;lt;- 2*data$y - data$yend
                                          data$radius &amp;lt;- 2*data$radius
                                          data
                                        }
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next re-define &lt;code&gt;party_colours&lt;/code&gt;, the object we use for manually setting colours, to contain just three values: hex codes for Conservative, Labour and Other.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;party_colours &amp;lt;- c(con, lab, other)
names(party_colours) &amp;lt;- c(&amp;quot;Conservative&amp;quot;, &amp;quot;Labour&amp;quot;, &amp;quot;Other&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And the &lt;code&gt;ggplot2&lt;/code&gt; specification:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;max_shift &amp;lt;- max(abs(data_gb %&amp;gt;% pull(swing_con_lab)))
min_shift &amp;lt;- -max_shift

gb &amp;lt;- data_gb %&amp;gt;%
  mutate(
    is_flipped=seat_change_1719 %in% c(&amp;quot;Conservative gain from Labour&amp;quot;,&amp;quot;Labour gain from Conservative&amp;quot;),
    elected=if_else(!winner_19 %in% c(&amp;quot;Conservative&amp;quot;, &amp;quot;Labour&amp;quot;), &amp;quot;Other&amp;quot;, as.character(winner_19))
    ) %&amp;gt;%
  ggplot()+
  geom_sf(aes(fill=elected), colour=&amp;quot;#636363&amp;quot;, alpha=.2, size=.01)+
  geom_spoke(
             aes(x=bng_e, y=bng_n, angle=get_radians(map_scale(swing_con_lab,min_shift,max_shift,135,45)), colour=elected, size=is_flipped),
             radius=7000, position=&amp;quot;center_spoke&amp;quot;
             )+
  coord_sf(crs=27700, datum=NA)+
  scale_size_ordinal(range=c(.3,.9))+
  scale_colour_manual(values=party_colours)+
  scale_fill_manual(values=party_colours)+
  theme_v_gds()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A breakdown:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Data&lt;/strong&gt;: &lt;code&gt;data_gb&lt;/code&gt; is updated with a boolean identifying whether or not the Constituency flipped Con-Lab/Lab-Con between successive elections (&lt;code&gt;is_flipped&lt;/code&gt;), and a variable simplifying the party elected to either Conservative, Labour or Other.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Encoding&lt;/strong&gt;: &lt;code&gt;geom_sf&lt;/code&gt; is again filled by elected party. This encoding is made more subtle by adding transparency (&lt;code&gt;alpha=.2&lt;/code&gt;). &lt;a href=&#34;https://ggplot2.tidyverse.org/reference/geom_spoke.html&#34;&gt;&lt;code&gt;geom_spoke()&lt;/code&gt;&lt;/a&gt; is a line primitive that can be encoded with a location and direction. It is mapped to the geographic centroid of each Constituency (&lt;code&gt;bng_e&lt;/code&gt; - easting, &lt;code&gt;bng_n&lt;/code&gt; - northing), coloured according to elected party, sized according to whether the Constituency flipped its vote and tilted according to the Swing variable. Here I’ve created a function (map_scale) which pegs the maximum Swing values in either direction to 45 degrees (max Swing to the right, Conservative) and 135 degrees (max Swing to the left, Labour).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Marks&lt;/strong&gt;: &lt;code&gt;geom_sf()&lt;/code&gt; for the Constituency boundaries, &lt;code&gt;geom_spoke()&lt;/code&gt; for the angled line primitives.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Scale&lt;/strong&gt;: &lt;code&gt;geom_spoke()&lt;/code&gt; primitives are sized to emphasise whether constituencies have flipped. The size encoding is censored to two values with &lt;code&gt;scale_size_ordinal()&lt;/code&gt;. Passed to &lt;code&gt;scale_colour_manual()&lt;/code&gt; and &lt;code&gt;scale_fill_manual()&lt;/code&gt; is the vector of &lt;code&gt;party_colours&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Coordinates&lt;/strong&gt;: &lt;code&gt;coord_sf&lt;/code&gt; – the CRS is &lt;a href=&#34;https://spatialreference.org/ref/epsg/osgb-1936-british-national-grid/&#34;&gt;OS British National Grid&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Setting&lt;/strong&gt;: The &lt;code&gt;radius&lt;/code&gt;, the of &lt;code&gt;geom_spoke()&lt;/code&gt; primitives is a sensible default arrived at through trial and error, its &lt;code&gt;position&lt;/code&gt; set using our &lt;code&gt;center_spoke&lt;/code&gt; class.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;Visualization design is ultimately a process of decision-making. Data must be filtered and prioritised before being encoded with marks, visual channels and symbolisation. The most successful data graphics are those that expose structure, connections and comparisons that could not be achieved easily via other, non-visual means. This session has introduced concepts – a vocabulary, framework and empirically-informed guidelines – that helps support this decision-making process and that underpins modern visualization toolkits (&lt;code&gt;ggplot2&lt;/code&gt; included). Through an analysis of UK 2019 General Election data, we have demonstrated how these concepts can be applied in a real data analysis.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2 unnumbered&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-beecham_using_2020&#34;&gt;
&lt;p&gt;Beecham, R. 2020. “Using position, angle and thickness to expose the shifting geographies of the 2019 UK General Election.” &lt;em&gt;Environment and Planning A: Economy and Space&lt;/em&gt; 52 (5): 833–36.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-beecham_maplineups_2017&#34;&gt;
&lt;p&gt;Beecham, R., J. Dykes, W. Meulemans, A. Slingsby, C. Turkay, and J. Wood. 2017. “Map Line-Ups: Effects of Spatial Structure on Graphical Inference.” &lt;em&gt;IEEE Transactions on Visualization &amp;amp; Computer Graphics&lt;/em&gt; 23 (1): 391–400.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-butler_why_1990&#34;&gt;
&lt;p&gt;Butler, D., and S. Van Beek. 1990. “Why not swing? Measuring electoral change.” &lt;em&gt;Political Science &amp;amp; politics&lt;/em&gt; 23 (2): 178–84.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-harrison_ranking_2014&#34;&gt;
&lt;p&gt;Chang, Lane Harrison AND Fumeng Yang AND Steven Franconeri AND Remco. 2014. “Ranking Visualizations of Correlation Using Weber’s Law.” &lt;em&gt;IEEE Conference on Information Visualization (InfoVis)&lt;/em&gt; 20 (12): 1943–52.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-cleveland_elements_1993&#34;&gt;
&lt;p&gt;Cleveland, William S. 1993. &lt;em&gt;The Elements of Graphing Data&lt;/em&gt;. Hobart Press.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-cleveland_graphical_1984&#34;&gt;
&lt;p&gt;Cleveland, W., and R. McGill. 1984. “Graphical Perception: Theory, Experimentation, and Application to the Development of Graphical Methods.” &lt;em&gt;Journal of the American Statistical Association&lt;/em&gt; 79 (387): 531–54.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-correll_error_2014&#34;&gt;
&lt;p&gt;Correll, M., and M. Gleicher. 2014. “Error Bars Considered Harmful: Exploring Alternate Encodings for Mean and Error.” &lt;em&gt;IEEE Transactions on Visualization &amp;amp; Computer Graphics&lt;/em&gt; 20 (12): 2141–51.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-flannery_subjective_1963&#34;&gt;
&lt;p&gt;Flannery, J. J. 1971. “The Relative Effectiveness of Some Common Graduated Point Symbols in the Presentation of Quantitative Data.” &lt;em&gt;Cartographica&lt;/em&gt; 8 (2): 96–109.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-hanretty_areal_2017&#34;&gt;
&lt;p&gt;Hanretty, Chris. 2017. “Areal Interpolation and the Uk’s Referendum on Eu Membership.” &lt;em&gt;Journal of Elections, Public Opinion and Parties&lt;/em&gt; 37 (4): 466–83.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-heer_crowdsourcing_2010&#34;&gt;
&lt;p&gt;Heer, Jeffrey, and Michael Bostock. 2010. “Crowdsourcing Graphical Perception: Using Mechanical Turk to Assess Visualization Design.” In &lt;em&gt;ACM Human Factors in Computing Systems&lt;/em&gt;, 203–12. doi:&lt;a href=&#34;https://doi.org/10.1145/1753326.1753357&#34;&gt;10.1145/1753326.1753357&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-kay_beyond_2016&#34;&gt;
&lt;p&gt;Kay, Matthew, and Jeffrey Heer. 2016. “Beyond Weber’s Law: A Second Look at Ranking Visualizations of Correlation.” &lt;em&gt;IEEE Trans. Visualization &amp;amp; Comp. Graphics (InfoVis)&lt;/em&gt; 22 (1): 469–78.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-klippel_interpreting_2011&#34;&gt;
&lt;p&gt;Klippel, A., F. Hardisty, and Rui. Li. 2011. “Interpreting Spatial Patterns: An Inquiry into Formal and Cognitive Aspects of Tobler’s First Law of Geography.” &lt;em&gt;Annals of the Association of American Geographers&lt;/em&gt; 101 (5): 1011–31.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-munzner_visualization_2014&#34;&gt;
&lt;p&gt;Munzner, Tamara. 2014. &lt;em&gt;Visualization Analysis and Design&lt;/em&gt;. AK Peters Visualization Series. Boca Raton, FL: CRC Press.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-rensink_perception_2010&#34;&gt;
&lt;p&gt;Rensink, R, and G Baldridge. 2010. “The Perception of Correlation in Scatterplots.” &lt;em&gt;Computer Graphics Forum&lt;/em&gt; 29 (3): 1203–10.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-stevens_subjective_1963&#34;&gt;
&lt;p&gt;Stevens, S, and M. Guirao. 1963. “Subjective Scaling of Length and Area and the Matching of Length to Loudness and Brightness.” &lt;em&gt;Journal of Experimental Psychology&lt;/em&gt; 66 (2): 177–86.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-tufte_visual_1983&#34;&gt;
&lt;p&gt;Tufte, Edward R. 1983. &lt;em&gt;The Visual Display of Quantitative Information&lt;/em&gt;. Cheshire, CT: Graphics Press.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-ware_visual_2008&#34;&gt;
&lt;p&gt;Ware, Colin. 2008. &lt;em&gt;Visual Thinking for Design&lt;/em&gt;. Waltham, MA: Morgan Kaufman.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-white_symbolization_2017&#34;&gt;
&lt;p&gt;White, T. 2017. “Symbolization and the Visual Variables.” In &lt;em&gt;He Geographic Information Science &amp;amp; Technology Body of Knowledge&lt;/em&gt;, edited by John P. Wilson.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-wickham_layered_2010&#34;&gt;
&lt;p&gt;Wickham, Hadley. 2010. “A Layered Grammar of Graphics.” &lt;em&gt;Journal of Computational and Graphical Statistics&lt;/em&gt; 19 (1): 3–28.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-wilkinson_grammar_1999&#34;&gt;
&lt;p&gt;Wilkinson, Leland. 1999. &lt;em&gt;The Grammar of Graphics&lt;/em&gt;. New York: Springer.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Data fundamentals: Describe, wrangle, tidy</title>
      <link>/class/02-class/</link>
      <pubDate>Tue, 18 May 2021 00:00:00 +0000</pubDate>
      <guid>/class/02-class/</guid>
      <description>
&lt;!-- BLOGDOWN-HEAD --&gt;
&lt;link href=&#34;./rmarkdown-libs/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;./rmarkdown-libs/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;./rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;./rmarkdown-libs/lightable/lightable.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;!-- /BLOGDOWN-HEAD --&gt;

&lt;h2&gt;Contents&lt;/h2&gt;
&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#session-outcomes&#34;&gt;Session outcomes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#concepts&#34;&gt;Concepts&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#data-structure&#34;&gt;Data structure&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#types-of-variable&#34;&gt;Types of variable&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#types-of-observation&#34;&gt;Types of observation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#tidy-data&#34;&gt;Tidy data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#techniques&#34;&gt;Techniques&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#import&#34;&gt;Import&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#describe&#34;&gt;Describe&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#transform&#34;&gt;Transform&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#tidy&#34;&gt;Tidy&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#conclusions&#34;&gt;Conclusions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#references&#34;&gt;References&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;session-outcomes&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Session outcomes&lt;/h2&gt;
&lt;p&gt;By the end of this session you should gain the following &lt;strong&gt;&lt;em&gt;knowledge&lt;/em&gt;&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;

&lt;div class=&#34;alert alert-objective&#34;&gt;
  &lt;div&gt;
    &lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; The vocabulary and concepts used to &lt;strong&gt;describe&lt;/strong&gt; data.&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;strong&gt;Appreciate&lt;/strong&gt; the characteristics and importance of &lt;strong&gt;tidy data&lt;/strong&gt; &lt;span class=&#34;citation&#34;&gt;(Wickham &lt;a href=&#34;#ref-wickham_tidy_2014&#34; role=&#34;doc-biblioref&#34;&gt;2014&lt;/a&gt;)&lt;/span&gt; for data processing and analysis.&lt;/li&gt;
&lt;/ul&gt;

  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;By the end of this session you should gain the following &lt;strong&gt;&lt;em&gt;practical skills&lt;/em&gt;&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;

&lt;div class=&#34;alert alert-objective&#34;&gt;
  &lt;div&gt;
    &lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;strong&gt;Load&lt;/strong&gt; flat file datasets RStudio via querying an API.&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;strong&gt;Calculate&lt;/strong&gt; descriptive summaries over datasets.&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;strong&gt;Apply&lt;/strong&gt; high-level functions in &lt;code&gt;dplyr&lt;/code&gt; and &lt;code&gt;tidyr&lt;/code&gt; for working with data.&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;strong&gt;Create&lt;/strong&gt; statistical graphics that expose high-level structure in data for cleaning purposes.&lt;/li&gt;
&lt;/ul&gt;

  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;This session covers some of the basics around how to describe and organise data. Whilst this might sound prosaic, there are several reasons why being able to consistently describe a dataset is important. First: it is the initial step in any analysis and helps delimit the research themes and technical procedures that can be deployed. This is especially relevant to modern Data Science-type workflows (like those supported by &lt;code&gt;tidyverse&lt;/code&gt;), where it is common apply the same analysis templates for working over data. Describing your dataset with a consistent vocabulary enables you to identify which analysis templates to reuse. Second relates to the point in Session 1 that Geographic Data Science projects usually involve repurposing datasets for social science research for the first time. It is often not obvious whether the data contain sufficient detail and structure to characterise the target behaviours to be researched and the target populations they are assumed to represent. This leads to additional levels of uncertainty and places greater importance on the initial step of data processing, description and exploration.&lt;/p&gt;
&lt;p&gt;&lt;!-- Data will be &#34;messy&#34;, with missing observations, potentially inconsistent structure and levels of precision.
Paying attention to   --&gt;&lt;/p&gt;
&lt;p&gt;Through the session we will learn both language and concepts for describing and thinking about data, but also how to deploy some of the most important data processing and organisation techniques in &lt;code&gt;R&lt;/code&gt; to wrangle over a real dataset. We will be working throughout with data from New York’s &lt;a href=&#34;https://www.citibikenyc.com/&#34;&gt;Citibike&lt;/a&gt; scheme, accessed through the &lt;code&gt;bikedata&lt;/code&gt; package, an API to Citibike’s &lt;a href=&#34;https://www.citibikenyc.com/system-data&#34;&gt;publicly available origin-destination trip data&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    The idea of applying a consistent vocabulary to describing your data applies especially to working with modern visualization toolkits (&lt;a href=&#34;https://ggplot2.tidyverse.org/&#34;&gt;ggplot2&lt;/a&gt;, &lt;a href=&#34;https://www.tableau.com/en-gb&#34;&gt;Tableau&lt;/a&gt;, &lt;a href=&#34;https://vega.github.io/vega-lite/&#34;&gt;vega-lite&lt;/a&gt;), and will be covered in some detail during the next session as we introduce Visualization Fundamentals and the &lt;a href=&#34;https://www.springer.com/gp/book/9780387245447&#34;&gt;Grammar of Graphics&lt;/a&gt;.
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;concepts&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Concepts&lt;/h2&gt;
&lt;div id=&#34;data-structure&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Data structure&lt;/h3&gt;
&lt;p&gt;In the module we will work with &lt;a href=&#34;http://adv-r.had.co.nz/Data-structures.html#data-frames&#34;&gt;data frames&lt;/a&gt; in R. These are spreadsheet like representations where rows are &lt;strong&gt;observations&lt;/strong&gt; (case/record) and columns are &lt;strong&gt;variables&lt;/strong&gt;. Each variable (column) in a data frame is a &lt;a href=&#34;http://adv-r.had.co.nz/Data-structures.html#vectors&#34;&gt;vector&lt;/a&gt; that must be of equal length. Where observations have missing values for certain variables, therefore where they may violate this equal-length requirement, the missing values must be substituted with something, usually with &lt;code&gt;NA&lt;/code&gt; or similar. This constraint occasionally causes difficulties, for example when working with variables that contain values of different length for an observation. In these cases we create a special class of column, a &lt;a href=&#34;https://jennybc.github.io/purrr-tutorial/ls13_list-columns.html&#34;&gt;&lt;code&gt;list-column&lt;/code&gt;&lt;/a&gt;, something we’ll return to later in the module.&lt;/p&gt;
&lt;p&gt;Organising data according this simple structure – rows as observations, columns as variables – makes working with data more straightforward. A specific set of tools, made available via the &lt;code&gt;tidyverse&lt;/code&gt;, can be deployed for doing most data &lt;strong&gt;tidy&lt;/strong&gt;ing tasks &lt;span class=&#34;citation&#34;&gt;(Wickham &lt;a href=&#34;#ref-wickham_tidy_2014&#34; role=&#34;doc-biblioref&#34;&gt;2014&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;types-of-variable&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Types of variable&lt;/h3&gt;
&lt;table&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:variable-types&#34;&gt;Table 1: &lt;/span&gt;A breakdown of &lt;span class=&#34;citation&#34;&gt;Stevens (&lt;a href=&#34;#ref-stevens_on_1946&#34; role=&#34;doc-biblioref&#34;&gt;1946&lt;/a&gt;)&lt;/span&gt; variable types, operators and measures of central tendency that can be applied to each.
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Measurement
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Description
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Example
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Operators
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Midpoint
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Dispersion
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr grouplength=&#34;2&#34;&gt;
&lt;td colspan=&#34;6&#34; style=&#34;border-bottom: 0px solid;&#34;&gt;
Categories
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left; padding-left:  2em;width: 8em; &#34; indentlevel=&#34;1&#34;&gt;
&lt;code&gt;Nominal&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Non-orderable categories
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Political parties; street names
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
= ≠
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
mode
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
entropy
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left; padding-left:  2em;width: 8em; &#34; indentlevel=&#34;1&#34;&gt;
&lt;code&gt;Ordinal&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Orderable categories
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;a href=&#34;https://www.gov.uk/terrorism-national-emergency&#34;&gt;Terrorism threat levels&lt;/a&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
… | &amp;lt;&amp;gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
… | median
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
… | percentile
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr grouplength=&#34;2&#34;&gt;
&lt;td colspan=&#34;6&#34; style=&#34;border-bottom: 0px solid;&#34;&gt;
Measures
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left; padding-left:  2em;width: 8em; &#34; indentlevel=&#34;1&#34;&gt;
&lt;code&gt;Interval&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Numeric measurements
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Temperatures; years
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
… | + -
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
… | mean
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
… | variance
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left; padding-left:  2em;width: 8em; &#34; indentlevel=&#34;1&#34;&gt;
&lt;code&gt;Ratio&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
… | Counts
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Distances; prices
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
… | × ÷
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
… | mean
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
… | variance
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;A classification you may have encountered for describing variables is that developed by &lt;span class=&#34;citation&#34;&gt;Stevens (&lt;a href=&#34;#ref-stevens_on_1946&#34; role=&#34;doc-biblioref&#34;&gt;1946&lt;/a&gt;)&lt;/span&gt;, which considers the &lt;em&gt;level of measurement&lt;/em&gt; of a variable. &lt;span class=&#34;citation&#34;&gt;Stevens (&lt;a href=&#34;#ref-stevens_on_1946&#34; role=&#34;doc-biblioref&#34;&gt;1946&lt;/a&gt;)&lt;/span&gt; classed variables into two groups: variables that describe &lt;em&gt;categories&lt;/em&gt; of things and variables that describe &lt;em&gt;measurements&lt;/em&gt; of things. Categories include attributes like gender, titles, &lt;code&gt;Subscribers&lt;/code&gt; or &lt;code&gt;Casual&lt;/code&gt; users of a bikeshare scheme and ranked orders (1st, 2nd, 3rd largest etc.). Measurements include quantities like distance, age, travel time, number of journeys made on a bikeshare scheme.&lt;/p&gt;
&lt;p&gt;Categories can be further subdivided into those that are unordered (&lt;strong&gt;nominal&lt;/strong&gt;) from those that are ordered (&lt;strong&gt;ordinal&lt;/strong&gt;). Measurements can also be subdivided. &lt;strong&gt;Interval&lt;/strong&gt; measurements are quantities that can be ordered and where the difference between two values is meaningful. &lt;strong&gt;Ratio&lt;/strong&gt; measurements have both these properties, but also have a meaningful &lt;code&gt;0&lt;/code&gt; – where &lt;code&gt;0&lt;/code&gt; means the absence of something – and where the ratio of two values can be computed. The most common cited example of an interval measurement is temperature (in degrees C). Temperatures can be ordered and compared additively, but &lt;code&gt;0&lt;/code&gt; degrees C does not mean the absence of temperature and 20 degrees C is not twice as “hot” as 10 degrees C. &lt;strong&gt;Add Cyclic ratio (measures bound to range – circle, clock time)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Why is this important? The measurement level of a variable determines the types of data analysis procedures that can be performed and therefore allows us to efficiently make decisions when working with a dataset for the first time (Table &lt;a href=&#34;#tab:variable-types&#34;&gt;1&lt;/a&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;types-of-observation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Types of observation&lt;/h3&gt;
&lt;p&gt;Observations either together form an entire &lt;strong&gt;population&lt;/strong&gt; or a subset, or &lt;strong&gt;sample&lt;/strong&gt; that we expect represents a &lt;strong&gt;target population&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;You no doubt will be familiar with these concepts, but we have to think a little more about this in Geographic Data Science applications as we may often be working with datasets that are so-called population-level. The &lt;a href=&#34;(https://www.citibikenyc.com/system-data)&#34;&gt;Citibike dataset&lt;/a&gt; is a complete, population-level dataset in that every journey made through the scheme is recorded. Whether or not this is truly a population-level dataset, however, depends on the analysis purpose. When analysing the bikeshare dataset are we interested only in describing use within the Citibike scheme or are we taking the patterns observed through our analysis to make claims and inferences about cycling more generally?&lt;/p&gt;
&lt;p&gt;If the latter, then there are problems as the level of detail we have on our sample is pretty trivial compared to traditional datasets, where we deliberately design data collection activities with a specified target population in mind. It may therefore be difficult to gauge how representative Citibike users and Citibike cycling is of New York’s general cycling population. The flipside is that passively collected data do not suffer from the same problems such as non-response bias and social-desirability bias as traditionally collected datasets.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;tidy-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Tidy data&lt;/h3&gt;
&lt;p&gt;I mentioned that we would be working with data frames organised such that columns always and only refer to variables and rows always and only refer to observations. This arrangement, called &lt;strong&gt;tidy&lt;/strong&gt; &lt;span class=&#34;citation&#34;&gt;(Wickham &lt;a href=&#34;#ref-wickham_tidy_2014&#34; role=&#34;doc-biblioref&#34;&gt;2014&lt;/a&gt;)&lt;/span&gt;, has two key advantages. First, if data are arranged in a consistent way, then it is easier to apply and re-use tools for wrangling them due to data having the same underlying structure. Second, placing variables into columns, with each column containing a vector of values, means that we can take advantage of R’s vectorised functions for transforming data – we will demonstrate this in the technical element of this session.&lt;/p&gt;
&lt;p&gt;The three rules for tidy data:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Each variable forms a column.&lt;/li&gt;
&lt;li&gt;Each observation forms a row.&lt;/li&gt;
&lt;li&gt;Each type of observational unit forms a table.&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;drug-treatment-dataset&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Drug treatment dataset&lt;/h4&gt;
&lt;p&gt;To elaborate further, we can use the example given in &lt;span class=&#34;citation&#34;&gt;Wickham (&lt;a href=&#34;#ref-wickham_tidy_2014&#34; role=&#34;doc-biblioref&#34;&gt;2014&lt;/a&gt;)&lt;/span&gt;, a drug treatment dataset in which two different treatments were administered to participants.&lt;/p&gt;
&lt;p&gt;The data could be represented as:&lt;/p&gt;
&lt;table&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:drugs-one&#34;&gt;Table 2: &lt;/span&gt;Table 1 of &lt;span class=&#34;citation&#34;&gt;Wickham (&lt;a href=&#34;#ref-wickham_tidy_2014&#34; role=&#34;doc-biblioref&#34;&gt;2014&lt;/a&gt;)&lt;/span&gt;.
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
person
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
treatment_a
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
treatment_b
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
John Smith
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
–
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Jane Doe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
16
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
11
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mary Johnson
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;An alternative organisation could be:&lt;/p&gt;
&lt;table&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:drugs-two&#34;&gt;Table 3: &lt;/span&gt;Alternative organisation of Table 1 of &lt;span class=&#34;citation&#34;&gt;Wickham (&lt;a href=&#34;#ref-wickham_tidy_2014&#34; role=&#34;doc-biblioref&#34;&gt;2014&lt;/a&gt;)&lt;/span&gt;.
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
treatment
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
John Smith
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Jane Doe
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Mary Johnson
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
treatment_a
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
–
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
16
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
treatment_b
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Both present the same information unambiguously – Table &lt;a href=&#34;#tab:drugs-two&#34;&gt;3&lt;/a&gt; is simply Table &lt;a href=&#34;#tab:drugs-one&#34;&gt;2&lt;/a&gt; transposed. However, neither is &lt;strong&gt;tidy&lt;/strong&gt; as the observations are spread across both the rows and columns. This means that we need to apply different procedures to extract, perform computations on, and visually represent, these data.&lt;/p&gt;
&lt;p&gt;Much better would be to organise the table into a &lt;strong&gt;tidy&lt;/strong&gt; form. To do this we need to identify the &lt;strong&gt;variables&lt;/strong&gt;:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;code&gt;person&lt;/code&gt;: a categorical nominal variable which takes three values: John Smith, Jane Doe, Mary Johnson.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;treatment&lt;/code&gt;: a categorical nominal variable which takes values: a and b.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;result&lt;/code&gt;: a measurement ratio (I think) variable which six recorded values (including the missing value): -, 16, 3, 2, 11,&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Each &lt;strong&gt;observation&lt;/strong&gt; is then a test result returned for each combination of &lt;code&gt;person&lt;/code&gt; and &lt;code&gt;treatment&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;So, a &lt;strong&gt;tidy&lt;/strong&gt; organisation for this dataset would be:&lt;/p&gt;
&lt;table&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:drugs-tidy&#34;&gt;Table 4: &lt;/span&gt;Tidy version of Table 1 of &lt;span class=&#34;citation&#34;&gt;Wickham (&lt;a href=&#34;#ref-wickham_tidy_2014&#34; role=&#34;doc-biblioref&#34;&gt;2014&lt;/a&gt;)&lt;/span&gt;.
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
person
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
treatment
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
result
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
John Smith
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
a
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
–
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
John Smith
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
b
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Jane Doe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
a
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
16
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Jane Doe
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
b
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
11
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mary Johnson
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
a
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mary Johnson
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
b
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;gapminder-population-dataset&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Gapminder population dataset&lt;/h4&gt;
&lt;p&gt;In &lt;a href=&#34;https://r4ds.had.co.nz/tidy-data.html#tidy-data-1&#34;&gt;chapter 12&lt;/a&gt; of &lt;span class=&#34;citation&#34;&gt;Wickham and Grolemund (&lt;a href=&#34;#ref-wickham_r_2017&#34; role=&#34;doc-biblioref&#34;&gt;2017&lt;/a&gt;)&lt;/span&gt;, the benefits of this layout, particularly for working with R, are demonstrated with the canonical &lt;a href=&#34;https://www.gapminder.org/data/&#34;&gt;&lt;code&gt;gapminder&lt;/code&gt;&lt;/a&gt; dataset. I recommend reading this short chapter in full. We will be applying similar approaches in the technique part of this class (which follows shortly) and also the &lt;a href=&#34;&#34;&gt;homework&lt;/a&gt;. To consolidate our conceptual understanding of &lt;strong&gt;tidy&lt;/strong&gt; data let’s quickly look at the &lt;code&gt;gapminder&lt;/code&gt; data, as it is a dataset we’re probably more likely to encounter.&lt;/p&gt;
&lt;p&gt;First, a &lt;strong&gt;tidy&lt;/strong&gt; version of the data:&lt;/p&gt;
&lt;table&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:gapminder-tidy&#34;&gt;Table 5: &lt;/span&gt;Tidy excerpt of &lt;a href=&#34;https://www.gapminder.org/data/&#34;&gt;&lt;code&gt;gapminder&lt;/code&gt;&lt;/a&gt; dataset.
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
country
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
year
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
cases
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
population
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Afghanistan
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1999
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
745
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
19987071
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Afghanistan
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2000
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2666
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
20595360
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Brazil
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1999
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
37737
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
172006362
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Brazil
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2000
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
80488
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
174504898
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
China
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1999
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
212258
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1272915272
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
China
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2000
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
213766
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1280428583
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;So the &lt;strong&gt;variables&lt;/strong&gt;:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;code&gt;country&lt;/code&gt;: a categorical nominal variable.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;year&lt;/code&gt;: a date (cyclic ratio) variable.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cases&lt;/code&gt;: a ratio (count) variable.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;population&lt;/code&gt;: a ratio (count) variable.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Each &lt;strong&gt;observation&lt;/strong&gt; is therefore a recorded count of cases and population for a country in a year.&lt;/p&gt;
&lt;p&gt;An alternative organisation of this dataset that appears in &lt;span class=&#34;citation&#34;&gt;Wickham and Grolemund (&lt;a href=&#34;#ref-wickham_r_2017&#34; role=&#34;doc-biblioref&#34;&gt;2017&lt;/a&gt;)&lt;/span&gt; is below. This is &lt;strong&gt;untidy&lt;/strong&gt; as the observations are spread across two rows. This makes operations that we might want to perform on the &lt;code&gt;cases&lt;/code&gt; and &lt;code&gt;population&lt;/code&gt; variables – for example computing exposure rates – somewhat tedious.&lt;/p&gt;
&lt;table&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:gapminder-untidy1&#34;&gt;Table 6: &lt;/span&gt;Untidy excerpt of &lt;a href=&#34;https://www.gapminder.org/data/&#34;&gt;&lt;code&gt;gapminder&lt;/code&gt;&lt;/a&gt; dataset: observations spread across rows
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
country
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
year
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
type
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
count
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Afghanistan
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1999
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
cases
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
745
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Afghanistan
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1999
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
population
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
19987071
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Afghanistan
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2000
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
cases
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2666
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Afghanistan
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2000
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
population
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
20595360
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Brazil
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1999
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
cases
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
37737
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Brazil
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1999
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
population
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
174504898
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
…
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
…
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
…
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
…
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This actually doesn’t appear in &lt;span class=&#34;citation&#34;&gt;Wickham and Grolemund (&lt;a href=&#34;#ref-wickham_r_2017&#34; role=&#34;doc-biblioref&#34;&gt;2017&lt;/a&gt;)&lt;/span&gt;, but imagine that the &lt;code&gt;gapminder&lt;/code&gt; dataset instead reported values of &lt;code&gt;cases&lt;/code&gt; separately by gender. A type of representation I’ve often seen in social sciences, probably as it is helpful for data entry, is where observations are spread across the columns. This too creates problems for performing aggregate functions, but also for specifying visualization designs (in &lt;a href=&#34;https://ggplot2.tidyverse.org/&#34;&gt;&lt;code&gt;ggplot2&lt;/code&gt;&lt;/a&gt;) as we will discover in the next session.&lt;/p&gt;
&lt;table&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:gapminder-untidy2&#34;&gt;Table 7: &lt;/span&gt;Untidy possible excerpt of &lt;a href=&#34;https://www.gapminder.org/data/&#34;&gt;&lt;code&gt;gapminder&lt;/code&gt;&lt;/a&gt; dataset: observations spread across columns
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
country
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
year
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
f_cases
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
m_cases
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
f_population
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
m_population
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Afghanistan
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1999
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
447
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
298
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9993400
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
9993671
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Afghanistan
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2000
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1599
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1067
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10296280
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
10299080
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Brazil
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1999
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
16982
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
20755
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
86001181
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
86005181
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Brazil
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2000
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
39440
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
41048
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
87251329
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
87253569
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
China
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1999
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
104007
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
108252
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
636451250
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
636464022
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
China
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2000
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
104746
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
109759
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
640212600
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
640215983
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;techniques&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Techniques&lt;/h2&gt;
&lt;p&gt;The technical element to this session involves importing, describing, transforming and tidying data from a large bikeshare scheme – New York’s &lt;a href=&#34;https://www.citibikenyc.com/&#34;&gt;Citibike&lt;/a&gt; scheme.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Download the &lt;a href=&#34;./homework/02-homework_files/02-template.Rmd&#34;&gt;&lt;i class=&#34;fab fa-r-project&#34;&gt;&lt;/i&gt; 02-template.Rmd&lt;/a&gt; file for this session and save it to the &lt;code&gt;reports&lt;/code&gt; folder of your &lt;code&gt;vis-for-gds&lt;/code&gt; project that you created in session 1.&lt;/li&gt;
&lt;li&gt;Open your &lt;code&gt;vis-for-gds&lt;/code&gt; project in RStudio and load the template file by clicking &lt;code&gt;File&lt;/code&gt; &amp;gt; &lt;code&gt;Open File ...&lt;/code&gt; &amp;gt; &lt;code&gt;reports/02-template.Rmd&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;import&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Import&lt;/h3&gt;
&lt;p&gt;In the template file there is a discussion of how to &lt;strong&gt;setup&lt;/strong&gt; your R session with key packages – &lt;code&gt;tidyverse&lt;/code&gt; , &lt;code&gt;fst&lt;/code&gt;, &lt;code&gt;lubridate&lt;/code&gt;, &lt;code&gt;sf&lt;/code&gt; – and also the &lt;a href=&#34;https://github.com/ropensci/bikedata&#34;&gt;&lt;code&gt;bikedata&lt;/code&gt;&lt;/a&gt; package for accessing bikeshare data.&lt;/p&gt;
&lt;p&gt;Available via the &lt;code&gt;bikedata&lt;/code&gt; package are trip and occupancy data for a number of bikeshare schemes (as below). We will work with data from New York’s &lt;a href=&#34;https://www.citibikenyc.com/&#34;&gt;Citibike&lt;/a&gt; scheme for June 2020. A list of all cities covered by the &lt;code&gt;bikedata&lt;/code&gt; package is below:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bike_cities()
##    city     city_name      bike_system
## 1    bo        Boston           Hubway
## 2    ch       Chicago            Divvy
## 3    dc Washington DC CapitalBikeShare
## 4    gu   Guadalajara           mibici
## 5    la   Los Angeles            Metro
## 6    lo        London        Santander
## 7    mo      Montreal             Bixi
## 8    mn   Minneapolis         NiceRide
## 9    ny      New York         Citibike
## 10   ph  Philadelphia           Indego
## 11   sf      Bay Area       FordGoBike&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the template there are code chunks demonstrating how to download and process these data using &lt;a href=&#34;https://github.com/ropensci/bikedata&#34;&gt;bikedata&lt;/a&gt;’s API. This is mainly for illustrative purposes and the code chunks take some time to execute. We ultimately use the &lt;a href=&#34;https://www.fstpackage.org/&#34;&gt;&lt;code&gt;fst&lt;/code&gt;&lt;/a&gt; package for serializing and reading in the these data. So I suggest you ignore the import code and calls to the &lt;code&gt;bikedata&lt;/code&gt; API and instead follow the instructions for downloading and reading in the &lt;code&gt;.fst&lt;/code&gt; file with the trips data and also the &lt;code&gt;.csv&lt;/code&gt; &lt;i class=&#34;fas fa-file-csv&#34;&gt;&lt;/i&gt; file containing stations data, with:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Create subdirectory in data folder for storing bike data.
if(!dir.exists(here(&amp;quot;data&amp;quot;, &amp;quot;bikedata&amp;quot;))) dir.create(here(&amp;quot;data&amp;quot;, &amp;quot;bikedata&amp;quot;))

# Read in .csv file of stations data from url.
tmp_file &amp;lt;- tempfile()
url &amp;lt;- &amp;quot;https://www.roger-beecham.com/datasets/ny_stations.csv&amp;quot;
curl::curl_download(url, tmp_file, mode=&amp;quot;wb&amp;quot;)
ny_stations &amp;lt;- read_csv(tmp_file)

# Read in .fst file of trips data from url.
tmp_file &amp;lt;- tempfile()
cs_url &amp;lt;- &amp;quot;https://www.roger-beecham.com/datasets/ny_trips.fst&amp;quot;
curl::curl_download(url, tmp_file, mode=&amp;quot;wb&amp;quot;)
ny_trips &amp;lt;- read_fst(tmp_file)

# Write out to subdirectory for future use.
write_fst(trips, here(&amp;quot;data&amp;quot;, &amp;quot;ny_trips.fst&amp;quot;))
write_csv(stations, here(&amp;quot;data&amp;quot;, &amp;quot;ny_stations.csv&amp;quot;))

# Clean workspace.
rm(url, tmp_file)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;code&gt;fst&lt;/code&gt; implements in the background various operations such as multi-threading to reduce load on disk space. It therefore makes it possible to work with large datasets in-memory in &lt;code&gt;R&lt;/code&gt; rather than connecting to a database and serving up summaries/subsets to be loaded into R. We will be working with just 2 million records, but with &lt;code&gt;fst&lt;/code&gt; it is possible to work in-memory with much larger datasets – in &lt;span class=&#34;citation&#34;&gt;Lovelace (&lt;a href=&#34;#ref-lovelace_is_2020&#34; role=&#34;doc-biblioref&#34;&gt;2020&lt;/a&gt;)&lt;/span&gt; we ended up working with 80 million + trip records.
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;If you completed the reading and research from the &lt;a href=&#34;./homework/01-homework/&#34;&gt;Session 1 Homework&lt;/a&gt;, some of the above should be familiar to you. The key arguments to look at are &lt;code&gt;read_csv()&lt;/code&gt; and &lt;code&gt;read_fst()&lt;/code&gt;, into which we pass the path to the file. In this case we created a &lt;code&gt;tmpfile()&lt;/code&gt; within the R session. We then write these data out and save locally to the project’s &lt;code&gt;data&lt;/code&gt; folder. This is useful as we only want to download the data once. In the &lt;code&gt;write_*&amp;lt;&amp;gt;&lt;/code&gt; functions we reference this location using the &lt;a href=&#34;https://here.r-lib.org/&#34;&gt;&lt;code&gt;here&lt;/code&gt;&lt;/a&gt; package’s &lt;code&gt;here()&lt;/code&gt; function. &lt;a href=&#34;https://here.r-lib.org/&#34;&gt;&lt;code&gt;here&lt;/code&gt;&lt;/a&gt; is really useful for reliably creating paths relative to your project’s root. To read in these data for future sessions:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Read in these local copies of the trips and stations data.
ny_trips &amp;lt;- read_fst(here(&amp;quot;data&amp;quot;, &amp;quot;ny_trips.fst&amp;quot;))
ny_stations &amp;lt;- read_csv(here(&amp;quot;data&amp;quot;, &amp;quot;ny_stations.csv&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice that we use &lt;strong&gt;assignment&lt;/strong&gt; here (&lt;code&gt;&amp;lt;-&lt;/code&gt;) so that these data are loaded as objects and appear in the Environment pane of your RStudio window. An efficient description of data import with &lt;code&gt;read_csv()&lt;/code&gt; is also in &lt;a href=&#34;https://r4ds.had.co.nz/data-import.html&#34;&gt;Chapter 11&lt;/a&gt; of &lt;span class=&#34;citation&#34;&gt;Wickham and Grolemund (&lt;a href=&#34;#ref-wickham_r_2017&#34; role=&#34;doc-biblioref&#34;&gt;2017&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;
&lt;code&gt;ny_stations&lt;/code&gt; and &lt;code&gt;ny_trips&lt;/code&gt; are data frames, spreadsheet type representations containing observations in rows and variables in columns. Inspecting the layout of the stations data with &lt;code&gt;View(ny_stations)&lt;/code&gt; you will notice that the top line is the header and contains column (variable) names.
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:view-annotate&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;./class/02-class_files/view.png&#34; alt=&#34;`ny_trips` and `ny_stations` as they appear when calling `View()`.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: &lt;code&gt;ny_trips&lt;/code&gt; and &lt;code&gt;ny_stations&lt;/code&gt; as they appear when calling &lt;code&gt;View()&lt;/code&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;describe&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Describe&lt;/h3&gt;
&lt;p&gt;There are several functions for generating a quick overview of a data frame’s contents. &lt;code&gt;glimpse&amp;lt;dataset-name&amp;gt;&lt;/code&gt; is particularly useful. It provides a summary of the data frame dimensions – we have c. 1.9 million trip observations in &lt;code&gt;ny_trips&lt;/code&gt; and 11 variables. The function also prints out the object type for each of these variables, with the variables either of type &lt;code&gt;int&lt;/code&gt; or &lt;code&gt;chr&lt;/code&gt; in this case.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glimpse(ny_trips)
## Rows: 1,882,273
## Columns: 11
## $ id               &amp;lt;int&amp;gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21…
## $ city             &amp;lt;chr&amp;gt; &amp;quot;ny&amp;quot;, &amp;quot;ny&amp;quot;, &amp;quot;ny&amp;quot;, &amp;quot;ny&amp;quot;, &amp;quot;ny&amp;quot;, &amp;quot;ny&amp;quot;, &amp;quot;ny&amp;quot;, &amp;quot;ny&amp;quot;, &amp;quot;ny&amp;quot;, &amp;quot;ny&amp;quot;, &amp;quot;ny&amp;quot;, &amp;quot;ny&amp;quot;, &amp;quot;…
## $ trip_duration    &amp;lt;dbl&amp;gt; 1062, 3810, 1017, 226, 1437, 355, 99, 1810, 87, 2714, 2096, 1611, 529, 69…
## $ start_time       &amp;lt;chr&amp;gt; &amp;quot;2020-06-01 00:00:03&amp;quot;, &amp;quot;2020-06-01 00:00:03&amp;quot;, &amp;quot;2020-06-01 00:00:09&amp;quot;, &amp;quot;202…
## $ stop_time        &amp;lt;chr&amp;gt; &amp;quot;2020-06-01 00:17:46&amp;quot;, &amp;quot;2020-06-01 01:03:33&amp;quot;, &amp;quot;2020-06-01 00:17:06&amp;quot;, &amp;quot;202…
## $ start_station_id &amp;lt;chr&amp;gt; &amp;quot;ny3419&amp;quot;, &amp;quot;ny366&amp;quot;, &amp;quot;ny389&amp;quot;, &amp;quot;ny3255&amp;quot;, &amp;quot;ny367&amp;quot;, &amp;quot;ny248&amp;quot;, &amp;quot;ny3232&amp;quot;, &amp;quot;ny3263…
## $ end_station_id   &amp;lt;chr&amp;gt; &amp;quot;ny3419&amp;quot;, &amp;quot;ny336&amp;quot;, &amp;quot;ny3562&amp;quot;, &amp;quot;ny505&amp;quot;, &amp;quot;ny497&amp;quot;, &amp;quot;ny247&amp;quot;, &amp;quot;ny390&amp;quot;, &amp;quot;ny496&amp;quot;,…
## $ bike_id          &amp;lt;chr&amp;gt; &amp;quot;39852&amp;quot;, &amp;quot;37558&amp;quot;, &amp;quot;37512&amp;quot;, &amp;quot;39674&amp;quot;, &amp;quot;21093&amp;quot;, &amp;quot;39594&amp;quot;, &amp;quot;43315&amp;quot;, &amp;quot;16571&amp;quot;, &amp;quot;…
## $ user_type        &amp;lt;chr&amp;gt; &amp;quot;Customer&amp;quot;, &amp;quot;Subscriber&amp;quot;, &amp;quot;Customer&amp;quot;, &amp;quot;Customer&amp;quot;, &amp;quot;Customer&amp;quot;, &amp;quot;Subscriber…
## $ birth_year       &amp;lt;chr&amp;gt; &amp;quot;1997&amp;quot;, &amp;quot;1969&amp;quot;, &amp;quot;1988&amp;quot;, &amp;quot;1969&amp;quot;, &amp;quot;1997&amp;quot;, &amp;quot;1990&amp;quot;, &amp;quot;1938&amp;quot;, &amp;quot;1995&amp;quot;, &amp;quot;1971&amp;quot;, &amp;quot;…
## $ gender           &amp;lt;dbl&amp;gt; 2, 0, 2, 0, 2, 1, 2, 2, 2, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glimpse(ny_stations)
## Rows: 1,010
## Columns: 6
## $ id        &amp;lt;int&amp;gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 2…
## $ city      &amp;lt;chr&amp;gt; &amp;quot;ny&amp;quot;, &amp;quot;ny&amp;quot;, &amp;quot;ny&amp;quot;, &amp;quot;ny&amp;quot;, &amp;quot;ny&amp;quot;, &amp;quot;ny&amp;quot;, &amp;quot;ny&amp;quot;, &amp;quot;ny&amp;quot;, &amp;quot;ny&amp;quot;, &amp;quot;ny&amp;quot;, &amp;quot;ny&amp;quot;, &amp;quot;ny&amp;quot;, &amp;quot;ny&amp;quot;, &amp;quot;n…
## $ stn_id    &amp;lt;chr&amp;gt; &amp;quot;ny116&amp;quot;, &amp;quot;ny119&amp;quot;, &amp;quot;ny120&amp;quot;, &amp;quot;ny127&amp;quot;, &amp;quot;ny128&amp;quot;, &amp;quot;ny143&amp;quot;, &amp;quot;ny144&amp;quot;, &amp;quot;ny146&amp;quot;, &amp;quot;ny150&amp;quot;,…
## $ name      &amp;lt;chr&amp;gt; &amp;quot;W 17 St &amp;amp; 8 Ave&amp;quot;, &amp;quot;Park Ave &amp;amp; St Edwards St&amp;quot;, &amp;quot;Lexington Ave &amp;amp; Classon Ave&amp;quot;, &amp;quot;B…
## $ longitude &amp;lt;chr&amp;gt; &amp;quot;-74.00149746&amp;quot;, &amp;quot;-73.97803415&amp;quot;, &amp;quot;-73.95928168&amp;quot;, &amp;quot;-74.00674436&amp;quot;, &amp;quot;-74.00297088&amp;quot;, …
## $ latitude  &amp;lt;chr&amp;gt; &amp;quot;40.74177603&amp;quot;, &amp;quot;40.69608941&amp;quot;, &amp;quot;40.68676793&amp;quot;, &amp;quot;40.73172428&amp;quot;, &amp;quot;40.72710258&amp;quot;, &amp;quot;40.6…&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:data-types&#34;&gt;Table 8: &lt;/span&gt;A breakdown of data types in R.
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Type
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Description
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;code&gt;lgl&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Logical – vectors that can contain only &lt;code&gt;TRUE&lt;/code&gt; or &lt;code&gt;FALSE&lt;/code&gt; values
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;code&gt;int&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Integers – whole numbers
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;code&gt;dbl&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Double – real numbers with decimals
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;code&gt;chr&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Character – text strings
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;code&gt;dttm&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Date-times – a date + a time
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;code&gt;fctr&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Factors – represent categorical variables of fixed and potentially orderable values
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The object type of a variable in a data frane relates to that variable’s &lt;em&gt;measurement level&lt;/em&gt;. It is often useful to convert to types with greater specificity. For example, we may which to convert the &lt;code&gt;start_time&lt;/code&gt; and &lt;code&gt;stop_time&lt;/code&gt; variables to a date-time format so that various time-related functions could be used. For efficient storage, we may wish to convert the &lt;em&gt;station identifier&lt;/em&gt; variables as &lt;code&gt;int&lt;/code&gt; types by removing the redundant “ny” text which prefaces &lt;code&gt;end_station_id&lt;/code&gt;, &lt;code&gt;end_station_id&lt;/code&gt;, &lt;code&gt;stn_id&lt;/code&gt;. The geographic coordinates are currently stored as type &lt;code&gt;chr&lt;/code&gt;. These could be regarded as quantitative variables, floating points with decimals. So converting to type &lt;code&gt;dbl&lt;/code&gt; or as a &lt;a href=&#34;https://r-spatial.github.io/sf/articles/sf1.html#simple-feature-geometry-types&#34;&gt;&lt;code&gt;POINT&lt;/code&gt;&lt;/a&gt; geometry type (more on this later in the module) may be sensible.&lt;/p&gt;
&lt;p&gt;In the &lt;a href=&#34;./homework/02-homework_files/02-template.Rmd&#34;&gt;&lt;i class=&#34;fab fa-r-project&#34;&gt;&lt;/i&gt; 02-template.Rmd&lt;/a&gt; file there are code chunks for doing these conversions. There are some slightly more involved data transform procedures in this code. Don’t fixate too much on these, but the upshot can be seen when running &lt;code&gt;glimpse()&lt;/code&gt; on the converted data frames:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glimpse(ny_trips)
## Rows: 1,882,273
## Columns: 10
## $ id               &amp;lt;int&amp;gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 2…
## $ trip_duration    &amp;lt;dbl&amp;gt; 1062, 3810, 1017, 226, 1437, 355, 99, 1810, 87, 2714, 2096, 1611, 529, 695, 206,…
## $ start_time       &amp;lt;dttm&amp;gt; 2020-06-01 00:00:03, 2020-06-01 00:00:03, 2020-06-01 00:00:09, 2020-06-01 00:00…
## $ stop_time        &amp;lt;dttm&amp;gt; 2020-06-01 00:00:03, 2020-06-01 00:00:03, 2020-06-01 00:00:09, 2020-06-01 00:00…
## $ start_station_id &amp;lt;int&amp;gt; 3419, 366, 389, 3255, 367, 248, 3232, 3263, 390, 319, 237, 3630, 3610, 3708, 465…
## $ end_station_id   &amp;lt;int&amp;gt; 3419, 336, 3562, 505, 497, 247, 390, 496, 3232, 455, 3263, 3630, 3523, 3740, 379…
## $ bike_id          &amp;lt;int&amp;gt; 39852, 37558, 37512, 39674, 21093, 39594, 43315, 16571, 28205, 41760, 30745, 380…
## $ user_type        &amp;lt;chr&amp;gt; &amp;quot;Customer&amp;quot;, &amp;quot;Subscriber&amp;quot;, &amp;quot;Customer&amp;quot;, &amp;quot;Customer&amp;quot;, &amp;quot;Customer&amp;quot;, &amp;quot;Subscriber&amp;quot;, &amp;quot;Sub…
## $ birth_year       &amp;lt;int&amp;gt; 1997, 1969, 1988, 1969, 1997, 1990, 1938, 1995, 1971, 1989, 1990, 1969, 1984, 19…
## $ gender           &amp;lt;chr&amp;gt; &amp;quot;female&amp;quot;, &amp;quot;unknown&amp;quot;, &amp;quot;female&amp;quot;, &amp;quot;unknown&amp;quot;, &amp;quot;female&amp;quot;, &amp;quot;male&amp;quot;, &amp;quot;female&amp;quot;, &amp;quot;female&amp;quot;, …&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glimpse(ny_stations)
## Rows: 1,010
## Columns: 5
## $ id        &amp;lt;dbl&amp;gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, …
## $ stn_id    &amp;lt;int&amp;gt; 116, 119, 120, 127, 128, 143, 144, 146, 150, 151, 157, 161, 164, 167, 168, 173, 174, 19…
## $ name      &amp;lt;chr&amp;gt; &amp;quot;W 17 St &amp;amp; 8 Ave&amp;quot;, &amp;quot;Park Ave &amp;amp; St Edwards St&amp;quot;, &amp;quot;Lexington Ave &amp;amp; Classon Ave&amp;quot;, &amp;quot;Barrow S…
## $ longitude &amp;lt;dbl&amp;gt; -74.00150, -73.97803, -73.95928, -74.00674, -74.00297, -73.99338, -73.98069, -74.00911,…
## $ latitude  &amp;lt;dbl&amp;gt; 40.74178, 40.69609, 40.68677, 40.73172, 40.72710, 40.69240, 40.69840, 40.71625, 40.7208…&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;transform&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Transform&lt;/h3&gt;
&lt;div id=&#34;transform-with-dplyr&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Transform with &lt;code&gt;dplyr&lt;/code&gt;&lt;/h4&gt;
&lt;table&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:dplyr-verbs&#34;&gt;Table 9: &lt;/span&gt;dplyr funcitions (verbs) for manipulating data frames.
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
function()
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Description
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;code&gt;filter()&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Picks rows (observations) if their values match a specified criteria
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;code&gt;arrange()&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Reorders rows (observations) based on their values
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;code&gt;select()&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Picks a subset of columns (variables) by name (or name characteristics)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;code&gt;rename()&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Changes the name of columns in the data frame
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;code&gt;mutate()&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Adds new columns (or variables)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;code&gt;group_by()&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Chunks the dataset into groups for grouped operations
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;code&gt;summarise()&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Calculate single-row (non-grouped) or multiple-row (if grouped) summary values
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;code&gt;..and more&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;a href=&#34;https://dplyr.tidyverse.org/&#34;&gt;&lt;code&gt;dplyr&lt;/code&gt;&lt;/a&gt; is one of the most important packages for supporting modern data analysis workflows. The package provides a &lt;strong&gt;grammar of data manipulation&lt;/strong&gt;, with access to functions that can be variously combined to support most data processing and transformation activity. Once you become familiar with &lt;code&gt;dplyr&lt;/code&gt; functions (or &lt;strong&gt;verbs&lt;/strong&gt;) you will find yourself generating analysis templates to re-use whenever you work on a new dataset.&lt;/p&gt;
&lt;p&gt;All &lt;code&gt;dplyr&lt;/code&gt; functions work in the same way:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Start with a data frame.&lt;/li&gt;
&lt;li&gt;Pass some arguments to the function which control what you do to the data frame.&lt;/li&gt;
&lt;li&gt;Return the updated data frame.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So every &lt;code&gt;dplyr&lt;/code&gt; function expects a data frame and will always return a data frame.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;use-pipes-with-dplyr&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Use pipes &lt;code&gt;%&amp;gt;%&lt;/code&gt; with &lt;code&gt;dplyr&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;dplyr&lt;/code&gt; is most effective when its functions are chained together – you will see this shortly as we explore the New York bikeshare data. This chaining of functions can be achieved using the &lt;strong&gt;pipe&lt;/strong&gt; operator (&lt;code&gt;%&amp;gt;%&lt;/code&gt;). Pipes are used for passing information in a program. They take the output of a set of code (a &lt;code&gt;dplyr&lt;/code&gt; specification) and make it the input of the next set (another &lt;code&gt;dplyr&lt;/code&gt; specification).&lt;/p&gt;
&lt;p&gt;Pipes can be easily applied to &lt;code&gt;dplyr&lt;/code&gt; functions, and the functions of all packages that form the &lt;code&gt;tidyverse&lt;/code&gt;. I mentioned in &lt;a href=&#34;./class/01-class&#34;&gt;Session 1&lt;/a&gt; that &lt;code&gt;ggplot2&lt;/code&gt; provides a framework for specifying a &lt;strong&gt;layered grammar of graphics&lt;/strong&gt; (more on this in Session 3). Together with the pipe operator (&lt;code&gt;%&amp;gt;%&lt;/code&gt;), &lt;code&gt;dplyr&lt;/code&gt; supports a &lt;strong&gt;layered grammar of data manipulation&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;count-rows&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;&lt;code&gt;count()&lt;/code&gt; rows&lt;/h4&gt;
&lt;p&gt;This might sound a little abstract so let’s use and combine some &lt;code&gt;dplyr&lt;/code&gt; functions to generate some statistical summaries on the New York bikeshare data.&lt;/p&gt;
&lt;p&gt;First we’ll count the number of trips made in Jun 2020 by gender. &lt;code&gt;dplyr&lt;/code&gt; has a convenience function for counting, so we could run the code below, also in the &lt;a href=&#34;./homework/02-homework_files/02-template.Rmd&#34;&gt;&lt;i class=&#34;fab fa-r-project&#34;&gt;&lt;/i&gt; 02-template.Rmd&lt;/a&gt; for this session. I’ve commented the code block to convey what each line achieves.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ny_trips %&amp;gt;%  # Take the ny_trips data frame.
  count(gender, sort=TRUE) # Run the count function over the data frame and set the sort parameter to TRUE.
##    gender       n
## 1    male 1044621
## 2  female  586361
## 3 unknown  251291&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are a few things happening in the &lt;code&gt;count()&lt;/code&gt; function. It takes the &lt;code&gt;gender&lt;/code&gt; variable from &lt;code&gt;ny_trips&lt;/code&gt;, organises or &lt;em&gt;groups&lt;/em&gt; the rows in the data frame according to its values (&lt;code&gt;female&lt;/code&gt; | &lt;code&gt;male&lt;/code&gt; | &lt;code&gt;unknown&lt;/code&gt;), counts the rows and then orders the &lt;em&gt;summarised&lt;/em&gt; output descending on the counts.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;summarise-over-rows&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;&lt;code&gt;summarise()&lt;/code&gt; over rows&lt;/h4&gt;
&lt;table&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:aggregate-functions&#34;&gt;Table 10: &lt;/span&gt;A breakdown of aggregate functions commonly used with &lt;code&gt;summarise()&lt;/code&gt;.
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Function
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Description
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;code&gt;n()&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Counts the number of observations
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;code&gt;n_distinct(var)&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Counts the number of unique observations
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;code&gt;sum(var)&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Sums the values of observations
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;code&gt;max(var)&lt;/code&gt;|&lt;code&gt;min(var)&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Finds the min|max values of observations
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;code&gt;mean(var)&lt;/code&gt;|&lt;code&gt;median(var)&lt;/code&gt;|&lt;code&gt;sd(var)&lt;/code&gt;| &lt;code&gt;...&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Calculates central tendency of observations
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&lt;code&gt;...&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Many more
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Often you will want to do more than simply counting and you may also want to be more explicit in the way the data frame is &lt;em&gt;grouped&lt;/em&gt; for computation. We’ll demonstrate this here with a more involved analysis of the usage data and using some key aggregate functions (Table &lt;a href=&#34;#tab:aggregate-functions&#34;&gt;10&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;A common workflow is to combine &lt;code&gt;group_by()&lt;/code&gt; and &lt;code&gt;summarise()&lt;/code&gt;, and in this case &lt;code&gt;arrange()&lt;/code&gt; to replicate the &lt;code&gt;count()&lt;/code&gt; example.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ny_trips %&amp;gt;% # Take the ny_trips data frame.
  group_by(gender) %&amp;gt;% # Group by gender.
  summarise(count=n()) %&amp;gt;% # Count the number of observations per group.
  arrange(desc(count)) # Arrange the grouped and summarised (collapsed) rows according to count.
## # A tibble: 3 x 2
##  gender    count
##  &amp;lt;chr&amp;gt;     &amp;lt;int&amp;gt;
## 1 male    1044621
## 2 female   586361
## 3 unknown  251291&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In &lt;code&gt;ny_trips&lt;/code&gt; there is a variable measuring trip duration in seconds (&lt;code&gt;trip_duration&lt;/code&gt;) and distinguishing casual users from those formally registered to use the scheme (&lt;code&gt;user_type&lt;/code&gt; - &lt;code&gt;Customer&lt;/code&gt; vs. &lt;code&gt;Subscriber&lt;/code&gt;). It may be instructive to calculate some summary statistics to see how trip duration varies between these groups.&lt;/p&gt;
&lt;p&gt;The code below uses &lt;code&gt;group_by()&lt;/code&gt;, &lt;code&gt;summarise()&lt;/code&gt; and &lt;code&gt;arrange()&lt;/code&gt; in exactly the same way, but with the addition of other aggregate functions profiles the &lt;code&gt;trip_duration&lt;/code&gt; variable according to central tendency and by &lt;code&gt;user_type&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ny_trips %&amp;gt;% # Take the ny_trips data frame.
  group_by(user_type) %&amp;gt;% # Group by user type.
  summarise( # Summarise over the grouped rows, generate a new variable for each type of summary.
    count=n(),
    avg_duration=mean(trip_duration/60),
    median_duration=median(trip_duration/60),
    sd_duration=sd(trip_duration/60),
    min_duration=min(trip_duration/60),
    max_duration=min(trip_duration/60)
    ) %&amp;gt;%
  arrange(desc(count)) # Arrange on the count variable.

## # A tibble: 2 x 6
##  user_type    count avg_duration median_duration sd_duration min_duration max_duration
##  &amp;lt;chr&amp;gt;        &amp;lt;int&amp;gt;        &amp;lt;dbl&amp;gt;           &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;
## 1 Subscriber 1306688         20.2            14.4        110.         1.02         1.02
## 2 Customer    575585         43.6            23.2        393.         1.02         1.02&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Clearly there are some outlier trips that may need to be examined. Bikeshare schemes are built to incentivise short journeys of &amp;lt;30 minutes. However, the max trip duration made by a &lt;code&gt;Subscriber&lt;/code&gt; was almost 2 hours and a &lt;code&gt;Customer&lt;/code&gt; 6.5 hours. These may be legitimate trips rather than errors in the data – the durations are not in the order of months or years. It also makes sense that more casual users may have longer trip durations, as they are more likely to be tourists or occasional cyclists using the scheme for non-utility trips. However, they do skew the mean travel time.&lt;/p&gt;
&lt;p&gt;Returning to the breakdown of usage by gender, an interesting question is whether or not the male-female split in bikehare is similar to that of the cycling population of New York City as a whole. This might tell us something about whether the bikeshare scheme could be &lt;em&gt;representative&lt;/em&gt; of wider cycling. This could be achieved with the code below. A couple of new additions: we use &lt;code&gt;filter()&lt;/code&gt;, to remove observations where the gender of the cyclist is &lt;code&gt;unknown&lt;/code&gt;. We also use &lt;code&gt;mutate()&lt;/code&gt; for the first time, which allows us to modify or create new variables.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ny_trips %&amp;gt;% # Take the ny_trips data frame.
  filter(gender != &amp;quot;unknown&amp;quot;) %&amp;gt;% # Filter out rows with the value &amp;quot;unknown&amp;quot; on gender.
  group_by(gender) %&amp;gt;% # Group by gender.
  summarise(count=n()) %&amp;gt;% # Count the number of observations per group.
  mutate(prop=count/sum(count)) %&amp;gt;% # Add a new column called `prop`, divide the value in the row for the variable count by the sum of the count variable across all rows.
  arrange(desc(count)) # Arrange on the count variable.

## # A tibble: 2 x 3
##  gender   count  prop
##  &amp;lt;chr&amp;gt;    &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt;
## 1 male   1044621 0.640
## 2 female  586361 0.360&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As I’ve commented each line you hopefully get a sense of what is happening in the code above. I mentioned that &lt;code&gt;dplyr&lt;/code&gt; functions read like &lt;strong&gt;verbs&lt;/strong&gt;. This is a very deliberate design decision. With the code laid out as above – each &lt;code&gt;dplyr&lt;/code&gt; verb occupying a single line, separated by a pipe (&lt;code&gt;%&amp;gt;%&lt;/code&gt;) – you can generally understand the code with a cursory glance. There are obvious benefits to this. Once you become familiar with &lt;code&gt;dplyr&lt;/code&gt; it becomes very easy to read, write and share code.&lt;/p&gt;
&lt;p&gt;

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Remembering that &lt;strong&gt;pipes&lt;/strong&gt; (&lt;code&gt;%&amp;gt;%&lt;/code&gt;) take the output of a set of code and make it the input of the next set, what do you think would happen if you were to comment out the call to &lt;code&gt;arrange()&lt;/code&gt; in the code block above? Try it for yourself. You will notice that I use separate lines for each call to the &lt;strong&gt;pipe&lt;/strong&gt; operator. This is good practice for supporting readibility of your code.
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;manipulate-dates-with-lubridate&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Manipulate dates with &lt;a href=&#34;https://lubridate.tidyverse.org/&#34;&gt;&lt;code&gt;lubridate&lt;/code&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;Let’s continue this investigation of usage by gender, and whether bikeshare might be representative of regular cycling, by profiling how usage varies over time. To do this we will need to work with &lt;code&gt;date-time&lt;/code&gt; variables. The &lt;a href=&#34;https://lubridate.tidyverse.org/&#34;&gt;&lt;code&gt;lubridate&lt;/code&gt;&lt;/a&gt; package provides various convenience functions for this.&lt;/p&gt;
&lt;p&gt;In the code block below we extract the &lt;em&gt;day of week&lt;/em&gt; and &lt;em&gt;hour of day&lt;/em&gt; from the &lt;code&gt;start_time&lt;/code&gt; variable using &lt;code&gt;lubridate&lt;/code&gt;’s &lt;a href=&#34;https://lubridate.tidyverse.org/reference/day.html&#34;&gt;day accessor&lt;/a&gt; functions. Documentation on these can be accessed in the usual way (&lt;code&gt;?&amp;lt;function-name&amp;gt;&lt;/code&gt;), but reading down the code it should be clear to you how this works. Next we count the number of trips made by hour of day, day of week and gender. The summarised data frame will be re-used several times in our analysis, so we store it as an object with a suitable name (&lt;code&gt;ny_temporal&lt;/code&gt;) using the assignment operator.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Create a hod dow summary by gender and assign it the name &amp;quot;ny_temporal&amp;quot;.
ny_temporal &amp;lt;- ny_trips %&amp;gt;%  # Take the ny_trips data frame.
  mutate(
    day=wday(start_time, label=TRUE), # Create a new column identify dow.
    hour=hour(start_time)) %&amp;gt;% # Create a new column identify hod.
  group_by(gender, day, hour) %&amp;gt;% # Group by day, hour, gender.
  summarise(count=n()) %&amp;gt;% # Count the grouped rows.
  ungroup()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Whether or not to store derived data tables like &lt;code&gt;ny_temporal&lt;/code&gt; in a session is not an easy decision. You want to try to avoid cluttering your Environment pane with many data objects. Often when generating charts it is necessary to create these sorts of derived tables as input data (to &lt;code&gt;ggplot2&lt;/code&gt;) – and so when doing visual data analysis you may end up with an unhelpfully large number of these derived tables. The general rule I apply: if the derived table is to be used &amp;gt;3 times in a data analysis or is computationally intensive, assign it to an object.
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;In Figure &lt;a href=&#34;#fig:plot-temporal&#34;&gt;2&lt;/a&gt; below these derived data are plotted. The template contains &lt;code&gt;ggplot2&lt;/code&gt; code for creating the graphic. Don’t obsess too much on it – more on this next session. The plot demonstrates a familiar weekday-weekend pattern of usage. Trip frequencies peak in the morning and evening rush hours during weekdays and mid/late-morning and afternoon during weekends. This is consistent with typical travel behaviour. Notice though that the weekday afternoon peak is much larger than the morning peak. There are several speculative explanations for this and re-running the plot on &lt;code&gt;Subscriber&lt;/code&gt; users only may be instructive. A secondary observation is that whilst men and women share this overall pattern of usage, the relative number of trips taken by each day of week varies. Men make many more trips at peak times during the start of the week than they do later in the week. The same pattern does not appear for women. This is certainly something to follow up on, for example by collecting data over a longer period of time.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:plot-temporal&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;./class/02-class_files/hod_dow.png&#34; alt=&#34;Line charts generated with `ggplot2`. Plot data computed using `dplyr` and `lubridate`.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 2: Line charts generated with &lt;code&gt;ggplot2&lt;/code&gt;. Plot data computed using &lt;code&gt;dplyr&lt;/code&gt; and &lt;code&gt;lubridate&lt;/code&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Our analysis is based on data from June 2020, a time when New York residents were emerging from lockdown. It would be instructive to compare with data from a non-Covid year. If there is a very clear contrast in usage between this data and a control (non-Covid) year, this suggests bikeshare data may be used for monitoring &lt;em&gt;behavioural change&lt;/em&gt;. The fact that bikeshare is collected continuously makes this possible. Check out &lt;a href=&#34;https://github.com/jwoLondon/mobv&#34;&gt;Jo Wood’s current work&lt;/a&gt; analysing Covid-related change in movement behaviours across a range of cities.
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;relate-tables-with-join&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Relate tables with &lt;code&gt;join()&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;Trip distance is not recorded directly in the &lt;code&gt;ny_trips&lt;/code&gt; table, but may be important for profiling usage behaviour. Calculating trip distance is eminently achievable as the &lt;code&gt;ny_trips&lt;/code&gt; table contains the origin and destination station of every trip and the &lt;code&gt;ny_stations&lt;/code&gt; table contains coordinates corresponding to those stations. To relate the two tables, we need to specify a &lt;strong&gt;join&lt;/strong&gt; between them.&lt;/p&gt;
&lt;p&gt;A sensible approach is to:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Select all uniquely cycled trip pairs (origin-destination pairs) that appear in the &lt;code&gt;ny_trips&lt;/code&gt; table.&lt;/li&gt;
&lt;li&gt;Bring in the corresponding coordinate pairs representing the origin and destination stations by joining on the &lt;code&gt;ny_stations&lt;/code&gt; table.&lt;/li&gt;
&lt;li&gt;Calculate the distance between the coordinate pairs representing the origin and destination.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The code below is one way of achieving this.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;od_pairs &amp;lt;- ny_trips %&amp;gt;% # Take the ny_trips data frame.
select(start_station_id, end_station_id) %&amp;gt;% unique() %&amp;gt;% # Select trip origin and destination (OD) station columns and extract unique OD pairs.
  left_join(ny_stations %&amp;gt;% select(stn_id, longitude, latitude), by=c(&amp;quot;start_station_id&amp;quot;=&amp;quot;stn_id&amp;quot;)) %&amp;gt;% # Select lat, lon columns from ny_stations and join on the origin column.
  rename(o_lon=longitude, o_lat=latitude) %&amp;gt;% # Rename new lat, lon columns -- associate with origin station.
  left_join(ny_stations %&amp;gt;% select(stn_id, longitude, latitude), by=c(&amp;quot;end_station_id&amp;quot;=&amp;quot;stn_id&amp;quot;)) %&amp;gt;% # Select lat, lon columns from ny_stations and join on the destination column.
  rename(d_lon=longitude, d_lat=latitude) %&amp;gt;%  # Rename new lat, lon columns -- associate with destination station.
  rowwise() %&amp;gt;% # For computing distance calculation one row-at-a-time.
  mutate(dist=geosphere::distHaversine(c(o_lat, o_lon), c(d_lat, d_lon))/1000) %&amp;gt;% # Calculate distance and express in kms.
  ungroup()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The code block above introduces some new functions: &lt;code&gt;select()&lt;/code&gt; to pick or drop variables, &lt;code&gt;rename()&lt;/code&gt; to rename variables and a convenience function for calculating straight line distance from polar coordinates (&lt;code&gt;distHaversine()&lt;/code&gt;). The key function to emphasise is the &lt;code&gt;left_join()&lt;/code&gt;. If you’ve worked with relational databases and &lt;code&gt;SQL&lt;/code&gt;, &lt;code&gt;dplyr&lt;/code&gt;’s join functions will be familiar to you. In a &lt;code&gt;left_join&lt;/code&gt;, all the values from the main table are retained, the one on the left – &lt;code&gt;ny_trips&lt;/code&gt;, and variables from the table on the right (&lt;code&gt;ny_stations&lt;/code&gt;) are added. We specify explicitly the variable on which the tables should be joined with the &lt;code&gt;by=&lt;/code&gt; parameter, &lt;code&gt;station_id&lt;/code&gt; in this case. If there is a &lt;code&gt;station_id&lt;/code&gt; in &lt;code&gt;ny_trips&lt;/code&gt; that doesn’t exist in &lt;code&gt;ny_stations&lt;/code&gt; then &lt;code&gt;NA&lt;/code&gt; is returned.&lt;/p&gt;
&lt;p&gt;Other &lt;strong&gt;join&lt;/strong&gt; functions provided by &lt;code&gt;dplyr&lt;/code&gt; are in the table below. Rather than discussing each, I recommend consulting &lt;a href=&#34;https://r4ds.had.co.nz/relational-data.html&#34;&gt;Chapter 13&lt;/a&gt; of &lt;span class=&#34;citation&#34;&gt;Wickham and Grolemund (&lt;a href=&#34;#ref-wickham_r_2017&#34; role=&#34;doc-biblioref&#34;&gt;2017&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; &#34; colspan=&#34;1&#34;&gt;
&lt;div style=&#34;border-bottom: 1px solid #ddd; padding-bottom: 5px; &#34;&gt;
&lt;code&gt;*_join(x, y) ...&lt;/code&gt;
&lt;/div&gt;
&lt;/th&gt;
&lt;th style=&#34;empty-cells: hide;border-bottom:hidden;&#34; colspan=&#34;1&#34;&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:table-joins&#34;&gt;Table 11: &lt;/span&gt;A breakdown of &lt;code&gt;dplyr&lt;/code&gt; join functions.
&lt;/caption&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;width: 10em; &#34;&gt;
&lt;code&gt;left_join()&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
all rows from x
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;width: 10em; &#34;&gt;
&lt;code&gt;right_join()&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
all rows from y
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;width: 10em; &#34;&gt;
&lt;code&gt;full_join()&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
all rows from both x and y
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;width: 10em; &#34;&gt;
&lt;code&gt;semi_join()&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
all rows from x where there are matching values in y, keeping just columns from x
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;width: 10em; &#34;&gt;
&lt;code&gt;inner_join()&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
all rows from x where there are matching values in y, return all combination of multiple matches in the case of multiple matches
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;width: 10em; &#34;&gt;
&lt;code&gt;anti_join&lt;/code&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
return all rows from x where there are not matching values in y, never duplicate rows of x
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:plot-dist&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;./class/02-class_files/dist.png&#34; alt=&#34;Histograms generated with `ggplot2`. Plot data computed using `dplyr` and `lubridate`&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 3: Histograms generated with &lt;code&gt;ggplot2&lt;/code&gt;. Plot data computed using &lt;code&gt;dplyr&lt;/code&gt; and &lt;code&gt;lubridate&lt;/code&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;From the newly created distance variable, we can calculate the average (mean) trip distance for the 1.9m trips – 1.6km. This might seem very short, but remember that the distance calculation is problematic in that these are straight-line distances between pairs of docking stations. Really we should be calculating network distances derived from the cycle network in New York. A separate reason – discovered when generating a histogram on the &lt;code&gt;dist&lt;/code&gt; variable – is that there are a large number of trips (124,403) that start and end at the same docking station. Initially these might seem to be unsuccessful hires – people failing to undock a bike for example. We could investigate this further by paying attention to the docking stations at which same origin-destination trips occur, as in the code block below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ny_trips %&amp;gt;%
  filter(start_station_id==end_station_id) %&amp;gt;%
  group_by(start_station_id) %&amp;gt;% summarise(count=n()) %&amp;gt;%
  left_join(ny_stations %&amp;gt;%  select(stn_id, name), by=c(&amp;quot;start_station_id&amp;quot;=&amp;quot;stn_id&amp;quot;)) %&amp;gt;%
  arrange(desc(count))

## # A tibble: 958 x 3
##    start_station_id count name
##    &amp;lt;chr&amp;gt;            &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;
##  1 ny3423            2017 West Drive &amp;amp; Prospect Park West
##  2 ny3881            1263 12 Ave &amp;amp; W 125 St
##  3 ny514             1024 12 Ave &amp;amp; W 40 St
##  4 ny3349             978 Grand Army Plaza &amp;amp; Plaza St West
##  5 ny3992             964 W 169 St &amp;amp; Fort Washington Ave
##  6 ny3374             860 Central Park North &amp;amp; Adam Clayton Powell Blvd
##  7 ny3782             837 Brooklyn Bridge Park - Pier 2
##  8 ny3599             829 Franklin Ave &amp;amp; Empire Blvd
##  9 ny3521             793 Lenox Ave &amp;amp; W 111 St
## 10 ny2006             782 Central Park S &amp;amp; 6 Ave
## # … with 948 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;All of the top 10 docking stations are either in parks, near parks or located along river promenades. This coupled with the fact that these trips occur in much greater relative number for casual than regular users (&lt;code&gt;Customer&lt;/code&gt; vs &lt;code&gt;Subscriber&lt;/code&gt;) is further evidence that these are valid trips.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;write-functions-of-your-own&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Write functions of your own&lt;/h4&gt;
&lt;p&gt;Through most of the module we will be making use of functions written by others – mainly those developed for packages that form the &lt;code&gt;tidyverse&lt;/code&gt; and therefore that follow a consistent syntax. However, there may be times where you need abstract over some of your code to make functions of your own. &lt;a href=&#34;https://r4ds.had.co.nz/functions.html&#34;&gt;Chapter 19&lt;/a&gt; of &lt;span class=&#34;citation&#34;&gt;Wickham and Grolemund (&lt;a href=&#34;#ref-wickham_r_2017&#34; role=&#34;doc-biblioref&#34;&gt;2017&lt;/a&gt;)&lt;/span&gt; presents some helpful guidelines around the circumstances under which the data scientist typically tends to write functions. Most often this is when you find yourself copy and pasting the same chunks of code with minimal adaptation.&lt;/p&gt;
&lt;p&gt;Functions have three key characteristics:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;They are (usually) &lt;strong&gt;named&lt;/strong&gt; – the name should be expressive and communicate what the function does (we talk about &lt;code&gt;dplyr&lt;/code&gt; &lt;strong&gt;verbs&lt;/strong&gt;).&lt;/li&gt;
&lt;li&gt;They have brackets &lt;code&gt;&amp;lt;function()&amp;gt;&lt;/code&gt; usually containing &lt;strong&gt;arguments&lt;/strong&gt; – inputs which determine what the function does and returns.&lt;/li&gt;
&lt;li&gt;Immediately followed by &lt;code&gt;&amp;lt;function()&amp;gt; are&lt;/code&gt;` used to contain the &lt;strong&gt;body&lt;/strong&gt; – in this is code that performs a distinct task, described by the function’s &lt;strong&gt;name&lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Effective functions are &lt;strong&gt;short&lt;/strong&gt;, perform &lt;strong&gt;single&lt;/strong&gt; discrete operations and are &lt;strong&gt;intuitive&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;You will recall that in the &lt;code&gt;ny_trips&lt;/code&gt; table there a variable called &lt;code&gt;birth_year&lt;/code&gt;. From this we can derive cyclists’ approximate age. Below I have written a function &lt;code&gt;get_age()&lt;/code&gt; for doing this. The function expects two &lt;strong&gt;arguments&lt;/strong&gt;: &lt;code&gt;yob&lt;/code&gt; – a year of birth as type &lt;code&gt;chr&lt;/code&gt;; &lt;code&gt;yref&lt;/code&gt; – a reference year. In the &lt;strong&gt;body&lt;/strong&gt;, &lt;code&gt;lubridate&lt;/code&gt;’s &lt;code&gt;as.period&lt;/code&gt; function is used to calculate the time in years that elapsed, the value that the function &lt;strong&gt;returns&lt;/strong&gt;. Once defined, and loaded into the session by being executed, it can be used (as below).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Function for calculating time elapsed between two dates in years (age).
get_age &amp;lt;- function(yob, yref) {
    period &amp;lt;- lubridate::as.period(lubridate::interval(yob, yref),unit = &amp;quot;year&amp;quot;)
    return(period$year)
}

ny_trips &amp;lt;- ny_trips %&amp;gt;% # Take the ny_trips data frame.
  mutate(
    age=get_age(as.POSIXct(birth_year, format=&amp;quot;%Y&amp;quot;), as.POSIXct(&amp;quot;2020&amp;quot;, format=&amp;quot;%Y&amp;quot;)) # Calculate age from birth_date.
    )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can use the two new derived variables – distance travelled and age – in our analysis. In Figure 4, we explore how &lt;strong&gt;approximate&lt;/strong&gt; travel speeds vary by age, gender and trip distance. The code used to generate the summary data and plot is in the template file. Again the average “speed” calculation should be treated very cautiously as it is based on straight line distances and it is very difficult to select out “utility” from “leisure” trips. I have tried to do the latter by selecting trips that occur only on weekdays and that are made by &lt;code&gt;Subscriber&lt;/code&gt; cyclists. Additionally, due to the heavy subsetting data become a little volatile for certain age groups and so I’ve aggregated the age variable into 5-year bands. Collecting more data is probably a good idea. Still there are some interesting patterns. Men tend to cycle at faster speeds than do women, although this gap narrows with the older age groups. The effect of age on speed cycled is more apparent for the longer trips. This trend is reasonably strong, although the volatility in the older age groups for trips &amp;gt;4.5km suggests we probably need more data and a more involved analysis to establish this. For example, it may be that the comparatively rare occurrence of trips in the 65-70 age group is made by only a small subset of cyclists. A larger dataset would result in a regression to the mean effect and negate any noise caused by outlier individuals.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:plot-speeds&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;./class/02-class_files/speeds.png&#34; alt=&#34;Line charts generated with `ggplot2`. Plot data computed using `dplyr` and `lubridate`&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 4: Line charts generated with &lt;code&gt;ggplot2&lt;/code&gt;. Plot data computed using &lt;code&gt;dplyr&lt;/code&gt; and &lt;code&gt;lubridate&lt;/code&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;tidy&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Tidy&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;ny_trips&lt;/code&gt; and &lt;code&gt;ny_stations&lt;/code&gt; data already comply with the rules for &lt;strong&gt;tidy&lt;/strong&gt; data &lt;span class=&#34;citation&#34;&gt;(Wickham &lt;a href=&#34;#ref-wickham_tidy_2014&#34; role=&#34;doc-biblioref&#34;&gt;2014&lt;/a&gt;)&lt;/span&gt;. Each row in &lt;code&gt;ny_trips&lt;/code&gt; is a distinct trip and each row in &lt;code&gt;ny_stations&lt;/code&gt; a distinct station. However throughout the module we will undoubtedly encounter datasets that need to be reshaped. There are two key functions to learn here, made available via the &lt;a href=&#34;https://tidyr.tidyverse.org/articles/pivot.html&#34;&gt;&lt;code&gt;tidyr&lt;/code&gt;&lt;/a&gt; package: &lt;a href=&#34;https://tidyr.tidyverse.org/reference/pivot_longer.html&#34;&gt;&lt;code&gt;pivot_longer()&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://tidyr.tidyverse.org/reference/pivot_wider.html&#34;&gt;&lt;code&gt;pivot_wider()&lt;/code&gt;&lt;/a&gt;. &lt;code&gt;pivot_longer&lt;/code&gt; is used to tidy data in which observations are spread across columns, as in Table &lt;a href=&#34;#tab:gapminder-untidy1&#34;&gt;6&lt;/a&gt; (the &lt;code&gt;gapminder&lt;/code&gt; dataset). &lt;code&gt;pivot_wider&lt;/code&gt; is used to tidy data in which observations are spread across rows, as in Table &lt;a href=&#34;#tab:gapminder-untidy2&#34;&gt;7&lt;/a&gt; (the &lt;code&gt;gapminder&lt;/code&gt; dataset). You will find yourself using these functions, particularly &lt;code&gt;pivot_longer&lt;/code&gt; not only for fixing messy data, but for flexibly reshaping data for use in &lt;code&gt;ggplot2&lt;/code&gt; specifications (more on this in sessions 3 and 4) or joining tables.&lt;/p&gt;
&lt;p&gt;A quick breakdown of &lt;code&gt;pivot_longer&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pivot_longer(
  data,
  cols, # Columns to pivot longer (across rows).
  names_to=&amp;quot;name&amp;quot;, # Name of the column where for pivoted variables.
  values_to=&amp;quot;name&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A quick breakdown of &lt;code&gt;pivot_wider&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pivot_wider(
  data,
  names_from, # Column in the long format which contains what will be column names in the wide format.
  values_from # Column in the long format which contains what will be values in the new wide format.
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the homework you will be tidying some messy derived tables based on the bikeshare data using both of these functions, but we can demonstrate both of these functions in &lt;strong&gt;tidying&lt;/strong&gt; the messy &lt;code&gt;gapminder&lt;/code&gt; data in Table &lt;a href=&#34;#tab:gapminder-untidy2&#34;&gt;7&lt;/a&gt;. Remember that these data were messy as the observations by gender were spread across the columns:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;untidy_wide
##   country     year  f_cases m_cases f_population m_population
##   &amp;lt;chr&amp;gt;       &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;        &amp;lt;chr&amp;gt;
## 1 Afghanistan 1999  447     298     9993400      9993671
## 2 Afghanistan 2000  1599    1067    10296280     10299080
## 3 Brazil      1999  16982   20755   86001181     86005181
## 4 Brazil      2000  39440   41048   87251329     87253569
## 5 China       1999  104007  108252  636451250    636464022
## 6 China       2000  104746  109759  640212600    640215983&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First we need to gather the problematic columns with &lt;code&gt;pivot_wider&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;untidy_wide %&amp;gt;%
  pivot_longer(cols=c(f_cases: m_population), names_to=c(&amp;quot;gender_count_type&amp;quot;), values_to=c(&amp;quot;counts&amp;quot;))

##   country     year  gender_count_type       counts
##   &amp;lt;chr&amp;gt;       &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;                   &amp;lt;chr&amp;gt;
##  1 Afghanistan 1999  f_cases                447
##  2 Afghanistan 1999  m_cases                298
##  3 Afghanistan 1999  f_population           9993400
##  4 Afghanistan 1999  m_population           9993671
##  5 Afghanistan 2000  f_cases                1599
##  6 Afghanistan 2000  m_cases                1067
##  7 Afghanistan 2000  f_population           10296280
##  8 Afghanistan 2000  m_population           10299080
##  9 Brazil      1999  f_cases                16982
## 10 Brazil      1999  m_cases                20755
## # … with 14 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So this has usefully collapsed the dataset by gender, we now have a problem similar to that in Table &lt;a href=&#34;#tab:gapminder-untidy1&#34;&gt;6&lt;/a&gt; where observations are spread across the rows – in this instance &lt;code&gt;cases&lt;/code&gt; and &lt;code&gt;population&lt;/code&gt; are better treated as separate variables. This can be fixed by &lt;code&gt;separating&lt;/code&gt; the &lt;code&gt;gender_count_type&lt;/code&gt; variables and then spreading the values of the new &lt;code&gt;count_type&lt;/code&gt; (&lt;code&gt;cases&lt;/code&gt;, &lt;code&gt;population&lt;/code&gt;) across the columns. Hopefully you can see how this gets us to the &lt;strong&gt;tidy&lt;/strong&gt; &lt;code&gt;gapminder&lt;/code&gt; data structure in Table &lt;a href=&#34;#tab:gapminder-tidy&#34;&gt;5&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;untidy_wide %&amp;gt;%
  pivot_longer(cols=c(f_cases: m_population), names_to=c(&amp;quot;gender_count_type&amp;quot;), values_to=c(&amp;quot;counts&amp;quot;)) %&amp;gt;%
  separate(col=gender_count_type, into=c(&amp;quot;gender&amp;quot;, &amp;quot;count_type&amp;quot;), sep=&amp;quot;_&amp;quot;)

##    country     year  gender count_type counts
##    &amp;lt;chr&amp;gt;       &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;
##  1 Afghanistan 1999  f      cases      447
##  2 Afghanistan 1999  m      cases      298
##  3 Afghanistan 1999  f      population 9993400
##  4 Afghanistan 1999  m      population 9993671
##  5 Afghanistan 2000  f      cases      1599
##  6 Afghanistan 2000  m      cases      1067
##  7 Afghanistan 2000  f      population 10296280
##  8 Afghanistan 2000  m      population 10299080
##  9 Brazil      1999  f      cases      16982
## 10 Brazil      1999  m      cases      20755
## # … with 14 more rows

untidy_wide %&amp;gt;%
  pivot_longer(cols=c(f_cases: m_population), names_to=c(&amp;quot;gender_count_type&amp;quot;), values_to=c(&amp;quot;counts&amp;quot;)) %&amp;gt;%
  separate(col=gender_count_type, into=c(&amp;quot;gender&amp;quot;, &amp;quot;count_type&amp;quot;), sep=&amp;quot;_&amp;quot;) %&amp;gt;%
  pivot_wider(names_from=count_type, values_from=counts)

##    country     year  gender cases  population
##    &amp;lt;chr&amp;gt;       &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt;
##  1 Afghanistan 1999  f      447    9993400
##  2 Afghanistan 1999  m      298    9993671
##  3 Afghanistan 2000  f      1599   10296280
##  4 Afghanistan 2000  m      1067   10299080
##  5 Brazil      1999  f      16982  86001181
##  6 Brazil      1999  m      20755  86005181
##  7 Brazil      2000  f      39440  87251329
##  8 Brazil      2000  m      41048  87253569
##  9 China       1999  f      104007 636451250
## 10 China       1999  m      108252 636464022
## 11 China       2000  f      104746 640212600
## 12 China       2000  m      109759 640215983&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;Developing the vocabulary and technical skills to systematically describe and organise data is crucial to modern data analysis. This session has covered the fundamentals here: that data consist of &lt;strong&gt;observations&lt;/strong&gt; and &lt;strong&gt;variables&lt;/strong&gt; of different types &lt;span class=&#34;citation&#34;&gt;(Stevens &lt;a href=&#34;#ref-stevens_on_1946&#34; role=&#34;doc-biblioref&#34;&gt;1946&lt;/a&gt;)&lt;/span&gt; and that in order to work effectively with datasets, especially in a functional way in &lt;code&gt;R&lt;/code&gt;, these data must be organised according to the rules of &lt;strong&gt;tidy&lt;/strong&gt; data &lt;span class=&#34;citation&#34;&gt;(Wickham &lt;a href=&#34;#ref-wickham_tidy_2014&#34; role=&#34;doc-biblioref&#34;&gt;2014&lt;/a&gt;)&lt;/span&gt;. Most of the session content was dedicated to the techniques that enable these concepts to be operationalised. We covered how to download, transform and reshape a reasonably large set of data from New York’s &lt;a href=&#34;&#34;&gt;Citibike&lt;/a&gt; scheme. In doing so, we generated insights that might inform further data collection and analysis activity. In the next session we will apply and extend this conceptual and technical knowledge as we introduce the fundamental of visual data analysis and &lt;code&gt;ggplot2&lt;/code&gt;’s grammar of graphics.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2 unnumbered&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-lovelace_is_2020&#34;&gt;
&lt;p&gt;Lovelace, Beecham, R. 2020. “Is the London Cycle Hire Scheme Becoming More Inclusive? An Evaluation of the Shifting Spatial Distribution of Uptake Based on 70 Million Trips.” &lt;em&gt;Transportation Research Part A: Policy and Practice&lt;/em&gt; 140 (October): 1–15.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-stevens_on_1946&#34;&gt;
&lt;p&gt;Stevens, S. 1946. “On the Theory of Scales of Measurement.” &lt;em&gt;Science&lt;/em&gt; 103 (2684): 677–80.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-wickham_tidy_2014&#34;&gt;
&lt;p&gt;Wickham, H. 2014. “Tidy Data.” &lt;em&gt;Journal of Statistical Software&lt;/em&gt; 59 (10): 1–23.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-wickham_r_2017&#34;&gt;
&lt;p&gt;Wickham, Hadley, and Garrett Grolemund. 2017. &lt;em&gt;R for Data Science: Import, Tidy, Transform, Visualize, and Model Data&lt;/em&gt;. Sebastopol, California: O’Reilly Media. &lt;a href=&#34;http://r4ds.had.co.nz/&#34;&gt;http://r4ds.had.co.nz/&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Schedule</title>
      <link>/schedule/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/schedule/</guid>
      <description>
&lt;link href=&#34;./schedule/index_files/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;./schedule/index_files/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Each session has three sections.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i class=&#34;fas fa-book-reader&#34;&gt;&lt;/i&gt; &lt;a href=&#34;./reading/&#34;&gt;&lt;strong&gt;Reading&lt;/strong&gt;&lt;/a&gt;: Reading and other reference material.&lt;/li&gt;
&lt;li&gt;&lt;i class=&#34;fas fa-chalkboard-teacher&#34;&gt;&lt;/i&gt; &lt;a href=&#34;./class/&#34;&gt;&lt;strong&gt;Class&lt;/strong&gt;&lt;/a&gt;: Main content – a mix of ideas/theory and worked examples.&lt;/li&gt;
&lt;li&gt;&lt;i class=&#34;fas fa-laptop-code&#34;&gt;&lt;/i&gt; &lt;a href=&#34;./homework/&#34;&gt;&lt;strong&gt;Homework&lt;/strong&gt;&lt;/a&gt;: Homework activity to complete after having worked through the main class content.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;table class=&#34;table schedule&#34; style=&#34;max-width:100%&#34;&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td align=&#34;right&#34; style=&#34;width:20%;text-align:right&#34;&gt;Week 1&lt;/td&gt;
            &lt;td style=&#34;width:50%;text-align:left&#34;&gt;Introduction&lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;&lt;a
                    href=&#34;./reading/01-reading/&#34;&gt;
                    &lt;i class=&#34;fas fa-book-reader fa-lg&#34;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;&lt;a href=&#34;./class/01-class/&#34;&gt;
                    &lt;i class=&#34;fas fa-chalkboard-teacher fa-lg&#34;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;&lt;a
                    href=&#34;./homework/01-homework/&#34;&gt;
                    &lt;i class=&#34;fas fa-laptop-code&#34;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td align=&#34;right&#34; style=&#34;width:20%;text-align:right&#34;&gt;Week 2&lt;/td&gt;
            &lt;td style=&#34;width:50%;text-align:left&#34;&gt;Data fundamentals&lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;&lt;a
                    href=&#34;./reading/02-reading/&#34;&gt;
                    &lt;i class=&#34;fas fa-book-reader fa-lg&#34;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;&lt;a href=&#34;./class/02-class/&#34;&gt;
                    &lt;i class=&#34;fas fa-chalkboard-teacher fa-lg&#34;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;&lt;a
                    href=&#34;./homework/02-homework/&#34;&gt;
                    &lt;i class=&#34;fas fa-laptop-code&#34;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td align=&#34;right&#34; style=&#34;width:20%;text-align:right&#34;&gt;Week 3&lt;/td&gt;
            &lt;td style=&#34;width:50%;text-align:left&#34;&gt;Visualization fundamentals&lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;&lt;a
                    href=&#34;./reading/03-reading/&#34;&gt;
                    &lt;i class=&#34;fas fa-book-reader fa-lg&#34;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;&lt;a href=&#34;./class/03-class/&#34;&gt;
                    &lt;i class=&#34;fas fa-chalkboard-teacher fa-lg&#34;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;&lt;a
                    href=&#34;./homework/03-homework/&#34;&gt;
                    &lt;i class=&#34;fas fa-laptop-code&#34;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td align=&#34;right&#34; style=&#34;width:20%;text-align:right&#34;&gt;Week 4&lt;/td&gt;
            &lt;td style=&#34;width:50%;text-align:left&#34;&gt;Visualization for exploratory data analysis&lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;
                &lt;font color=&#34;f1f1f1&#34;&gt;
                    &lt;i class=&#34;fas fa-book-reader fa-lg&#34;&gt;&lt;/i&gt;&lt;/font&gt;
            &lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;
                &lt;font color=&#34;f1f1f1&#34;&gt;
                    &lt;i class=&#34;fas fa-chalkboard-teacher fa-lg&#34;&gt;&lt;/i&gt;&lt;/font&gt;
            &lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;
                &lt;font color=&#34;f1f1f1&#34;&gt;
                    &lt;i class=&#34;fas fa-laptop-code&#34;&gt;&lt;/i&gt;&lt;/font&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td align=&#34;right&#34; style=&#34;width:20%;text-align:right&#34;&gt;Week 5&lt;/td&gt;
            &lt;td style=&#34;width:50%;text-align:left&#34;&gt;Visualization for exploratory geospatial data analysis&lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;
                &lt;font color=&#34;f1f1f1&#34;&gt;
                    &lt;i class=&#34;fas fa-book-reader fa-lg&#34;&gt;&lt;/i&gt;&lt;/font&gt;
            &lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;
                &lt;font color=&#34;f1f1f1&#34;&gt;
                    &lt;i class=&#34;fas fa-chalkboard-teacher fa-lg&#34;&gt;&lt;/i&gt;&lt;/font&gt;
            &lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;
                &lt;font color=&#34;f1f1f1&#34;&gt;
                    &lt;i class=&#34;fas fa-laptop-code&#34;&gt;&lt;/i&gt;&lt;/font&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td align=&#34;right&#34; style=&#34;width:20%;text-align:right&#34;&gt;Week 6&lt;/td&gt;
            &lt;td style=&#34;width:50%;text-align:left&#34;&gt;Visualization for model building 1&lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;
                &lt;font color=&#34;f1f1f1&#34;&gt;
                    &lt;i class=&#34;fas fa-book-reader fa-lg&#34;&gt;&lt;/i&gt;&lt;/font&gt;
            &lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;
                &lt;font color=&#34;f1f1f1&#34;&gt;
                    &lt;i class=&#34;fas fa-chalkboard-teacher fa-lg&#34;&gt;&lt;/i&gt;&lt;/font&gt;
            &lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;
                &lt;font color=&#34;f1f1f1&#34;&gt;
                    &lt;i class=&#34;fas fa-laptop-code&#34;&gt;&lt;/i&gt;&lt;/font&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td align=&#34;right&#34; style=&#34;width:20%;text-align:right&#34;&gt;Week 7&lt;/td&gt;
            &lt;td style=&#34;width:50%;text-align:left&#34;&gt;Visualization for model building 2&lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;
                &lt;font color=&#34;f1f1f1&#34;&gt;
                    &lt;i class=&#34;fas fa-book-reader fa-lg&#34;&gt;&lt;/i&gt;&lt;/font&gt;
            &lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;
                &lt;font color=&#34;f1f1f1&#34;&gt;
                    &lt;i class=&#34;fas fa-chalkboard-teacher fa-lg&#34;&gt;&lt;/i&gt;&lt;/font&gt;
            &lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;
                &lt;font color=&#34;f1f1f1&#34;&gt;
                    &lt;i class=&#34;fas fa-laptop-code&#34;&gt;&lt;/i&gt;&lt;/font&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td align=&#34;right&#34; style=&#34;width:20%;text-align:right&#34;&gt;Week 8&lt;/td&gt;
            &lt;td style=&#34;width:50%;text-align:left&#34;&gt;Visualization for uncertainty analysis&lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;
                &lt;font color=&#34;f1f1f1&#34;&gt;
                    &lt;i class=&#34;fas fa-book-reader fa-lg&#34;&gt;&lt;/i&gt;&lt;/font&gt;
            &lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;
                &lt;font color=&#34;f1f1f1&#34;&gt;
                    &lt;i class=&#34;fas fa-chalkboard-teacher fa-lg&#34;&gt;&lt;/i&gt;&lt;/font&gt;
            &lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;
                &lt;font color=&#34;f1f1f1&#34;&gt;
                    &lt;i class=&#34;fas fa-laptop-code&#34;&gt;&lt;/i&gt;&lt;/font&gt;
            &lt;/td&gt;
        &lt;/tr&gt;

    &lt;/tbody&gt;

&lt;/table&gt;

</description>
    </item>
    
    <item>
      <title>Syllabus</title>
      <link>/syllabus/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/syllabus/</guid>
      <description>
&lt;link href=&#34;./syllabus/index_files/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;./syllabus/index_files/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#overview&#34;&gt;Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#module-objectives&#34;&gt;Module objectives&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#assessment&#34;&gt;Assessment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#software&#34;&gt;Software&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#module-breakdown&#34;&gt;Module breakdown&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#navigating-the-course-materials&#34;&gt;Navigating the course materials&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#self-guided-learning&#34;&gt;Self-guided learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#slack&#34;&gt;Slack&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#asking-questions&#34;&gt;Asking questions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;!-- [^courseinfo]: {-}
  &lt;div class=&#34;row&#34;&gt;
    &lt;div class=&#34;col-md-4&#34;&gt;
        &lt;h3&gt;Instructor&lt;/h3&gt;

        &lt;ul class=&#34;icon-list&#34;&gt;
            &lt;li&gt;&lt;i class=&#34;fas fa-user&#34;&gt;&lt;/i&gt; &lt;a href=&#34;http://www.roger-beecham.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt; Roger Beecham&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;i class=&#34;fas fa-university&#34;&gt;&lt;/i&gt; 10.139 Manton Building&lt;/li&gt;
            &lt;li&gt;&lt;i class=&#34;fas fa-envelope&#34;&gt;&lt;/i&gt; &lt;a href=&#34;mailto:r.j.beecham@leeds.ac.uk&#34;&gt; r.j.beecham@leeds.ac.uk&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;i class=&#34;fab fa-twitter&#34;&gt;&lt;/i&gt; &lt;a href=&#34;https://twitter.com/rjbeecham&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt; @rjbeecham&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
    &lt;/div&gt;

    &lt;div class=&#34;col-md-4&#34;&gt;
        &lt;h3&gt;Course details&lt;/h3&gt;

        &lt;ul class=&#34;icon-list&#34;&gt;
            &lt;li&gt;&lt;i class=&#34;far fa-calendar&#34;&gt;&lt;/i&gt; Wednesdays&lt;/li&gt;
            &lt;li&gt;&lt;i class=&#34;far fa-calendar-alt&#34;&gt;&lt;/i&gt; 25th May - 13th Jul&lt;/li&gt;
            &lt;li&gt;&lt;i class=&#34;far fa-clock&#34;&gt;&lt;/i&gt; 10:00 - 12:00&lt;/li&gt;
            &lt;li&gt;&lt;i class=&#34;fas fa-university&#34;&gt;&lt;/i&gt; ODL&lt;/li&gt;
            
        &lt;/ul&gt;
    &lt;/div&gt;

    &lt;div class=&#34;col-md-4 contact-policy&#34;&gt;
        &lt;h3&gt;Contacting me&lt;/h3&gt;

        &lt;p&gt;Questions to do with the substantive aspects of the module should be directed to the #general channel of the course Slack in the first instance. For matters such as absences, extensions, email me: &lt;a href=&#34;mailto:r.j.beecham@leeds.ac.uk&#34;&gt;r.j.beecham@leeds.ac.uk&lt;/a&gt;.&lt;/p&gt;
    &lt;/div&gt;
&lt;/div&gt;
 --&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Overview&lt;/h2&gt;
&lt;p&gt;In modern data analysis, graphics and computational statistics are increasingly used together to explore and identify complex patterns in data and to make and communicate claims under uncertainty. This course will go beyond traditional ideas of charts, graphs, maps (and also statistics!) to equip you with the critical analysis, design and technical skills to analyse and communicate with geographic datasets.&lt;/p&gt;
&lt;p&gt;The course emphasises real-world applications. You will work with both new, large-scale behavioural datasets, as well as more traditional, administrative datasets located within various social science domains: Political Science, Crime Science, Urban and Transport Planning. As well as learning how to use graphics and statistics to explore patterns in these data, implementing recent ideas from data journalism you will learn how to communicate research findings – how to tell stories with data.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;module-objectives&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Module objectives&lt;/h2&gt;
&lt;p&gt;By the end of the course you will&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Describe, process and combine geographic datasets from a range of sources&lt;/li&gt;
&lt;li&gt;Design statistical graphics that expose structure in geographic data and that are underpinned by established principles in information visualization and cartography&lt;/li&gt;
&lt;li&gt;Use modern data science and visualization frameworks to produce coherent, reproducible data analyses&lt;/li&gt;
&lt;li&gt;Apply modern statistical techniques for analysing, representing and communicating data and model uncertainty&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;assessment&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Assessment&lt;/h2&gt;
&lt;p&gt;A detailed and formal description of the Assessment for this module can be found on the &lt;a href=&#34;&#34;&gt;Minerva&lt;/a&gt; pages. The summative assessment consists of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;30% (Decrease to 20%) - Portfolio of work from completing session &lt;a href=&#34;./homework/&#34;&gt;homework&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;70% (Increase to 80%) - Fully reproducible project report&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;software&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Software&lt;/h2&gt;
&lt;p&gt;All work in the module – data collection, analysis and reporting – will be completed using &lt;a href=&#34;https://www.r-project.org/&#34;&gt;&lt;code&gt;R&lt;/code&gt;&lt;/a&gt; and the &lt;a href=&#34;https://rstudio.com/&#34;&gt;&lt;code&gt;RStudio&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://en.wikipedia.org/wiki/Integrated_development_environment&#34;&gt;Integrated Development Environment&lt;/a&gt; (IDE). Along with &lt;a href=&#34;https://www.python.org/&#34;&gt;&lt;code&gt;Python&lt;/code&gt;&lt;/a&gt; &lt;code&gt;R&lt;/code&gt; is &lt;em&gt;the&lt;/em&gt; programming environment for modern data analysis.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;module-breakdown&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Module breakdown&lt;/h2&gt;
&lt;table class=&#34;table schedule&#34; style=&#34;max-width:100%&#34;&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td align=&#34;right&#34; style=&#34;width:20%;text-align:right&#34;&gt;Week 1&lt;/td&gt;
            &lt;td style=&#34;width:50%;text-align:left&#34;&gt;Introduction&lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;&lt;a
                    href=&#34;./reading/01-reading/&#34;&gt;
                    &lt;i class=&#34;fas fa-book-reader fa-lg&#34;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;&lt;a href=&#34;./class/01-class/&#34;&gt;
                    &lt;i class=&#34;fas fa-chalkboard-teacher fa-lg&#34;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;&lt;a
                    href=&#34;./homework/01-homework/&#34;&gt;
                    &lt;i class=&#34;fas fa-laptop-code&#34;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td align=&#34;right&#34; style=&#34;width:20%;text-align:right&#34;&gt;Week 2&lt;/td&gt;
            &lt;td style=&#34;width:50%;text-align:left&#34;&gt;Data fundamentals&lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;&lt;a
                    href=&#34;./reading/02-reading/&#34;&gt;
                    &lt;i class=&#34;fas fa-book-reader fa-lg&#34;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;&lt;a href=&#34;./class/02-class/&#34;&gt;
                    &lt;i class=&#34;fas fa-chalkboard-teacher fa-lg&#34;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;&lt;a
                    href=&#34;./homework/02-homework/&#34;&gt;
                    &lt;i class=&#34;fas fa-laptop-code&#34;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td align=&#34;right&#34; style=&#34;width:20%;text-align:right&#34;&gt;Week 3&lt;/td&gt;
            &lt;td style=&#34;width:50%;text-align:left&#34;&gt;Visualization fundamentals&lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;&lt;a
                    href=&#34;./reading/03-reading/&#34;&gt;
                    &lt;i class=&#34;fas fa-book-reader fa-lg&#34;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;&lt;a href=&#34;./class/03-class/&#34;&gt;
                    &lt;i class=&#34;fas fa-chalkboard-teacher fa-lg&#34;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;&lt;a
                    href=&#34;./homework/03-homework/&#34;&gt;
                    &lt;i class=&#34;fas fa-laptop-code&#34;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td align=&#34;right&#34; style=&#34;width:20%;text-align:right&#34;&gt;Week 4&lt;/td&gt;
            &lt;td style=&#34;width:50%;text-align:left&#34;&gt;Visualization for exploratory data analysis&lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;
                &lt;font color=&#34;f1f1f1&#34;&gt;
                    &lt;i class=&#34;fas fa-book-reader fa-lg&#34;&gt;&lt;/i&gt;&lt;/font&gt;
            &lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;
                &lt;font color=&#34;f1f1f1&#34;&gt;
                    &lt;i class=&#34;fas fa-chalkboard-teacher fa-lg&#34;&gt;&lt;/i&gt;&lt;/font&gt;
            &lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;
                &lt;font color=&#34;f1f1f1&#34;&gt;
                    &lt;i class=&#34;fas fa-laptop-code&#34;&gt;&lt;/i&gt;&lt;/font&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td align=&#34;right&#34; style=&#34;width:20%;text-align:right&#34;&gt;Week 5&lt;/td&gt;
            &lt;td style=&#34;width:50%;text-align:left&#34;&gt;Visualization for exploratory geospatial data analysis&lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;
                &lt;font color=&#34;f1f1f1&#34;&gt;
                    &lt;i class=&#34;fas fa-book-reader fa-lg&#34;&gt;&lt;/i&gt;&lt;/font&gt;
            &lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;
                &lt;font color=&#34;f1f1f1&#34;&gt;
                    &lt;i class=&#34;fas fa-chalkboard-teacher fa-lg&#34;&gt;&lt;/i&gt;&lt;/font&gt;
            &lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;
                &lt;font color=&#34;f1f1f1&#34;&gt;
                    &lt;i class=&#34;fas fa-laptop-code&#34;&gt;&lt;/i&gt;&lt;/font&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td align=&#34;right&#34; style=&#34;width:20%;text-align:right&#34;&gt;Week 6&lt;/td&gt;
            &lt;td style=&#34;width:50%;text-align:left&#34;&gt;Visualization for model building 1&lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;
                &lt;font color=&#34;f1f1f1&#34;&gt;
                    &lt;i class=&#34;fas fa-book-reader fa-lg&#34;&gt;&lt;/i&gt;&lt;/font&gt;
            &lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;
                &lt;font color=&#34;f1f1f1&#34;&gt;
                    &lt;i class=&#34;fas fa-chalkboard-teacher fa-lg&#34;&gt;&lt;/i&gt;&lt;/font&gt;
            &lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;
                &lt;font color=&#34;f1f1f1&#34;&gt;
                    &lt;i class=&#34;fas fa-laptop-code&#34;&gt;&lt;/i&gt;&lt;/font&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td align=&#34;right&#34; style=&#34;width:20%;text-align:right&#34;&gt;Week 7&lt;/td&gt;
            &lt;td style=&#34;width:50%;text-align:left&#34;&gt;Visualization for model building 2&lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;
                &lt;font color=&#34;f1f1f1&#34;&gt;
                    &lt;i class=&#34;fas fa-book-reader fa-lg&#34;&gt;&lt;/i&gt;&lt;/font&gt;
            &lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;
                &lt;font color=&#34;f1f1f1&#34;&gt;
                    &lt;i class=&#34;fas fa-chalkboard-teacher fa-lg&#34;&gt;&lt;/i&gt;&lt;/font&gt;
            &lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;
                &lt;font color=&#34;f1f1f1&#34;&gt;
                    &lt;i class=&#34;fas fa-laptop-code&#34;&gt;&lt;/i&gt;&lt;/font&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td align=&#34;right&#34; style=&#34;width:20%;text-align:right&#34;&gt;Week 8&lt;/td&gt;
            &lt;td style=&#34;width:50%;text-align:left&#34;&gt;Visualization for uncertainty analysis&lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;
                &lt;font color=&#34;f1f1f1&#34;&gt;
                    &lt;i class=&#34;fas fa-book-reader fa-lg&#34;&gt;&lt;/i&gt;&lt;/font&gt;
            &lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;
                &lt;font color=&#34;f1f1f1&#34;&gt;
                    &lt;i class=&#34;fas fa-chalkboard-teacher fa-lg&#34;&gt;&lt;/i&gt;&lt;/font&gt;
            &lt;/td&gt;
            &lt;td align=&#34;center&#34; style=&#34;width:10%;text-align:center&#34;&gt;
                &lt;font color=&#34;f1f1f1&#34;&gt;
                    &lt;i class=&#34;fas fa-laptop-code&#34;&gt;&lt;/i&gt;&lt;/font&gt;
            &lt;/td&gt;
        &lt;/tr&gt;

    &lt;/tbody&gt;

&lt;/table&gt;

&lt;/div&gt;
&lt;div id=&#34;navigating-the-course-materials&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Navigating the course materials&lt;/h2&gt;
&lt;p&gt;The home for this module is &lt;a href=&#34;../../&#34;&gt;this website&lt;/a&gt;. From here, you will find the course &lt;a href=&#34;./schedule/&#34;&gt;Schedule&lt;/a&gt; (also above), where for each session there is &lt;i class=&#34;fas fa-book-reader&#34;&gt;&lt;/i&gt; &lt;a href=&#34;./reading/&#34;&gt;&lt;strong&gt;Reading&lt;/strong&gt;&lt;/a&gt;, &lt;i class=&#34;fas fa-chalkboard-teacher&#34;&gt;&lt;/i&gt; &lt;a href=&#34;./class/&#34;&gt;&lt;strong&gt;Class&lt;/strong&gt;&lt;/a&gt; content and &lt;i class=&#34;fas fa-laptop-code&#34;&gt;&lt;/i&gt; &lt;a href=&#34;./homework/&#34;&gt;&lt;strong&gt;Homework&lt;/strong&gt;&lt;/a&gt;. Also accompanying each session is an &lt;a href=&#34;https://rmarkdown.rstudio.com/&#34;&gt;R Markdown&lt;/a&gt; file with a template to complete coding activities introduced through the &lt;a href=&#34;./class/&#34;&gt;class&lt;/a&gt; and &lt;a href=&#34;./homework/&#34;&gt;homework&lt;/a&gt; pages. These session templates contain pre-prepared code chunks for you to execute. As the module progresses and you become more familiar and competent in &lt;code&gt;R&lt;/code&gt;, you will be required to contribute more code of your own to these.&lt;/p&gt;
&lt;p&gt;As you work through the course materials you will notice special icons are used to distinguish &lt;strong&gt;learning outcomes&lt;/strong&gt; &lt;i class=&#34;fas fa-chevron-circle-down&#34;&gt;&lt;/i&gt; and &lt;strong&gt;instructions&lt;/strong&gt; &lt;i class=&#34;fas fa-tasks&#34;&gt;&lt;/i&gt; that need to be completed, along with important informational asides &lt;i class=&#34;fas fa-info-circle&#34;&gt;&lt;/i&gt;. Do pay special attention to these, and in particular revisit the &lt;strong&gt;learning outcomes&lt;/strong&gt; &lt;i class=&#34;fas fa-chevron-circle-down&#34;&gt;&lt;/i&gt; as you progress through the sessions.&lt;/p&gt;
&lt;p&gt;Use &lt;a href=&#34;&#34;&gt;Minerva&lt;/a&gt; to access the &lt;a href=&#34;&#34;&gt;Module Handbook&lt;/a&gt; and to upload assignments in the usual way.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;self-guided-learning&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Self-guided learning&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;The bad news is whenever you’re learning a new tool, for a long time you’re going to suck. It’s going to be very frustrating. But, the good news is that that is typical, it’s something that happens to everyone, and it’s only temporary … [T]here is no way to go from knowing nothing about a subject to knowing something about a subject and being an expert in it without going through a period of great frustration.&#34;&lt;/p&gt;
&lt;p&gt;Hadley Wickham&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;From the module overview and outline you will have got the sense that this is a reasonably technical module. You will be introduced to the key components of modern data analysis (Data Science) through doing – the course inevitably requires you to do a fair amount of “coding”, in this case in &lt;code&gt;R&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;It is understandable if this feels like a daunting prospect. The barrier to entry is greater than with point-and-click interfaces such as ArcGIS and SPSS. So do expect that this module may require a degree of patience and persistence – but isn’t that true of all things that are worth learning?&lt;/p&gt;
&lt;p&gt;In order reduce the pain, I’ve tried to include within the module a balance of content between programming fundamentals, theoretical/conceptual learning and more procedural ‘grunt-work’ with datasets. I have also carefully considered and incorporated ideas from some of the really high quality &lt;a href=&#34;../useful&#34;&gt;Resources&lt;/a&gt; out there aimed at lowering the barrier to doing Data Science in &lt;code&gt;R&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;In return, I expect you to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Read&lt;/strong&gt; all course materials&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Complete&lt;/strong&gt; the class session tasks, homework and coursework assignment&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Participate&lt;/strong&gt; in the discussion forum&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;slack&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Slack&lt;/h2&gt;
&lt;p&gt;A key mechanism through which you can &lt;strong&gt;participate&lt;/strong&gt; is by contributing to the discussion forum. Engaging fully with this will help to foster a sort of collegiate atmosphere on the module that will maximise your learning. I have set up a course &lt;a href=&#34;&#34;&gt;Slack&lt;/a&gt;, which should provide a useful mechanism for sharing information, resources and importantly posting and discussing &lt;code&gt;code&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;If you’ve not used Slack before, then follow these pages on &lt;a href=&#34;https://slack.com/intl/en-gb/help/articles/218080037-Getting-started-for-new-members&#34;&gt;getting started with Slack&lt;/a&gt;. You should post all substantive questions associated with the module to Slack. These will get answered. If you wish to discuss more personal matters around your completing the course, then send those directly to me via e-mail.&lt;/p&gt;
&lt;p&gt;

&lt;div class=&#34;alert alert-instruction&#34;&gt;
  &lt;div&gt;
    Create an account on the &lt;a href=&#34;&#34;&gt;vis-for-gds Slack&lt;/a&gt;. Be sue to register with you &lt;code&gt;.leeds.ac.uk&lt;/code&gt; e-mail. If you run into any problems, try &lt;a href=&#34;https://slack.com/intl/en-gb/help/articles/218080037-Getting-started-for-new-members&#34;&gt;getting started with Slack&lt;/a&gt;.
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;asking-questions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Asking questions&lt;/h2&gt;
&lt;p&gt;As many of you will be learning to program in R for the first time, you should expect to be baffled at times and to routinely encounter scary-looking &lt;code&gt;ERROR&lt;/code&gt; messages. Counterintuitively, this is actually to be welcomed. You need to be making mistakes and hitting obstacles on a regular basis if you are to progress.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;How&lt;/em&gt; you respond to these obstacles is important. In a face-to-face lab, the temptation when hitting a problem is to raise your hand, gesture towards your screen and have a demonstrator ‘de-bug’ for you. Whilst this may initially seem like an efficient solution, you risk learning very little if this is your only course of action.&lt;/p&gt;
&lt;p&gt;When you encounter problems working through the material in this course, try to force yourself to spend 15-20 minutes troubleshooting the problem individually. &lt;a href=&#34;https://www.google.com/&#34;&gt;Google&lt;/a&gt; your problem or try &lt;a href=&#34;https://stackoverflow.com/&#34;&gt;StackOverflow&lt;/a&gt;. If you are not able to resolve the problem on your own, then post your question to the course &lt;a href=&#34;&#34;&gt;Slack&lt;/a&gt;, which I will monitor regularly. When doing this, make an effort to be specific and unambiguous about your problem. You might wish to consult StackOverflow’s guidance on &lt;a href=&#34;https://stackoverflow.com/help/how-to-ask&#34;&gt;how to ask a good question&lt;/a&gt;.&lt;/p&gt;
&lt;!-- 
## Resources

### Primers

- [@healy_data_2018]\
-- An engaging read that manages to integrate ggplot2 code with key Information Visualization theory and using real social science datasets.\
[Free online (draft version)](https://socviz.co/).


- [@lovelace_geocomputation_2019]\
-- This book comprehensively introduces spatial data handling in R. It is a great complement to R for Data Science in that it draws on brand new libraries that support `tidyverse-style` operations on spatial data.\
[Free online](https://geocompr.robinlovelace.net/).

- [@wickham_r_2017]\
-- _The_ primer for doing data analysis with R. Wickham and Grolemund present a thesis of the data science workflow and illustrates how R and packages that form the `tidyverse` support this. It is both accessible and coherent and is highly recommended.\
[Free online](https://r4ds.had.co.nz/).


### Blogs

- [Flowingdata](http://flowingdata.com) \
-- Nathan Yau, a former statistics PhD from UCLA, has maintained a data vis blog and online training materials for some time. Numerous excellent examples, on the most part implemented in R and `ggplot2`.

- [giCentre](https://www.gicentre.net)  \
-- World-leading group researching and developing geovisualization. Check out recent work on [litvis](https://www.gicentre.net/software#/litvis-1/) and [elm-vega](https://www.gicentre.net/elmvegalite/).

- [Multiple Views](https://medium.com/multiple-views-visualization-research-explained) \
-- Blog series by leading visualization researchers and practitioners.

### Conferences

- [IEEE VIS](http://ieeevis.org/)\
-- *The* conference at which leading Data Visualization work is published through a special issue of [Transactions on Visualization &amp; Computer Graphics](https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=2945).

- [OpenVis Conf](http://www.openvisconf.com)\
-- New, exciting conference (though last one was in 2018!). Presenters are academics and practitioners. Videos of talks from previous conferences are published online. From the 2018 conference, I&#39;d recommend Matt Kay&#39;s on [Uncertainty Visualization](https://www.youtube.com/watch?v=vqzO-9LSoG4&amp;feature=youtu.be), Maarten Lambrechts&#39; [Xenographics](https://www.youtube.com/watch?v=fp-WNqaQG0s&amp;feature=youtu.be) and Heather Krause&#39;s [F-Word](https://www.youtube.com/watch?v=uw1Tag08dK4&amp;feature=youtu.be). --&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
